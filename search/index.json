[{"content":" FarCry6 的一个分享，热带天气的模拟。\nSpeakers 的介绍，一个图形程序和一个 TA。\n先介绍下 FarCry6，FarCry 系列大家都比较熟悉了，一直都做的开放世界第一人称射击，每一代 FarCry 的剧情都会在一个不同的环境下展开。这一代故事发生在一个名为雅拉的热带小岛上，雅拉的原型是古巴（现实生活中古巴在美洲加勒比海附近，是一个热带群岛国家，北纬 19-24 度）。\n这一代玩家会扮演一名名为丹尼罗杰斯的本地反叛军，剧情就是推翻独裁者安东和他儿子迭戈的凶暴统治。这里的封面就是安东和迭戈，看过绝命毒师的应该都知道，这张脸的原型就是炸鸡叔，看着就知道是大反派。\nFarCry 的每一代开放世界都有自己的特色，本作的特色就是热带风情，要给玩家完美地展示热带风土人情，全动态的天气系统是必不可少的。\n这几张图展示了游戏中的不同天气，分别是晴天、雨天、阴天、夜晚。\n下面会分为几个板块去介绍 FarCry6 的天气系统：\n天气系统的灵感来源 天气系统的核心概念 如何让湿度影响所有资产的材质 用到的渲染技术 总结 首先是一些现实生活中热带天气的参考，之前说的古巴就是一个很合适的地方。\n在项目开始的时候，项目组花时间对热带天气进行了大量的调研，以带给玩家一个更加真实的世界。热带小岛的天气是独特而多变的，这几张图是热带小岛标志性的晴天。\n这几张图是压抑的雨天和雷暴天气。除了实现天气效果本身，天气系统还要能够支持剧烈地变化与切换。\n上面的参考被吸纳进了他们的概念设计中，这张图是早期的概念设计图。\n然而他们的艺术总监想要打造一种不祥的氛围，然后就改成了上面这种充满雷暴的天气。\n想要营造一种被风暴困住的感觉，真实的雨和湿润效果是必不可少的。\n当然，雅拉是一个小岛，所以天气与海的互动也是天气系统中重要的一环。\n时候需要记得我们是为一个开放世界游戏打造一套天气系统，所以有这些目标：\n足够真实 全动态，支持 TOD 天气切换过渡自然 高性能 下面介绍天气系统的一些核心概念。\n天气系统的核心是 Weather Manager，里面包含了一些定义并控制天气的关键信息。Weather Manager 本身是一个后端，前端则是 Weather Database，即暴露给美术的各种天气设置。\nWeather Presets 是项目中可以引用的一系列天气预设，每一个 Weather Preset 都引用了一系列 Weather Manager 暴露的参数，参数的变化可以印象天气。\n举几个例子，这张图是 Few Clouds 预设的效果与对应的参数。\n对比下，Broken Clouds 预设下云的覆盖率就更大，而且显得更蓬松。\nMist 预设下就能看见一层淡淡的雾。\nFog 预设下则更明显。\nLight Rain 预设，开始下小雨。\nModerate Rain 预设，中雨。\nHeavy Rain，暴雨。\nThunderstorm，雷暴。\n有了一系列天气预设之后，我们需要按照某种模式让天气不断循环切换，并支持在游戏中进行天气预报。最开始的想法是收集并使用现实生活中某个城市的天气数据，这张图就是 2013 年某段时间迈阿密的真实天气预报数据。\n但是权衡下来还是觉得用现实生活中的数据不够艺术化，控制起来也不够自由。于是改为了使用类似的文本描述，但是天气数据改成了自己的预设。最后每个区域设计了足够使用 5 天的天气循环。\nFarCry6 的游戏地图由东部岛屿、中部岛屿、西部岛屿三部分组合而成，每个地区都有自己的气候特点，西部是干旱地带，中部是湿地，西部则是丛林。天气系统的表现在不同的地区也需要有对应的修改。\n为了实现不同区域的天气变化，天气系统中的每一个参数都会由美术指定两条曲线，曲线对应经度空间上的变化，指定了每个参数的最大值和最小值。在世界中不断移动，最终的天气参数就是插值的结果。\n举个例子来说，美术可以设定室内区域的 Max Fog Density 为 0，这样走进室内区域雾就会消失。当然，通过这种方法来控制天气参数在空间上的变化限制也很明显，如果一间房子有窗户，这小块区域设定了 Max Fog Density 为 0，走进房间之后会看见雾当面消失掉，这就要求美术在设计场景的时候需要小心一点，避免这种情况的发生。\n有的时候全局天气需要支持临时 Override，比如 Gameplay 中的任务开始后或播放过场动画这种。除此之外，因为 FarCry6 还支持多人合作模式，所有天气系统还需要支持多人同步。\n整个天气状态的工作流，首先是 TOD 中保存的 Preset 参数，经过位置插值和脚本的 Override 之后，结合天气已经运行的时间来更新湿度、雨量、闪电等参数，最后输出为 Weather Parameters，之后这些 Parameter 就可以用于渲染、音效、Gameplay 等了。\n下面讲湿度是如何影响材质的。\n湿度是天气系统中重要的一环，下雨时湿度会影响所有物体的渲染效果，这就意味着所有资产都需要支持湿度。\n然而资产数量庞大，并不是所有资产都使用同一套管线和材质。最终的解决方案是让湿度独立于资产制作，由 TA 控制，对于普通材质可以做到开箱即用，拖进场景就能受到湿度影响。当然，有些材质本身需要使用湿度来控制更多细节，这种材质不在讨论范畴内。\n湿度分为两种类型，静态湿度和动态湿度。就跟名字一样，静态湿度是给静态物体使用的，动态物体则是给动态物体使用的。\n静态湿度的绝大多数使用场景是道具和建筑，强度取决于 Weather Manager 提供的参数 Wetness Factor 和一种叫 Wetness Shadow Map 的特殊 Mask。静态湿度的计算是在 Deferred Lighting Pass。静态湿度的优点是简单通用，不需要专用的纹理，确定就是不灵活。\n动态湿度主要是为武器、载具和角色设计的。强度取决于两个参数，第一个是通过 Raycast 计算在雨水中的暴露程度，第二个是在水中的淹没程度。动态湿度的计算是放在单独的 Shader 中进行的，这意味着可以进行随意定制。这种方法优点是动态、可定制，缺点是需要管理额外的 Shader。\n上面提到的 Wetness Shadow Map 包含了物体的遮挡信息，其实 Wetness Shadow Map 很形象，想象雨水是一束平行光，那么处于阴影中的物体就不会被淋湿。Wetness Shadow Map 会在 Deferred Shadow Pass 被计算，然后在 Deferred Lighting Pass 中被使用，就跟阴影的使用方法一样。采样 Wetness Shadow Map 之后再与 WetnessFactor 相乘就可以得到最终的湿度。\n这是一个 Wetness Shadow Map 的例子，图中显得更亮更干燥的区域就是位于 Wetness Shadow 之中的部分。\n这个是 Wetness Shadow 的 Debug View，很多地方都能很好的工作，但是近乎垂直的面会有精度问题。为了处理这种问题每一帧都会略微 Dither 一下，这样就会从硬切的边缘变成图中这种较柔和的边缘，更加贴近自然。\n下面看一下如何在画面上表现出湿润的效果。这里是一些湿润物体的参考图，想沙子、纸板这种渗水性能比较好的材质在湿润后会呈现出更深的颜色，像石头、地砖这种渗水性能不是很好的材料就会表现得更光滑，当然还有的材质会同时呈现这两种效果。表现湿润效果得重点是我们怎么去描述材质的渗水性。\n我们引入了一个新的参数叫 Porosity，孔隙率，描述了物体内部细小空间的多少，代表了渗水能力。较高的孔隙率会让材质变暗（代表材质有泥土、纺织物、没有刷油漆的木头等），较低的孔隙率则会让材质反光（比如塑料、大理石、金属等）。\n引入这个参数之后，意味着与其他 PBR 参数一样，我们也需要一张 Porosity Map。但是问题是已经没有性能预算能够给到 Porosity Map 了。\n因为 Porosity 本身跟 Smoothness 是相关的，所以设计了一个基础公式来根据 Smoothness 推导 Porosity，其中 PorosityFactors 是根据材质类型预设的一组参数。根据这个公式就可以直接利用现有的 PBR Texture 计算得到 Porosity。\n好在 FarCry 系列本来就已经有一系列预设的 PBR Hard Code 参数了，直接把 Porosity 也加了进去，这样甚至连美术管线也完全不需要动。\nApplyWetness Shader 展示，主要就是根据 Porosity 使 Albedo 变暗，Smoothness 提升。这段 Shader 对于单个物体来说并不是完美得，只是从场景级别看起来还不错。\n这是部分材质在干燥和湿润效果下的差异。\n整个场景的展示。\n整体调高湿度后的表现。\n下面介绍动态湿度。动态湿度是针对角色、 武器、载具一类的动态物体的。每一帧都需要用 Raycast 判断是否暴露在雨中，载具需要进行多次 Raycast。动态湿度的增减是逐步的。另外为了支持被水淹没的效果还添加了 Local Wetness Feature。\n前面说过动态湿度的好处是可以随意定制物体湿润后的表现效果，先看一些参考图。\n服装的效果跟小物体类似，只是额外添加了光滑度上限的参数，来展现更好的效果。头发的话就直接由 Porosity 参数控制，本来开始是想做头发湿润后缠绕在一起的效果，后面因为太难就放弃了。\n皮肤的话想要做雨水吸附在上面的效果，而且看起来要尽量自然。实现的方法是使用一张纹理，RG 通道存放雨水的 Normal，B 通道存放 Wetness Mask，最终就能表现出图中的效果。\n在 FarCry6 中，载具和武器其实是比较类似的，他们都会受 Gameplay 控制，并且会被玩家近距离观察，所以为这两类物体做了雨水的动画效果，每一帧都会更新雨水的相关纹理。雨水在这类物体上的表现分为两种，水纹和水滴。\n先说水纹，水纹只会在枪械和载具的竖直平面上出现。输入纹理也只有一张，RG 通道存 Normal，B 通道存 Heightmap（这里应该写错了），A 通道存 Scroll，Scroll 纹理驱动了水纹在垂直方向上的移动，再按 Scroll 的 Local Space UV 采样 Normal 和 Heightmap，Scroll 纹理会被每帧更新。\n下面是水滴，水滴只在物体的水平平面上出现。同样是单张纹理，Pack 了 Normal、ID、Heightmap。也是类似的，ID Map 会每帧更新，按照 ID Map 采样两次 Normal、Heightmap 纹理然后做 Blend 就可以做出雨点产生和消失的动画。\n另外，因为雨点在水平平面上移动困难，所以会随着时间的推移不断累积到平面上，所以还做了随着时间推移改变 Heightmap 的效果。另外对于这张纹理，用自动制作的 Mipmaps 会导致闪烁的问题，所以改用了纯手工的 Mipmaps。\n为了节省 Drawcall，游戏中的载具车内车外基本都用的同一套材质，这种情况下车内也会收到雨水影响。为了解决这个问题用了顶点色来做 Mask，美术刷完之后车内就不会再受影响了。图中就是这个 Mask 的 Debug View。\nGameplay 团队做了一个雨刷器的游戏玩法，开始 3D 团队并没有考虑到这个设定。为了支持这个玩法，单独做了一张雨刷器的梯度 Mask，在 Shader 中会采样这张纹理来调整雨水的效果。图中就是最终的效果。\n最开始的时候植被本来使用 Static Wetness 的，但是会有一些问题。首先是下雨时植被相互遮挡，在丛林中位于下层的植被就不会受到雨水影响，这在自然界中是比较难见到的。然后就是用 Static Wetness 植被高光太明显了，看起来就很像金属。\n为了解决这两个问题，植被还是改用了 Dynamic Wetness，这样就可以在 Shader 里定制湿润效果。当然这样的话 Wetness Shadow Map 对植被就没用了，但是 99% 的情况下都不会把植被放到室内，所以其实也没太大关系。\n最终是在叶子上做了水滴效果，然后调整了反射，看起来就不会像左边那张图这么奇怪了。\n最后是地形，在雨天低洼的地面会有积水，这个效果也是需要实现的。\nFarCry5 原来的地形系统就已经有 Albedo、Normal、Smoothness 这几张纹理了，现在又单独新加了一张 Porosity 纹理。因为 FarCry5 开始地形渲染就已经用 VT 了，所以道路和贴画使用起来会比较方便，直接往 VT 上拍就可以了。\n地形的湿度计算跟使用 Static Wetness 的物体类似，也是搬了 ApplyWetness() 然后做了些修改。主要区别是不想让 Wetness 的过渡看起来这么平滑，而是像做成雨滴飞溅的效果，就像视频中展示的这样（pdf 没法放视频）。\n下面是水坑，水坑对视角效果的影响是非常大的，因为它会产生反射效果，极大地提升真实感。在游戏中，水坑其实就是一个贴花，一般都放置在低洼的道路上。\n绘制水坑的时候，gBuffer 的 Albedo 会变成泥泞的颜色，Smoothness 会接近 1，Normal 会变成垂直向上，最终就形成了图中的效果。\n有了基础的效果之后还要考虑跟环境的交互。雨水落在水坑上会产生涟漪，而风吹过水坑会产生波纹。\n两个效果分别对应两张带动画的 Tangent Normal Map，涟漪效果是帧动画，每帧按照序列替换一张新的纹理，强度受 Weather Manager 的 RainEffectsFactor 影响。波纹效果则是一张滚动纹理，受风的方向和强度控制。把两张纹理组合起来得到 Ripple Texture，再把这张图应用到树坑的渲染上就能做出来前面说的效果。\n进入下一部分，换图形程序来讲。\n下面介绍天气系统相关的渲染技术。\n在开始讲渲染技术前，先看一下 FarCry6 的各种技术参数，FarCry6 会在 9 个平台上发布，除了 PC、上世代和次时代主机，还有 Stadia、Luna 两个云游戏平台。次时代的主机要求 60fps，上世代 30fps。地图大小 10 km2。支持 TOD、有各种室内室外场景、一座大都市。现在好了，又要动态天气。\n下面看看各种渲染技术是怎么影响画面效果的，这是只有大气散射的效果。\n添加体积云之后的效果。\n添加体积雾。\n添加反射与 Cubemaps。\n添加雨水和雷电，最后就得到了一个被困雷暴中的场景。\n在讲单个渲染技术前，先看一下 FarCry6 的光照模型。FarCry 系列的光照是 PBR 的，并且尽量高性能。FarCry6 Diffuse BRDF 使用的是 Multiscattering Diffuse，Specular 使用的是 GGX + Multiscattering Lobe，并且支持面光源。\n右边这个表展示了各种不同的 Surface Type 使用的公式，主要不同的地方是半透明 Surface，在游戏中主要是给植被使用的，半透没有使用 Multiscattering Diffuse，改用了 Two Wrapped Lambert Lobes，来模拟透光效果。\nFarCry 的 GI 系统用的是摆探针的方法，美术纯手摆，每天都会通过打包机 Bake 然后进版本。GI 数据的存储用的是 Voxels，打包了 13 帧数据，其中 11 帧用于 TOD，一帧给夜晚的 Local Lights，一帧给天光遮蔽。\n这个系统并没有考虑云或者天气的影响，解决方法也很简单粗暴，当云的覆盖率设定的比较高时，直接给间接光做一个淡出来模拟云的阴影。\n另外就是这套系统直接放在城市里用效果并不太好，所以后来把数据改成了稀疏存储，探针尺寸也改成了可变的，这样就可以针对室内场景提高 GI 精度。\n先说天光，用的是 Bruneton 和 Preetham 两篇论文里面的 Sky Model 和 Sun Model。这部分是预先计算好然后存在 LUT 里的，但是之前是直接运行时计算的。\nWeather Manager 里面有两个参数会影响天光，浊度 Turbidity 和潮度 Humidity，两个参数的取值都只有 0 和 1，因此能组合出四种天空。\n展示下四种天空。\n大气散射配合体积云的效果。\n接下来是体积云。基于 Skybox 的云实现很简单，但是运动效果很差，也没办法跟天气系统做配合。Skybox 更像是一个背景，很难与世界产生交互，所以还是想要做体积云。\n云的渲染中最重要的部分是描述光穿过云层时的能量损失。云本身是由水分子聚集而成的，光穿过云层时会不断与水分子碰撞从而损失能量，这个过程遵循 Beer-lambert 定律，我们之后会用透光率 Transmittance 来描述它。\n光在云中会有两种行为，一种是被吸收，一种是散射，吸收在云中发生的比较少。散射后最终到达眼睛的光是通过 Radiance 来衡量的。\n散射分为两种，单散射和多散射，单散射就是碰到水分子后光改变方向然后直接到达人眼，多散射则是在云内部很多次遇见水分子并改变方向，之后到达人眼。\n这是只有单散射的效果。\n这是只有多散射的效果。\n结合起来的效果。\n所有的散射事件都可以通过相函数来建模。通过相函数可以计算出光遇见水分子之后会分散成什么方向，降低多少强度。相函数求值结果是一个近似的椭球形。\n最后选用的相函数是一个近似公式，按照这个公式求值可以得到右边这个椭球形。\n下面谈下如何存储云的数据，其实主要就是描述云内部的水分子密度。首先是两张 3D 噪声纹理，Base Noise Texture 和 Detail Noise Texture，Base 和 Detail 两种纹理都是离线工具生成的，组合了多种不同频率的噪声，他们之后会被用于生成云的形状。\n然后是 Weather Map，Weather Map 会被直接屏幕在世界空间上，还会随着风向滚动。用这张图可以构建出 XY 方向上云的形状，同时 Weather Map 中保存的值还代表了云的密度。\n最后是 Curl Noise，里面保存了三维的偏移数据，对 Base 和 Detail 纹理采样的时候会拿这张图进行偏移，让云看起来细节更丰富。\n最后是 Cirrus Map 和 Cirrus Horizon，Cirrus Map 会被半球映射到天空上，看起来会有一些细散的残云，Cirrus Horizon Texture 会在相机周围按照圆柱体映射，在地平线附近产生云的效果。\n下面看一下这些纹理对画面产生的影响，这张图是只有大气散射的效果。\n添加了 Cirrus Map 和 Cirrus Horzion Map 后的效果，有了残云和地平线的效果。\n添加 Weather Map，XY 方向上云的形状已经出来了。\n预设了一张云的梯度图来限制云的高度，采样这张图之后云的基本形状就有了。\n采样 Base Noise Texture 这张 3D 纹理之后的效果。\n采样 Detail Noise Texture 添加更多细节。\n采样 Curl Noise Texture 做偏移，最终得到了一个看起来还不错的效果。\n体积云的渲染使用的是 Raymarching，从观察者视角发射光线并步进。每前进一步，都计算当前位置到太阳方向的 ，然后作为透射率累加起来，用于后面计算散射。\nRaymarching 本身很慢，常用的优化手法是改变步进的策略和结果的分帧累加。\n伪代码：\n先检查 Occlusion 并提前 Return 计算光线起始位置 做 Raymarching 计算 Cirrus Clouds 用项函数计算散射 计算大气散射对云的影响 全分辨率做 Raymarching 实在太费了，于是做了半分辨率 + Temporal 的优化，所以最终会有两张 Radiance Texture 和两张 Transmittance Texture。\n还做了棋盘格渲染的优化，每帧每四个像素只做一次 Ray Marching，用 Checkboard Offset + Curl Noise 同时做偏移。接下来把历史帧的信息投影到当前帧，用启发式算法做 Clamp，然后再在相邻像素间做双线性插值，得到最终的结果。\n存储 Radiance 的时候因为分辨率太低，会出现瑕疵，为了解决这个问题改用了蓝噪声并对噪声做了两倍的模糊，而且在云画到场景的时候也加了两倍的模糊。\n另外一个问题是云对地面没有投影，看起来真实感大大降低。\n开始尝试了对 GBuffer/Depth 做 Ray-Marched 来获取阴影（就是 Contact Shadow），但是发现太昂贵了。就直接算了一个云对地面的正交投影，覆盖相机 5000m 范围，这张纹理后面也会被用于计算体积雾的 Light Shaft。\n用这种方法计算的效果。\n下面讲体积雾。\n体积雾的实现方法是经典的 Froxel Volume，按照体素划分视椎体，然后在这个区域内计算每个像素的光照结果并沿着视角方向进行离散化积分。体素视椎体的分辨率是 120x68x120，对应一张 Irradiance Volume 纹理和一张 Attenuation Volume 纹理。\n整个体积雾渲染的流程。首先进行降采样，然后对深度进行 XY 方向上的膨胀。之后为 Froxel Volume 填充数据，最后沿着视角方向进行积分，再沿着 XY 方向进行 Blur 得到最终的结果。\nIrradiance Volume 纹理在计算的时候会接受各种光照信息，包括天光、间接光、点光源和聚光灯等。接受的 Irradiance 强度受控于 Weather Manager 中的雾参数。计算的时候使用的项函数跟体积云的是一样的，在上世代主机和 PC 中低端机器上，这一步计算还是比较耗的，所以会用 Temporal Filtering，本世代和高端机器就直接用 Bilateral Blur。\n完成 Fill Cell 之后需要按照从前到后的方向累加 Irradiance，这一步用 Compute Shader 算，每一个 Thread 对应 XY 平面上的一个像素，完成累加后再按屏幕空间采样最后一个 XY 平面就是最终的 Irradiance。\n最后是做 Bilateral Blur，这一步只在次时代主机和高端 PC上做。其实就是分别在 XY 两个方向上单独做高斯模糊，X 方向上做完 Blur 之后会输出转置的图像，然后 Y 方向做完后会再转回来，这样可以优化纹理的读写效率（没搞懂原理，应该是提升 Cache 命中率吧）。\n采样的时候 Light Shaft 会有一些 Artifacts，Bilateral Filtering 能减缓这种现象但是不能根治，为了解决这个问题，对 Shadow Maps 做了降采样和模糊。\n对 Cascade Shadow Maps 先做一次 1/4 降采样，然后做一次 Blur，接着再做一次降采样，然后变成之前的 1/16，这时候计算体积效果的时候再采样这张 Shadow Maps 会非常快，同时还不会出现之前的 Artifacts。\n没有雾的时候的效果。\n最基本的版本。\n加了 Bilateral Blur 之后的效果，Artifacts 少了很多，但还是存在。\n对 Shadow Maps 再做 Blur 之后，基本就看不出来了。\n目前位置，还没有提到怎么应用云雾效果。为了节省带宽，大气云雾都是同时在屏幕空间内计算的。这样还很容易就可以把云的阴影注入到雾的 Irradiance 计算中，同时可以表现出透过云的 Light Shaft 效果。\n在整合阶段，还叠加了更多的蓝噪声，然后依靠 TAA 来糊一下，以达到更好的效果。\n接下来是反射。反射在体现湿度这一特点上至关重要。FarCry6 的反射用的是混合方案，有屏幕空间的反射 SSLR 也有硬件光追反射。\n屏幕空间反射有个问题，就是在某些视角下，压根就没有能反射的颜色信息，这时候就要 Fallback 到使用 Cubemap。这些用于 Fallback 的 Cubemap 是美术挑了一些固定场景进行 Bake，然后在运行时加载并进行 Relighting，在 Bake 下来的 Cubemap 上再添加天空云雾，最终再用于反射。\nCubemap Bake 的时候存的是 Albedo、Normal、Smoothness 和低分辨率的 Depth，然后在运行时做 Relighting，为了节省性能，除了渲染过场动画，基本上每一帧只更新 Cubemap 的一个面。\n每当 Streaming 地图新区块的时候，就会运行时做 Relighting，Relighting 的时候会先渲染一张 Sky Only 的 Cubemap，里面只包含天光、云雾，这张图会直接用作海面反射的 Fallback，然后会使用 Bake 下来的这几张纹理 Relit Scene，最后再把 Sky Only 和 Relit Scene 拼在一起得到最终的 Cubemap 作为场景整体的反射 Fallback。\n阴天的光照看起来有一些问题，不够黑，看起来很平，美术想要云和天空之间有更强的对比度。效果变成这样有很多原因：\n首先是制作的天空本身就看起来太灰暗、浑浊了，这个是首先要修改的地方。 然后就是雾的原因，修改方法是根据云层覆盖率对雾做 Fade Out。 因为云层没法达到地平线，然后 Cubemap 在地平线附近会有蓝色的亮带导致天光太亮。 然后是云层密度太均匀了，看起来就很扁平，这个也很好改，在风暴天气时限制积云覆盖率就行了。 最后是大气散射没有阴影。 下面介绍雨的实现，FarCry6 中的雨是基于 GPU 粒子实现的。\n整个 Particle System 的 Overview，粒子的 Emit、Simulate、Sort 和 Render 都是在 GPU 完成的。\n排序跟别的 GPU 粒子系统一样，用的是 Bitonic Sort，就是每一轮排序每个线程调换对应的两个数据，所有数据排序下来用了 37 个 Dispatch。\n粒子渲染会在六个不同的 Pass 做，所以要对粒子做过滤，用的 Prefix Sum Filtering 算法（没看懂在干嘛）。\n下面看雨水的粒子特效，首先是雨滴效果。开始尝试了折射、模糊、反射效果，最终还是直接用了半透纹理来做粒子，用到的纹理就是右下角的 Albedo 和 Normal。粒子 Emit 的范围就是玩家周围的一个圆柱体，超出范围就回收，所以无论相机移动多块，粒子的数量都是一致的。\n为了让画面看起来更自然，还用了 3D 纹理对粒子做扰动，这张 3D 纹理同时也被用在了体积水和体积雾上。雨水粒子 Emit 的方向和速度取决于天气和风速。\n因为有很多室内室外组合的场景，这时需要对雨水做遮挡，不然室内下雨就会穿帮。做法是把雨水当做一个方向光，然后按照雨水的方向去渲染阴影来判断遮挡。Shadow Map 的存储跟游戏中的普通方向光源一样，用了 Altas，貌似是类似 Virtual Shadow Map 的东西。\n另外一个雨水的粒子特效是雨水滴落到表面上时造成的飞溅效果。早期这个系统就是当雨水粒子与 Depth Buffer、地形、雨水产生撞击后就 Emit 一个新的粒子来做溅射效果。但是这样的话任何不透明的物体都会触发这个效果，一些地方就会很奇怪，比如建筑的侧表面，为了解决这个问题引入了斜率来判断。\n另外就是不是所有的雨水粒子都能触发这个事件，所以效果不太明显，所以又在相机周围加了额外的雨水粒子。\n下面是雨水的照明，本来希望是用 Pixel Lighting 的，但是实在太费了，就改用了 Vertex Lighting，这样效果又不够好。\n后来就改成了为粒子的每一个顶点生成一个球谐探针，每一个球谐探针都会根据周围的各种光源计算一个三阶球谐系数。最终效果会比 Vertex Lighting 好很多，而且还可以结合 Normal 获得更精确的高光。\n下面是闪电的粒子效果。为了实现闪电这种丝带的效果，做了一套叫 Tessellated Ribbon Emitter 的系统，在一个圆柱体内从上大小发射粒子，然后在断点之间添加扰动，就会得到图中的这种效果。但是这样看起来还是不够真实。\n想要更真实的话，雷电要能有光照效果。具体实现是先 Spawn 一个全局的光来照亮场景，然后是云层需要被闪电影响。闪电本身是一个圆柱形的光源，对云层的光照效果需要放到上采样 Pass，不然会因为 Temporal Filter 产生鬼影。然后为了决定把光源放到什么位置，这里用了 Sun Scattering Factor 来计算，这个值会在 Raymarching Pass 时保存到 Attachment 的 G 通道。\n下面是海洋。天气有两种方式影响海洋，一种是风级，另外一种是风向。用 Screen Space Tessellation 会有一些限制，有海岸线波浪问题，然后就是远距离看 Tiling 图案太明显了，所以 Screen Space Tessellation 只拿来做淡水效果。\n海水的话用了一种新的 Tessellation 技术，叫 SUBD。\n下面介绍一下这个算法，其实就是在三角形找找中线不断划分。这个算法是渐进式的，每一帧都会按照相机距离不断地进行细分和合并。可以看到图中离相机最近的部分每个 Quad 有四个三角形，紫色的部分就自由两个三角形了。\n细分和合并的控制是用编号来做的，可以看到图中的灰色三角形，在细分之后会变成 01 两个三角形，一直细分下去就会得到图中这些带编号的三角形。然后每两个三角形合并就会减少一位。这里说他们有个没解决的问题是处理这些编号的生成，最后用了跟 GPU 粒子类似的并行前缀和的算法。\n新的 Tessellation 需要跟 Screen Space Tessellation 做 Blend，对水面做 Displacement 并且在交界处做过渡。\n风级 0 的海面。\n风级 1。\n风级 2。\n风级 3，到了风级 3 之后还可以控制波浪的振幅、频率、数量等。\n风级 4，增加了泡沫的选项。\n用了几张 Texture 来模拟海浪，这些 Texture 每帧都会更新，而且可以回读回 CPU 做物理计算，但是因为性能限制没有开这些功能。首先是两张 World Space 的 FBM 纹理，用来在相机附近产生尖锐的波浪，之所以用世界空间是因为可以直接从 Displacement Texture 生成 Normal Texture，这样可以获得更好的细节。远处的波使用的是 FFT，这两张纹理可以受到风的影响，另外为了防止远处看起来 Tilling 图案明显，留了一个通道做累加，然后使用的时候还会拿两张 FFT 做 Cascade 并叠加 Perlin 噪声，进一步降低重复度。\n这是只有 FFT 的海面效果。\n多级 FFT 叠加之后能消除一些 Tiling。\n再加上 Perlin 噪声之后 Tiling 基本就没了。\n海岸线的波浪。通常是可以用粒子来模拟的，但是游戏中海岸太多了，手摆效率很低，需要程序化生成。在程序化生成的时候会根据海洋和陆地区域自动推导出什么地方需要摆这种波浪，这种波浪用 Gerstner Wave 公式生成，给了一些用于控制视觉效果的参数，振幅、坡度、速度、强度等。最后还给波浪加了一些噪声，不然看起来就是完美的原形波。理论上来说这套系统支持五层波浪，但是最后只用了一层。\n树的弯曲。树受到强风影响之后会产生弯曲，这个表现效果很直观，受控于风的方向和强度。这些树本身是 Skeletal Mesh，在受到风影响之后会修改树的形态，表现出在风暴中夸张的姿态。但是有时候运动会超出 Bounding Box，然后导致一些剔除上的错误，因为这个 Feature，把这些树的 Bounding Box 都调大了一些，然后只对近处的树开这个 Feature。\n总结。\n","date":"2022-09-03T00:00:00Z","permalink":"https://www.kindem.xyz/post/57/","title":"GDC 笔记 - Simulating Tropical Weather in FARCRY6"},{"content":" 原文链接：GDC 2022 - FidelityFX Super Resolution 2.0\nAMD FSR 2.0 版本，相对 FSR 1.0 架构上有较大改动。\n先回顾下 FSR 1.0，FSR 1.0 推出于 2021 年七月，是 AMD 推出的空间域超分解决方案，高性能，易集成，比价友好的 MIT License，已经在很多游戏中被集成了。\n因为 FSR 1.0 是基于空间域的超分算法，好处就是很容易集成（直接挂在后处理最后就行了），但同时也有一些缺陷：\nFSR 1.0 的输入需要经过高质量的抗锯齿处理，这个问题就算是不考虑超分，也是一个比较头疼的问题，把 FSR 1.0 挂在低质量的 TAA 实现后面就会产生质量很差的输出，这意味着如果游戏没有实现抗锯齿就集成 FSR 1.0，就要花上更多的时间。 超分的质量取决于输入图像的分辨率，如果输入图像的分辨率太低，就没有足够的信息来重现细节，太低的分辨率还会导致一些画面的缺陷，比如闪烁、边缘模糊等，这种情况通常在使用 Performance 模式时出现。 FSR 2.0 是下一代超分解决方案，不再基于空间域，而是基于时空域。FSR 2.0 与 FSR 1.0 并不兼容，需要不同的输入，并且直接内置了抗锯齿。质量要比 1.0 更高，提供了不同的 Quality Mode，同时支持了动态分辨率。跟 FSR 1.0 一样的是开源、跨平台、高度优化，不需要硬件支持的深度学习（内涵 DLSS），以 C++ / HLSL 库的方式提供 API，并且可以随意定制。\n算法介绍。\nFSR 2.0 的输入和 1.0 不再一样，输入为渲染尺寸的 Color、Depth、Motion（像素相比前一帧的位移）。与之对比，FSR 1.0 只有 Scene Color。\nRenderGraph。\nFSR 是基于 TAA 的，TAA 大家都比较熟悉了，对每一帧的像素进行抖动，在多帧间累加不同的采样点，从而达到多采样的效果，采样点越多，最终抗锯齿的效果就会越好。Jitter 序列的质量会直接影响到最终的效果，所以 Jitter 序列需要在时空域上有良好的分布，这样地分辨率的输入图像中的每一个像素都能在 Jitter 之后被采样点均匀覆盖。虽然理论上 Jitter 序列的长度是可以无穷大的，但是为了处理 Thin Features （后面会提到），FSR 2.0 在 Jitter 序列长度的设定上有一些自己的考虑。\n每一个历史帧的采样点对新一帧的像素都会产生影响，但是采样点是有自己的权重的，取决于两个要素：\n采样点与目标像素的空间相关度（也就是距离），距离越近，权重越高。 采样点与目标像素的时间相关度（采样点所属历史帧的年龄），年龄越小，权重越高。 如图所示，灰色方块表示一个像素，红点为像素中心，蓝点为采样点，第 N - 1 帧的采样点很靠近像素中心，理所当然要被纳入考虑范围，而第 N 帧的采样点虽然离得比较远，但是因为年龄较小，所以也有一定权重。\n第一个公式是新采样点与已经计算好的像素颜色混合的公式。S 是新增采样点，H 是已经累加的历史颜色，alpha 是混合的权重。 第二个公式是混合权重的计算公式，omega 是新增采样点的空间域权重（距离），tau 是该像素的空间域总权重。要注意的是这个公式中实际上并没有引入任何时间相关的变量，所以历史采样点在时间域上的空间都是一样的，但是因为历史采样点的权重在分母，会被新加入的采样点不断稀释，从而达到强调新加入采样点的目的。 在 FSR 2.0 中，输入图像是低分辨率的，输出图像是高分辨率的，所以中间有上采样的步骤。一个灰色方块还是一个像素，灰色的点代表输出的高分辨率像素的中心，蓝点代表 Jitter 得到的采样点。上采样的过程主要是使用 Lanczos 插值算法。\n一维 Lanczos 插值公式中，a 表示核的大小。x 为输入，L(x) 为输入点的权重，二维 Lanczos 公式就是分别在 x,y 方向上做两次。\n在 FSR 2.0 中，对于每一个目标像素 P，都使用核为 2x2 的二维 Lanczos 公式进行插值，所有参与最终混合的采样点的权重都通过 Lanczos 公式计算。\n从低分辨率到高分辨率需要更锐利的采样，在原有公式的基础上添加了一个系数 belta，用于对二维 Lanczos 函数的 xy 轴分别做缩放，belta 根据局部的 Luminance Stability （应该就是边缘度?）计算得到。\n上面的 Upscaling 流程做了一个基本假设，就是输入图像在时空域上是静态的，所以为了处理动画，需要引入 Motion Vectors。 Motion Vectors 描述了采样点如何从前一帧移动到当前帧。Motion Vectors 必须取消 Jitter，这样当图像静止的时候，Motion Vectors 也应该为 0。 为了正确地跟随边缘，很多基于 TAA 的解决方案都会取 3x3 领域中最近的值，之后会详细说。 如图所示，通过 Frame N - 1 和 Frame N，可以计算出来箭头所示的 Motion Vectors。\n在场景运动时，前一帧的颜色信息需要重投影到当前帧。具体是根据 Motion Vectors 来计算采样点的历史位置，并且将其投影到当前帧，这一步依然使用 Lanczos 算法，在 Upsample Stage 完成。\n有些情况下历史帧的数据跟当前帧已经没有任何关系了，这时候将历史帧的信息投影到当前帧就会有鬼影问题（无用的历史颜色信息在当前帧可见）。常见的情况有 Disocclusion、Shading Changes （光照变化、纹理变化）等。如图所示，机器人的爪子部分有鬼影。\n针对这些情况需要单独处理，首先是 Disocclusion。通过比较当前帧的深度和重建得到的历史帧深度得到一张 Disocclusion Mask，然后通过 Disocclusion Mask 来检测 Disocclusion。\n重建历史帧深度的流程：\n将当前帧深度的采样点重投影到历史帧 Gather 周边的四个点，将他们都设置为当前帧的深度 重复上述过程，每个像素如果同时受多个当前帧像素的影响，取最近的深度作为最后的结果 Disocclusion Mask 使用的具体方法：\n对于每一个采样点，我们可以得到当前帧的深度 D 和前一帧的深度 Dp 设置一个容忍度 MinDepthSep 如果 Dp - D \u0026gt; MinDepthSep 我们就认为产生了 Disocclusion 有了 Disocclusion Mask 就可以做历史颜色矫正了，需要先声明的一点是所有的矫正都只使用当前帧的信息，因为历史帧的信息可能会导致鬼影，违背了矫正的目的。\n如果检测到了某个采样点产生了 Disocclusion：\n首先需要丢弃绝大部分历史累积的颜色。全部丢弃会让画面看起来不那么平滑，所以还需要保留一小部分历史颜色，这会产生微小的鬼影，不过一般不是这么容易被注意到。 对于新加入的采样点，需要对其做 Blurred，这是前面 Upscaling Stage 就完成的，就是在计算权重的时候稍微减小 belta 的值。 前面说到除了 Disocclusion，Shading Changes 同样也会导致鬼影。就算是错误的，历史帧的信息依然有一定价值，所以我们不能简单地将其丢弃，而是在当前帧 3x3 的邻域中将所有颜色映射到 Lunminance/Chrominance 空间，然后计算一个 Clamping Box，再将错误的历史帧颜色 Clamp 到范围内，接着使用。\n另外一点需要注意的是细微特征的处理。这种细微的特种在 Jitter 序列中获得的采样点信息并不足够，所以前面提到的颜色矫正会把他们当成 Shading Changes 干掉，比较常见的常见是 Specular 高光。这个问题就会导致输出图像不稳定，部分位置比较模糊，如图所示，右图的扶手部分放大了看就出现了着色不足的现象。\n对于细微特征需要单独处理一下：\n检测像素的起伏并且锁定突兀的像素 被锁定的项目在颜色矫正阶段会获得更高的权重，以免被干掉 一旦某个像素被锁定，在整个 Jitter 序列中，锁都会持续生效，可以通过老化机制隐式地移除超出生命周期的锁。Jitter 序列要在保证效果的同时足够短，以便锁可以尽快释放。\n在产生 Disocclusion 或者 Shading Changes 后，锁就不再有效了。像前面说的一样通过老化机制来移除锁肯定是不够快的，此时就会产生鬼影。如图所示，黄色的拖影就是未能及时释放的锁。我们需要显式地检测这些锁并及时释放他们。\n对于 Disocclusion，同样可以使用前面提到的 Disocclusion Mask 来处理 对于 Shading Changes，在局部、低频空间对锁定颜色和新颜色进行亮度比较，如果差值大于一个规定的阈值，就把锁干掉 因为通常 FSR 2.0 是在 ToneMapping 前，会遇到另一个 TAA 解决方案中常见的问题，Firefly Artifacts，产生的原因是拥有较大 HDR 颜色值的采样点参与多采样时，其对最终效果的影响会远远大于其他采样点，从观感上来看表现为边缘的走样。FSR 2.0 用了跟其他 TAA 解决方案类似的处理方法，即 Local Reversible ToneMapping。\n一个示例 Shader，简单来说就是在多采样输入时先进行一次带权重的 ToneMapping，降低高强度 HDR 值在结果中的占比，计算完再对输出进行一次 ToneMappingInvert 还原回去。因为计算完还会还原，所以 FSR 2.0 在内部做的 ToneMapping 对用户是无感的，整个输入输出都还是 HDR。这个功能在 FSR 2.0 Pipeline 中是可选的，需要手动配置开启。\n另外一个 HDR 相关的话题是两个会影响到 FSR 2.0 输出质量的参数，一个是很多引擎会使用的预曝光，通常预曝光会持续到 ToneMapping Stage 被 Cancel 掉，这意味着它会影响到 FSR 2.0 的输入，因为 FSR 2.0 会使用到历史帧的数据，而预曝光参数有可能在帧间变化，所以需要把这个参数传递给 FSR 2.0 使其能够做出一些调整。另外一个参数是曝光度本身，也是类似的原理，如果引擎没有曝光度，FSR 2.0 也可以添加一个自动曝光 Pass 来做相关的处理。\nDRS，动态分辨率缩放，可以让游戏引擎根据当前负载动态调整渲染分辨率，使其即便在负载比较高的情况下也能输出一个效果较好的渲染结果。FSR 2.0 天生就支持 DRS，因为 FSR 2.0 内部的绝大部分工作都只依赖渲染分辨率的输入，而所有需要持久化保存的数据（如 Pixel Locks）都按照显示分辨率保存，所以无论输入分辨率怎么变化其实 FSR 2.0 都能处理。如图所示，连续几帧画面的分辨率各不相同，最终的输出分辨率都是一致的。\nFSR 2.0 跟 FSR 1.0 一样在 Upscaling 之后会提高一个 Sharpening Stage 来做锐化提高画面细节，依赖的是 AMD 的另外一个技术 RCAS。\n讲完了算法，接着讲一下优化部分。\n首先是前面提到的 Local Reversible ToneMapping，在 FSR 2.0 Pipeline 中的很多地方都使用了 Local Reversible ToneMapping，用于处理输出数据提高输出质量。早期的实现版本中一些 ToneMapping 操作是 Per-Sample 的，而且有很多采样相邻像素的操作，占用了大量的 ALU 资源。优化的目标是接近 Per-Pixel，释放 ALU 资源给其他的计算。\nFSR 2.0 算法非常依赖显存带宽，所以提升 GPU Cache 命中率很重要。对于 4k 场景来说，数据量远远超过了 GPU 的可用 Cache，就算是拥有 Infinity Cache 技术的最新架构 RDNA2 都没法 Cover。为了解决这个问题，FSR 2.0 会把单个大的 Compute Shader Dispatch 指令拆分成多个小的 Dispatch 指令，来提高 Cache 命中率。\n在 AMD Radeon RX 6800XT 上 L0 Cache 命中率有 37% 的提升。\n按照之前说的，FSR 2.0 提供了自动曝光选项，以便在引擎不提供曝光度输入时自动计算输入图像的曝光度，这部分计算有一定开销。最开始这部分计算效率是比较低的，使用了单线程 Dispatch 或者 1x1 RenderTarget 的 PixelShader，GPU 利用率很低。优化的方法是使用 AMD 的另外一个技术，Single Pass Downsampler，SPD，SPD 通常用于高效地对图像进行连续降采样，比如 Mipmaps 的生成就可以使用。SPD 具有可配置的 Kernal，可以将 SPD 配置成降采样到单个像素来计算曝光度，从而提高性能。1080p， 6800XT 仅需要 17us 来计算曝光度。\n之前说了上采样的时候会使用 Lanczos 插值来计算采样点对最终像素的贡献权重，Lanczos 公式还是比较费的，尤其是在老的硬件上。优化方法是在保证质量的基础上沿袭 FSR 1.0 的做法，对 Lanczos 公式做一个近似，这样可以减少 ALU 压力，另外就是把 Lanczos Look Up Table 做成一张 LUT Texture 来加速 Lookup，这两个优化在自家硬件上都还有额外的效果。\n在 RNDA 架构中，GPU 可以在 Wave32 和 Wave64 两种模式下运作（GCN 架构只有 Wave64）。通常情况下 Wave32 模式要比 Wave64 模式更快，因为延迟更小。但是在一些特殊场景下 Wave64 模式会更快。默认情况下 FSR 2.0 的 Shader 在 Wave32 模式下工作，但是 FSR 2.0 的一些运算在 Wave64 模式下会工作地更快。\n实测下来强制 Wave64 模式 FSR 2.0 的不少 Stage 都有更高的收益。在 Shader Model 6.6 下，可以在 Shader 源码中指定使用哪种模式，在 FSR 2.0 正式开源后，开发者可以根据自己的需要选择哪种模式运行。\n因为 FSR 2.0 是跨平台的，需要支持各种各样的 GPU，这样自己 RDNA2 架构上的优化在别的 GPU 上有可能是负优化。所以在别的 GPU 上运行时，会做一些 Fallback，有一些优化不会开启，比如 Wave64 模式就只在 AMD GPU 上默认打开。集成 FSR 2.0 的时候可以直接使用 AMD 的推荐配置，可以帮助根据硬件自动选择最佳参数，FSR 2.0 在性能上肯定是很能打的。\n2022 年 3 月 FSR 2.0 Beta3 版本几种模式下的性能数据，4k Quality Mode 只需要 1.1ms，还是很可观的，类似的超分算法 DLSS 就要差很多，而且这个时间还是可以 Cover TAA 的开销，还是很可观的。\nFSR 2.0 的集成。\nFSR 2.0 设计的一大目标就是良好地兼容性：\n支持所有 GPU 不依赖 ML 硬件 支持老的 GPU 架构 另外还会提供 DX12、Vulkan 的 Samples，提供 UE4.26 和 UE4.27 的插件，提供 Xbox GDKX 的 Samples，无论是什么平台，FSR 2.0 都能完美集成。\n因为 FSR 2.0 的工作流很复杂，所以专门设计了一套 API 来便于开发者方便地集成。\nFSR 2.0 提供了可以直接链接的 Windows 库，当然同时也会在 GPU Open 开源所有的 C++ 代码，也可以在其他平台上手动编译集成。跟 FSR 1.0、NIS 比较类似，使用 SDK 可以直接获取最佳参数，然后直接传入 Shader 就可以了。 SDK 的 API 有三个主要接口，ContextCreate、ContextDestroy、ContextDispatch，然后还提供了一些接口用于获取 JitterPhaseCount、JitterOffset、RenderResolution、UpscaleRatio 等。 给了一些集成的参考时间，像已经集成了 DLSS 2.0 的游戏最快只要三天就能搞定，其他集成的工作量视情况而定，最慢也只需要约 4 周左右。\n按照之间说的，FSR 2.0 在集成时是直接替换 TAA Stage 的，关闭 FSR 2.0 时需要打开 TAA，打开 TAA 就需要关闭 FSR 2.0。另外 FSR 2.0 还提供了一个 TAA-Only 模式，只开启 TAA 不做 Upscaling，方便直接切换。\nFSR 1.0 在一帧中的位置是后处理的最后阶段，而 FSR 2.0 不一样，它处于整个 Pipeline 比较早期的阶段。因为是替换 TAA，所以所有需要抗锯齿输入的后处理都应该放到 FSAR 2.0 后面，所有需要 Depth Buffer 的后处理都要放到 FSR 2.0 的前面。\nFSR 2.0 的 Buffer 输入只有当前帧的 Depth、Motion Vector、Color，不需要开发者传入任何历史帧的信息，FSR 会在内部存储上一帧的 Output Buffer。\nFSR 2.0 对 Depth Buffer 是有一定要求的，Reversed、Infinite Farplane、R32_FLOAT 精度，这样的话可以达到最佳效果，如果集成时 Depth 不能满足条件的话，也可以在创建 Context 的时候通过修改 FLags 来进行调整。\n类似的，对 Motion Vector Buffer 也有要求，需要 UV Space 的 2D Vector，是一张单独的 Buffer Resource、至少需要 R16G16 精度（R8G8 不能满足精度需求），还要就是需要保证所有的场景元素都要在 Motion Vector Resource 中。类似的 Motion Vector 也有控制的 Flags，可以根据需要调整。如果需要进行一些其他的定制（比如做一些定制化的 RT 合并）可以自行修改源码。\n最后是 Color Buffer，对于 LDR Pipelines，推荐使用 Linear Format 但不是必须的。对于 HDR Pipelines，输入必须是 Linear RGB，PQ / HLG 不太适合作为输入格式，另外输入颜色值不能为负数，需要 Clamp 到 0 以上。使用 HDR Pipelines 需要在创建 Context 指定对应的 Flags。另外就是自动曝光，如果需要启用自动曝光的话传入对应的 Flags 就行了，如果引擎本身就做了自动曝光的话，把对应的 Shader Resource 传入即可。\n另外一项配置是 Jitter Patterns，推荐的 Jitter Patterns 是 Halton(2,3)，在 FSR 2.0 SDK 中提供了相关的接口用于获取 Jitter Offset。要注意的是 Halton 序列长度随着会 Scaling Ratio 不同而产生变化，下面是一个对照表，序列长度可以通过 ffxFsr2GetJitterPhaseCount 获取。\nDRS 可以使用 Flags 开启，上面一页我们知道 Jitter Sequence Length 会随着 Scaling Ratio 变化而变化，ffxFsr2GetJitterPhaseCount 的入参是渲染分辨率的大小，所以每一帧得到的 Jitter Sequence Length 是不同的。Jitter Phase Id 不会立即清零，等到 Id 跟 Length 相等时就会归零重新开始，这样新的 Length 就生效了。\nMip Bias 在 Upscaling 时也是一个很重要的参数，因为以渲染分辨率渲染会导致纹理在被渲染时使用比较高的 Mip，这样再进行 Upscaling 之后就会出现失真的情况。所以我们需要计算一个负的 Mip Bias 来让纹理被采样时使用与目标分辨率匹配的 Mip。公式也很简单，就是 RenderResolution 与 DisplayResolution 的比例 - 1，右边是 Quality Mode 所对应的 Mip Bias。有一点需要注意的是表现出高频细节的纹理需要把 Mip Bias 设置成 0，否则经过 TAA 处理后会出现闪烁现象。\n前面已经提到了，FSR 2.0 有一个可配置的锐化 Pass，叫做 RCAS，默认情况下，RCAS Pass 是关闭的（FSR 1.0 是默认开启的）。RCAS Pass 可以配置一个锐化强度参数，参数范围为 0.0 → 1.0（与 FSR 1.0 相同），在 ContextDispatch 时传入。上面两张图是开关 RCAS 的对比，可以看见右图细节明显要清晰很多。另外一点要注意的是，如果单独使用了 AMD 的 RCAS，在集成 FSR 2.0 之后需要关掉，同时只需要启用一个 RCAS Pass 即可。\nFSR 2.0 SDK 还在 ContextDispatch 的参数中提供了一个 boolean 用于重设所有历史帧，通常用于大面积的场景切换后防鬼影，比如主场景与过场动画的切换。\n前面说的都是 FSR 2.0 SDK 的使用方法，由于 SDK 本身是开源的，在集成时可以对 API 做各种自定义修改，比如前面提到的把 Motion Vector 跟其他 RT Pack 到一起。\n跟 DLSS 类似，对于 UI、各种语言的选项描述，FSR 2.0 也有一套官方的 Guidline。\n总结一下：\nFSR 2.0 相比 FSR 1.0 有着更高的质量，基于新的 TAA 算法。 FSR 2.0 提高了容易使用的 SDK，如果已经集成了 DLSS，集成 FSR 2.0 是很容易的一件事，另外 FSR 2.0 完全开源，支持各种硬件。 关注 GPU Open 的新消息。 DLSS 在 4k 下其实还是挺耗的，而 FSR 2.0 效果不错，在 4k Quality Mode 下都只需要 1ms，还能把 TAA 的开销也给省了，论集成友好度和兼容性也远好于 DLSS，看起来还是挺香的。\n","date":"2022-09-02T00:00:00Z","permalink":"https://www.kindem.xyz/post/56/","title":"GDC 笔记 - FidelityFX Super Resolution 2.0"},{"content":"CryEngine5 Shader 调试 CryEngine5 跟 UE 一样，默认情况下 Shader 的符号表是隐藏了的，用 RenderDoc 抓帧之后是没法直接进行 Shader 调试的：\n这时候需要启用 Shader 符号表并重新编译 Shader，首先找到引擎根目录，打开 system.cfg 文件，在最后加上下面几行：\nr_ShadersEditing=1 r_ShadersDebug=3 r_ShadersRemoteCompiler=1 r_ShaderCompilerServer=127.0.0.1 r_ShaderCompilerPort=61453 然后进入 Tools/RemoteShaderCompiler 目录，打开 config.ini，确认端口号跟上面的一致。确认无误后打开同目录下的 CrySCompilerServer.exe出现下面字样 Shader 编译服务器就成功启动了：\ncaching enabled Ready 找到项目目录（有 .cryproject 文件的目录），进入 user/shaders/cache/d3d11 目录把下面所有文件都删了，清空 Cache 以便 CryEngine 识别并重新编译 Shader。\n最后重新进入 Sandbox，随便打开一个 Level，可以看到 Shader 编译器服务器已经开始重新编译所有 Shader 了：\n1094 | 24/04 16:35:30 | Updating: GameSDK/ShaderList_PC.txt 1786 | 24/04 16:40:20 | Compiled [ 1128ms| 22s] (D3D11 vs_5_0) Common_SG_VS 1788 | 24/04 16:40:21 | Compiled [ 1156ms| 24s] (D3D11 vs_5_0) Common_SG_VS 1790 | 24/04 16:40:22 | Compiled [ 1174ms| 25s] (D3D11 vs_5_0) Common_ZPassVS 1792 | 24/04 16:40:24 | Compiled [ 2068ms| 27s] (D3D11 vs_5_0) Common_SG_VS 1794 | 24/04 16:40:27 | Compiled [ 2452ms| 29s] (D3D11 vs_5_0) Common_SG_VS 1796 | 24/04 16:40:29 | Compiled [ 2523ms| 32s] (D3D11 vs_5_0) Common_SG_VS 1798 | 24/04 16:40:32 | Compiled [ 2523ms| 34s] (D3D11 vs_5_0) Common_SG_VS 1800 | 24/04 16:40:34 | Compiled [ 2419ms| 37s] (D3D11 vs_5_0) Common_ZPrePassVS 1804 | 24/04 16:40:34 | Compiled [ 51ms| 37s] (D3D11 ps_5_0) Common_CustomRenderPassPS 1806 | 24/04 16:40:35 | Compiled [ 152ms| 37s] (D3D11 ps_5_0) IlluminationPS 1808 | 24/04 16:40:36 | Compiled [ 1364ms| 38s] (D3D11 ps_5_0) IlluminationPS 1810 | 24/04 16:40:36 | Compiled [ 84ms| 38s] (D3D11 ps_5_0) Common_DebugPassPS 1812 | 24/04 16:40:37 | Compiled [ 953ms| 39s] (D3D11 ps_5_0) IlluminationPS 1814 | 24/04 16:40:38 | Compiled [ 1012ms| 40s] (D3D11 ps_5_0) IlluminationPS 1816 | 24/04 16:40:38 | Compiled [ 109ms| 40s] (D3D11 ps_5_0) Common_ZPassPS 1818 | 24/04 16:40:39 | Compiled [ 555ms| 41s] (D3D11 ps_5_0) Common_CustomRenderPassPS ...... 完成编译后再使用 RenderDoc 重新抓取，再编辑或调试 Shader 就能看见源码了：\n我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=2lqleka8dkysc\n","date":"2022-04-30T00:00:00Z","permalink":"https://www.kindem.xyz/post/55/","title":"CryEngine5 Shader 调试"},{"content":"SSDO 全称 Screen Space Directional Occlusion，可以看做一种实时 GI 算法，是 SSAO 的升级版。\nAmbient Occlusion (AO) 即环境光遮蔽是一种常见的提升表面细节的技术，基本思路是在 Mesh 表面预计算周围的遮挡信息，然后在计算光照的时候把遮蔽因子作为系数叠加到环境光上。遮蔽因子计算也比较简单，就是在表面上的一个半球区域内发射一系列射线，然后同级被遮挡的光线的数量即可。应用 AO 后，可以明显看到，表面的拐角处会变得更黑，从而体现出更真实的效果。\nAO 的计算比较耗，通常会为 Mesh 离线计算 AO 纹理，然后在运行时采样直接使用，下面这三张图分别是直接光照、AO 纹理、应用 AO 后的光照：\n因为 AO 纹理是预计算的，所以对于动态场景就没办法了。于是 SSAO (Screen Space Ambient Occlusion) 应运而生，在屏幕空间进行计算，在开销可以接受的情况下支持动态场景。SSAO 最早是 CryTek 提出的，并运用于自家的引擎 CryEngine 中，最初的 SSAO 算法是直接在屏幕空间表面的一个球形区域内随机进行一系列采样，然后把采样点的深度跟表面的深度相对比，如果在表面之下，则该采样对最终的遮蔽因子产生贡献。下面是盗的 LearnOpenGL 的图：\n但是这种算法实际效果不太好，会使得画面有一种灰蒙蒙的感觉：\n更好的做法是按照表面的法线取一个半球空间进行采样：\n这样效果会更好，但是无论如何，SSAO 有个致命的缺陷，就是它只考虑了遮挡关系，所以只能让拐角处 “更黑”，还是没办法记录光照信息。比如下面这张图，P 点附近有两个颜色不同的光源，按照遮挡关系，P 点应该会被绿光照亮，从而体现出绿色，而不是 SSAO 表现出来的黑色：\nSSDO 的提出就是为了解决这个问题，SSDO 在计算遮挡关系的同时还会考虑光照信息，从而让拐角处产生能带颜色的遮蔽效果：\n首先来看下 SSDO 怎么捕获直接光信息：\n我们在 P 点法线方向的一个半球空间中均匀散布一些采样点，用类似 SSAO 的方法，我们可以得知他们是在表面之上还是之下，如果在之上的话，就按照 P 点与采样点的连线方向采样 IrradianceEnvMap 即可，各个采样点的贡献累加后就是 P 点最终的直接光颜色。\n要提一句 EnvMap，EnvMap 原图保存的是 LatLong 格式的 Radiance（左图），对其进行高斯模糊可以得到一个小锥形区域内的 Irradiance（右图），我们在 SSDO 算法中采样的是右边这张图。\n上面是 P 点直接光信息的计算公式，没有 Latex 不好打公式解释，需要实现的朋友们自己看下论文原文吧，这里就放一放。\n我们可以看到加上了直接光信息后，体现出来的遮蔽效果是带颜色的，效果会比 SSAO 好很多。\nSSDO 可不光能搞定直接光信息，还可以从表面附近的其他表面获取反射过来的间接光（反射前是直接光）信息。看图中，对于所有被遮挡的采样点，我们都找到他们在表面上真正对应的点，然后根据表面的法线计算对 P 点贡献的间接光。\n公式如上。\n可以看到效果又提升了一个档次。\n总结一波：SSDO 是 SSAO 的后继者，要比 SSAO 效果更好但是更耗。在 SSAO 计算遮挡信息的基础上考虑了光照信息，可以对所有没有被遮挡的采样点计算一次直接光贡献，对所有被遮挡的采样点计算一次间接光贡献，最后得到带颜色的环境光遮蔽效果。\n","date":"2022-04-02T00:00:00Z","permalink":"https://www.kindem.xyz/post/54/","title":"GPU Pro 1 笔记 - Screen-Space Directional Occlusion"},{"content":" 原文链接：Quadtree Displacement Mapping with Height Blending\n目录\n下一代渲染的一些要素与目标。\n然而现实是现在的 Surface Rendering 差距甚远。\n地形的 Surface Rendering 是很费的，而且需要做混合，混合意味着不能拥有较高的几何复杂度。\nSurface 的几何细节包括体积、深度、各种频率的细节。他们结合起来可以产生一些其他的效果：深度视差、自阴影、光反应性。\nSurface Rendering 要实现光照交互依赖 Surface 的微观结构，目前已经有一些理论研究（比如烘焙 Terrance BDRF）了。要体现出几何的复杂性，可以通过修改三角面或者走光追。但是三角面相关的方法都比较费，比如直接增加面数，顶点的 Transform 和显存开销都会相应增加，更实用的做法是实用 Tessellation 在管线中倍增三角面。\n做这套方案的动机：\n应对不同的 Surface：地形、静态/动态物体 高性能：支持当前的硬件 最小化显存开销：开销与传统的 Normal Mapping 相当，能在当前的主机平台顺利运行 所以这套方案需要支持：\n获取任意角度下的精确深度 自阴影 AO 快速、准确的混合 效果对比图。\n现有的提高深度复杂度的解决方案无非两种：\n寻找真正的 Surface 的深度，即寻找 View Ray 和 Height Field 的真正交点 通过计算好的 Depth Offset 来进行光照计算 比如上面这张图，在无视高度细节的情况下交点实际上是错误的。\n正确的交点应该是图中虚线和 View Ray 的交点。\n一种做法是对 Height Field 数据做 Ray Tracing，这意味着额外的显存消耗。\nRelief Mapping (RM) 和 Parallax Oclussion Mapping (POM) 都是光追做法。\n传统的固定步长的 Linear Search Ray Tracing，可以看见 Tracing 的结果（实箭头的终点）和正确的交点还是有一定的误差。\nPOM 则是在 Linear Search 的基础上加了一次线性近似。\n如图所示，Linear Search 有一个问题，就是步长太长的话可能导致求交出错。\n上面这张图就是步长设置不对的情况。\n此外还有一些基于距离场的预处理的方案:\nPer-pixel Displacement with Distance Function Cone Step Mapping Relaxed Cone Step Mapping 因为是预处理，所以可以包含更多的信息来做一些额外的事情。\nQuadtree Displacement Mapping (QDM) 算法，用四叉树来存储到高度场基准平面的最小深度。\n四叉树结构简单，对应到硬件实现是 Mipmap 采样会更快、显存开销小。\n性能足以运行时生成。\n用 QDM 做 Ray Tracing 的时候需要从最高级 Mip 到最低级 Mip 遍历四叉树，最后用最低级 Mip 来计算交点。\n算法伪代码，获取当前位置投影在当前 Hierarchy_Level 中的最大 Depth，如果 Ray_Depth \u0026lt; Depth，就沿着 Ray 步进到最接近的交点，否则的话就降一级 Hierarchy_Level 重复上面的操作直到 当 Hierarchy_Level ≤ 0。\nQDM 的构建，由最低级的 Mip 往最高级 Mip 逐级构建，不过不能直接用硬件生成，因为每一级 Mip 要取低级 Mip 四个 Texel 的最大值。\n对照上面的算法来看图就容易理解了。\n最后再参考 POM 做一次线性近似。\nQDM Ray Tracing 是代数方式在进行求交测试，遍历的是离散数据。\nQDM 仍然有一些优化空间。\n因为 QDM 的 Level 0 是点采样即离散数据，这意味着越接近 Surface，效果越越差，需要额外的提升效果的手段，通常是用线性逼近求交（上面提到的那个）。\n正常 QDM 的时间复杂度是 O(log(n))，这还是不够快，所以需要限制最大的迭代次数。\nQDM 在一定条件下会退化成 Linear Search，典型的场景就是在特征边缘，Ray 已经达到了 Level 0，由于 QDM 没办法在遍历时往更高的 Level 走，所以 Ray 再往前算法就跟 Linear Search 没区别了。解决方案就是在穿越 Cel 的时候往上走一级。\nQDM 不能用传统的 MipMapping（猜测是 QDM 不能直接随距离变化，就算距离拉远了，还是需要一定程度的精度？）。相应的，需要根据当前的 Mip Level 来限制 LOD Level 的最大值。然后还需要动态地调整迭代上限（根据 Normal 和 View 向量的夹角）。还有就是根据 Camera Space 的 Z 来调整 QDM Depth Fade 的比例（最远处就是只用 Normal Mapping 了）。\nQDM 本身其实是一个离散数据集（纹素），如果需要提高精度的话就要使用未压缩的纹理。当然如果能保证整数运算精确的话，是可以使用压缩数据的，DXT5 alpha 插值的误差就可以接受。\n总结下 QDM 的优点：\n任何场景下都是准确的 运算快、Scalable 额外显存消耗小 预处理快 可以调整迭代次数来平衡性能与质量 涵盖四叉树的其他优点 缺点：\n每次迭代中更慢了 使用 text2DLod 采样时是随机访问，在现在的硬件上很慢 Depth 跨度较小、分辨率较低时效果不够好 理论的时间复杂度。\n实际上达到收敛状态所需要的迭代次数，可见 QDM 远远强于 POM。\n下一页的数据展示了 POM 和 QDM 在实际游戏场景中的性能差异。CSM 和 RCSM 因为预处理时间的原因，不太适合实际游戏？\nPOM 与 QDM 的性能对比。\nDepth Scale 1.0 对比。\nDepth Scale 1.5。\nDepth Scale 5.0。\n极限场景下的测试对比。\nHeightMap 的一个特性就是可以在 Surface 上产生自阴影。计算自阴影的办法就是 ViewRay 与 Surface 的交点 P 能否从光的位置 L 被看见，要完成这个计算，可以从 L → P 的方向开始做 Ray Tracing，如果与 HeightField 相交，就说明 P 在阴影中。\n对照这幅图来理解。\n按照这种方法做 Ray Tracing 成本较高，每个采样点都要进行一次 Light Ray 的 Ray Tracing。我们可以转换下思路，通过计算水平可见性来获取自阴影（POM 那篇论文里的做法）。\n从 POM 原 Paper 那盗了张图，要计算硬阴影可以从 View Ray 的命中点出发，沿着 Light Ray 计算是否被遮挡，被遮挡则在阴影中。\n计算软阴影则可以从 View Ray 的命中点 h0 出发，沿着 Light Vector 在 Height Field 上做一系列采样，然后求出遮挡系数 hi，以最大的遮挡系数来求软阴影的值（图中的这个公式只是说明为什么这两者有关系，不是用来计算的）。\n再拿这张图跟上面那张图中 Blocker Height 的说明对比一下就清楚了。\n用 POM 计算软阴影的 Shader。\n开关的对比。\nQDM 版本的自阴影。沿 Light Ray 方向里 View Ray 命中点较远的采样可以用高 Mip 替换，可以进一步提高速度。\n跟上面的 Shader 对比一下就知道了，w1-w5 是给美术调整效果用的。\n保证质量的同时提速，o(n) → o(logn)。\n开关对比。\nAO，简单提了下，跟 Self Shadowing 的计算类似，也可以用类似的手法处理，并不需要每一帧都计算，只需要在 Height Field 变化时计算即可，对提升大世界地形的效果尤其有效。\nSurface Blending，主要用在地形渲染，就是 Alpha Blending 的泛化版，对每一种材质给一个权重，最后加权混合。他这里说的使用顶点色做权重，一般更常用的是提供一张单独的 WeightMap。\n在 Surface Blending 中一般不会采用 Alpha Blending，现实生活中的 Surface 不会这样 Blending，实际上在游戏中还是有用的，一般是用来做一些附着材质的标记，比如湿度、积雪度等。\n更常用的一种混合方法是 Height Blending，也是老生常谈的混合方式了，在 Weight Blending 的基础上加上高度，从而在混合的材质间产生穿插的效果。\n混合效果。\nHB 的一些特点。\n使用 HB 的时候对 Surface 会造成一定影响（修改其高度）。\n比如这张图，Height Blending 中的高度参数会对 Height Field 再进行一次修改。\n在使用 Height Blending 的情况下，搜索交点的这个过程会使用混合的结果来替代原本需要采样的高度，这时候使用顶点色来保存 Weight 会出现 Artifacts，想要得到正确的结果需要使用纹理来保存 Weight，这个应该大部分游戏都是这么做的。\n示意图。\n依靠距离的预处理数据，比如 DF、CSM，都不能在没有预计算的情况下跟 Blend Weights 搭配使用。依靠深度的预处理数据可以跟 Weights 配合使用。\n整了个 CQDM 来跟 HB 配合。\nQDM 和 HB 搭配使用的一些好处。\n展示。\n性能测试。\n效果对比。\n一些总结，还有一张效果图 \u0026hellip;\u0026hellip;\n主要有价值的内容在于 Self-Shadowing 那部分，不过这部分是 POM 论文里就已经提出来的东西，只是 QDM 的 Tracing 相较于 POM 的 Tracing 对于小于 Step 的 Surface 更友好，POM 的 Self-Shadowing 可能对于这种的就直接跳过了。\n","date":"2022-03-15T00:00:00Z","permalink":"https://www.kindem.xyz/post/53/","title":"GDC 笔记 - Quadtree Displacement Mapping with Height Blending"},{"content":" 原文链接：\u0026lsquo;Ghost Recon Wildlands\u0026rsquo;: Terrain Tools and Technology\n地图规格。\n11 种生态群落，140 种地表材质。\n河流面积与顶点。\n植被与石头。\n道路、贴花。\n铁路网。\n建筑与聚落。\nGPU 雕刻工具的介绍。\n基于 World Machine 开发了一套程序化生成的管线，用于自动生成高度图，作为后续地形编辑的 Input。\n美术规格。\n做了一个非常快速的 GPU-Based 的地形雕刻工具，最多可以一次雕刻 2km x 2km 的地块。\n对高度图做了分层，Base 层是 World Matchine 的输出，不会被改变，Editor 产生的修改被放到 Macro 层。DCC 层专门放置 Houdini 生成的修改，后面会具体讲。Micro 则存放关卡美术做的微小调整。\n地表。\n目标是生成真实、高质量的地表，然而这么大的地图纯手刷不可能搞定。\n尝试了一个简单的规则，按照地形的 Normal 做灰色到白色的插值，其实就能生成一个不错的山脉地表了，可以按照这个思路扩展地表的生成规则。\n最终定下来的用于程序化生成的参数有四个，坡度、高度、噪声、曲率，按照这几个参数在 Pixel Shader 里面实时计算。\n美术工具截图，修改参数就可以实时生成地表看到效果，非常方便。\n虽然现在可以一键生成地表了，但是有些过渡的地方还是显得不太自然。于是又支持了美术手刷地表。\n地表最终会被保存为两张纹理，分别叫 Splatting Texture (R8) 和 Vista Texture (BC5)，Splatting Texture 中保存了当前地表所对应的材质索引，Vista Texture 保存的是一个简单的 Albedo，用于远处地表的渲染。\n地块是按照四叉树存储的，每一个四叉树节点都带 Payload，包含 LOD、Culling、Streaming 信息。这些节点会根据距离相机的距离进行 Streaming In / Out。\n地表材质。\n地表材质当然包含经典 PBR 纹理。\n还包含一张 Displacement 纹理，用于地形曲面细分的。\n地表基本都是由四层材质混合的（Splatting Map 是双线性插值，所以是四层），所有地表材质一共有 143 种，所以一次把所有纹理加载进来是不可能的。\n做法是动态将地块用到的纹理合成一组 Texture2DArray，这里 Array 最多 32 层，也就意味着每一个地块最多只能使用 32 种材质。由于是动态合成的 Array，在 Shader 里还会有一次 Index 的转换。\n近景渲染。\n先看最终效果，下面会依次分析渲染流程。\n先看单个地表材质（点采样）的渲染，因为只取了一种材质的纹理，所以看起来是格子状的。整个流程是先去采样 Splatting Texture 拿到 Material Index，然后拿到 Material Index 转换到 Texture Array Index，然后再采样 Texture Array 拿到材质的纹理进行渲染。\n实际上渲染当然不会只做一次点采样，实际上对 Splatting Texture 进行采样的时候会借助双线性插值的思想，取相邻的四个像素取得四个 Material Index，然后根据离临近像素的距离来做权重混合。\n最终效果就会好很多。\n老生常谈的 Slope 渲染问题，因为地表纹理的 UV 变化是按照世界空间的 x 和 y 来的，在比较陡峭的地方变化就会很剧烈，导致拉伸，处理方法一般是 Tri-Planar，就是按三个轴投影，然后按 Normal 做混合。Ghost Recon 的做法好像只是按 x 和 y 两个轴投影。\n首先双线性插值一套操作下来就要采样 Splatting Texture 4 次（不是最终采样数，最终采样数还需要计算材质纹理的采样）了，然后处理崖壁又要按两个轴投影，然后直接 x2，变成 8 次，性能堪忧。\n优化就是把地表块分成三种，使用不同的 Shader。\n普通地表就直接双线性采 4 次就完事了。\nSlope 8 次逃不掉。\n过渡要两种都采，然后做混合。\n实测下来效果还行，80% 的地表都只需要采 4 次 Splatting Texture。\n道路是直接画在地形上的，然而地形的分辨率不够，导致细节丢失，在一个就是用 Splatting Id 的方案过渡很僵硬。\n屏幕空间贴花看起来效果不错。\n但是开销太大了。\nVirtual Texture 在地形中的应用。\n就是 UE 里的 Runtime Virtual Texture，大家都比较熟悉了，这个技术跟地形很般配。\nVT Feedback Pass 必不可少，但是 Ghost Recon 做了一些改进。\n判断哪些 Page 需要加载进 Physical Texture，最简单的方法就是直接光栅化整个场景，把结果画到一个屏幕空间的 Buffer 上，然后再读回 CPU，如果是 4k 的屏幕开销更离谱。但是如果换低分辨率的 RT 又会损失一些细节。\n优化方法就是不再单独开 Pass，直接在 G-Buffer Pass 里面完成计算，输出到一张 3D Texture 中，输出的时候拿 (uv, mipLevel) 作为坐标。\n直接用 Compute Pass 算出缺少的部分，然后回读会 CPU。\n如果按照 10 Texels / cm 的分辨率，大概需要 2PB 的存储空间，蓝光光盘都塞不下。\n压缩和 Tiles 的实时生成。\n最终的一些参数。\nXbox One 上的性能。\n地形相关的一些其他玩意。\n地形不止高度和地表，还保存了一些其他的信息。\n道路的生成需要定义一组 Waypoints，然后自动生成路径来连接各个点，形成道路。\n正常性网格的连接，效果不太行。\n随机连接，效果好很多。\n道路生成的流程。\n输入输出。\n根据生成的道路会顺便生成一些其他的玩意。\n火车道也是类似。\n河流。\n聚落。\n种田。\n自动摆石头。\n植被。\n声音。\n145 个工具，一套自动化管线，4 个 TA 负责。\n总结，最有价值的的就是 Material Id 的地表算法，在开放世界地表渲染领域基本已经成为了政治正确的方案，兼顾性能和效果，各种基于 Material Id 的优化方案层出不穷。本篇 GDC 更多关注的是程序化生成方面，渲染方面讲得比较少。\n","date":"2022-02-21T00:00:00Z","permalink":"https://www.kindem.xyz/post/51/","title":"GDC 笔记 - 'Ghost Recon Wildlands': Terrain Tools and Technology"},{"content":" 原文链接：GDC Vault - Terrain Rendering in \u0026lsquo;Far Cry 5\u0026rsquo;\n地形 Heightfield 渲染。\n地图大小是 10km x 10km，分辨率 0.5m，地形按照四叉树管理，整个地形被划分成 2km x 2km 的地块，这些地块永久可见。\n上面说的 2km x 2km 的地块被按照四叉树划分成很多 Tile，这些 Tile 按照 LOD 以及与玩家的距离进行 Steaming，磁盘上存储的 Tiles 数量上万，但是实际上运行时加载进内存的 Tiles 数量大概在 500 左右。\n所有四叉树节点所需要的 Textures 会同步被 Streaming 进 Texture Atlases，节点中会记录对应 Atlases 中的位置。纹理格式：\nHeightmap: R16_UNORM, 129x129 World space normal map: BC3, 132x132 Baked albedo map: BC1, 132x132 地形的渲染大概这么几步。\n首先是四叉树节点的 Streaming，首先在 LOD0 找到离玩家最近的一圈节点。\n切换到下一级 LOD，按更大范围找四叉树中对应的节点。\n以此类推，直到最后一级 LOD，前面说到了，最后一级 LOD 对应的四叉树节点是永远被加载的。这里只演示了 3 级 LOD，实际上 Far Cry 5 里有 6 级。\n最后组合起来，就是需要 Streaming 的所有节点。\n然后需要按照视角做剔除。\n接下来需要按照离相机的距离做一次 Batch，同一组的节点使用相同的 Shader，距离越远，使用的 Shader 越简单。\n上面的渲染流程可以用 CPU 实现，也可以走 GPU-Driven 路线，区别就是下面这部分在哪做。\nGPU-Driven 的优势，BalaBala \u0026hellip;\u0026hellip;\n需要的 GPU 数据结构及特点。\n四叉树对应的 GPU 实现就是带 Mips 的纹理，Terrain Quad Tree 也是一样，是一张 160x160 的纹理，整个纹理有 6 级 Mips，每个节点对应纹理中的一个 Texel。\nTerrain Quad Tree 纹理的格式是 R16_UINT，存的是 16 位的 Index，用于索引保存在 Node Description Buffer 的真正的节点数据，Node Description Buffer 中的每个节点数据保存了 Min/Max Height、LOD Bias、Atlas ID 等信息，最终按位编码成 2 个 Uint。\n每当节点 Streaming In / Out 的时候，需要对 Node Description Buffer 里的数据进行填充 / 移除。\nTerrain Node List 就是一个节点 Id 的列表，表示可能被渲染的节点（剔除前）。Terrain Node List 需要每一帧遍历 Terrain Quad Tree 来生成。\nTerrain Node List 的生成使用 Compute Shader，分为多个 Stage，每个 Stage 处理一级 LOD，每个 Stage 中由一个线程来处理当前 LOD 的一个节点，将其划分成子节点，填充到 Terrain Node List 中。\nTerrain Node List 的初始状态是用 LOD 0 计算，直接根据当前 Terrain Quad Tree 的 Mip 0 计算出一组 NodeID。\n进入下一个 Stage，读取上一个 Stage 的结果（Temp A），构造两个新的 Buffer，Temp B 和 Final，如果上一级 Mip 中的节点可以被细分（在这一级 Mip 中四个子节点被完全加载）就将其细分成 4 个节点，并存入 Temp B，如果不能被细分就直接放入 Final。\n有些节点的子节点没有被完全加载，这种也直接放入 Final。\n清空 Temp A，交换一下 Temp A 和 Temp B 的角色，进入下一个 Stage。\n以此类推完成 Terrain Node List 的生成。每个 Pass 对应一个 Stage，每个 Pass 需要两次 Compute Shader 的 Dispatch，因为需要统计每个 LOD 中节点的数量，来 Feed 下一个 Pass。\n每一帧都要计算一个 160x160 的 Terrain LOD Map 纹理，格式为 R8，每个 Texel 代表一个 Sector，保存了这个 Sector 对应的 LOD。这张纹理的作用是用于处理不同 LOD 之间的接缝。这里有些部分为 0 是因为 Sector 为空，不是 LOD 0。\n计算 Terrain LOD Group 的方法也很简单，拿着 Terrain Node List 直接照填就行了。\n最后是 Visible Render Patch List，由一个 Indirect Args 和一组 Patch 构成，Patch 里保存了 Draw 所需要的信息。最终下发 DrawCall 后每个 Patch 会被渲染成一个 16x16 的 Grid。Visible Render Patch List 的生成就是拿着 Terrain Node List 继续做细分与剔除，最终完成。\n每个节点会被细分成 8x8 个 Patch，每个 Patch 会被渲染成 16x16 的 Grid。每个 Compute Shader 线程负责处理一个 Patch，其中每个 Patch 都要做视椎体剔除、遮挡剔除、背面剔除、计算 LOD 过渡。\nCulling 的步骤与 SIGGRAPH 2015 的一篇文章 GPU-Driven Rendering Pipelines 里面介绍的类似。\n遮挡剔除用的是一个低分辨率的深度 Buffer，即 Conservative Depth，主机上和 PC 上的来源不同。\n生成 Mips 来适应不同大小的物体。\n对每一个 Patch，首先要拿到它的包围盒，然后投影到屏幕空间，在级联 Mips 中找到覆盖了这个范围的采样点，然后进行保守的剔除。\n背面剔除需要离线生成一张 8x8 BC3 的 Patch Cone Texture，每个节点 Build 一张这个纹理。对每一个 Patch，先对每一个三角形找到其 World Space 下的 Normal，然后对这些 Normal 在球面空间计算出一个最小的圈，从而形成一个 Cone。Cone 最终体现成中心的一根 Normal 向量和一个半角，被保存到 Patch Cone Texture 的一个 Texel 中。\n对每一个 Patch，按照上面的公式来计算是否要被剔除，保守起见，不光要拿相机方向做这个判断，还需要拿相机到 Patch 四个角的四个向量做计算，防止误剔除。\n每个 Patch Description 中包含了一个 LOD Transitions 信息，这个信息是当前 Patch 四个方向上与相邻 Patch 的 LOD 差值，由采样 LOD map 得到。\n上面这些步骤的计算时间。\nVertex Shading。\n不同 LOD Mesh 之前需要额外处理接缝。\n前面已经说过 Patch 中保存了相邻 Patch 的 LOD 差值，可以利用这一点来进行处理。上面几张图是 LOD 差值为 1 的情况，两个顶点一组，把第二个顶点直接移动到第一个顶点的位置，从而达到过渡的目的。\n差值为 2 的情况下，一次处理四个顶点，后三个顶点全部移动到第一个顶点的位置。\nFar Cry 5 里有地形挖洞的需求，实现是存了 1Bit 的挖洞数据在 BC1 的 Atlas Albedo Map 里。\n通过在 Vertex Shader 里输出 NaN 来完成 Vertex 的 Cull，号称这样更省点。\n干掉一个点会影响周围 8 个点，所以开洞的分辨率是地形分辨率的一半，即 1M。\nShading，主要讲地表渲染。\nTerrain Shading 跟 2017 GDC 上的 Ghost Recon 分享类似。\n之前说的 Terrain Quad Tree 是带着 Texture Payload 的，他们分别是 Height、Normal、Albedo、Patch Cone Map、Color Modulation Map、Splat Map。\n远处的 Shading 可以直接用 Normal、Albedo 搞定，近处的用 Splat Map（就是我们常说的 IdMap）。Splat Map 保存了一个 8-Bit 的 Id，索引了 Material Buffer 中的一个单位，里面保存了地表的 Albedo、Normal、Height 等纹理在 Texture Array 中的索引，以及 Rotation、Tiling、Burning 等一些其他参数。\n这里要注意的是 Splat Map 的位宽是 8，意味着最多可以有 256 种地表材质，但是这些材质的纹理是不可能全部加载进内存的，这些地表材质的纹理会动态地被拼成 32 层的 Texture Array 加载进内存，然后再按照 Material Buffer 中保存的 Id 进行索引，所以这意味着一个地形节点最多使用 32 种地表材质。\n经典的 IdMap 地表渲染，先拿 World Position 算 UV，然后采样 Splat Map 找到材质参数，然后采样 Texture Array 完成渲染。\nIdMap 算法使用的是双线性插值，所以一个点需要进行 4 次 Splat Map 的采样，然后还要采 3x4 次 Texture Array，所以最终是 16 次采样。\n16 次采样还是略微昂贵了点，Far Cry 5 也像 Far Cry 4 一样用了 Virtual Texture（对应 UE 里的 Runtime Virtual texture）来缓存。\n一些参数信息。\n可以把采样数降低到 4 次（不算 Physical Texture 更新）。\n一些 Physical Texture Page 渲染的参数，一帧计划最多更新 6 个 Page。每个 Page 大小为 256x256 Texel，还有 4 Texel 的 Border。跟主流做法一样，还会用 Compute Shader 做一次 BC 格式的异步压缩，最终算下来 GPU 开销大概是每帧 1ms。\n为了计算哪些 Page 需要更新，回读 PageId 到 CPU 是必不可少的，为了保持速度够快，限制了 RT 的大小。\n使用 VT 的一大好处就是方便多种材质混合，上图中就有 Road、Decal、Terrain 几种材质。\n这是一个 Overdraw 的可视化，可以看到 decal 的开销还行。\n崖壁的渲染。\n老生常谈的崖壁渲染，上面标记成红色的就是崖壁。通常地形的相关纹理都是从俯视角拍的，UV 坐标对应的都是 World Position 的 (x, y)，而崖壁这种地貌在地形的纹理上对应的 Texel Resolution 就很小，这就会导致问题。\n去掉 Debug Draw 后的效果，看起来就很糟糕，拉伸得很严重。\n处理的办法是比较经典的 Tri-Planar Mapping，即使用世界坐标 xy、xz、yz 在三个投影方向上代替 UV 进行采样，然后再使用 Normal 对这三次采样结果进行混合。图中标记成红色和蓝色的崖壁是按照 x 轴、y 轴投影的结果。\n这会导致采样数变成原来的三倍，这种做法是比较 Expensive 的。\n另外一个问题就是崖壁通常离玩家比较远，一旦离远了，纹理的 Tiling 就会变得很明显，看起来重复度会很高。\n去掉 DebugDraw 之后的效果，还是比较明显的。\n做法是调整 UV Space 使其在 Screen Space 中分配更均匀，后面说了实际上是依靠离相机的距离对 Tiling 进行调整。\n调整之后的效果。\n因为依赖距离进行调整，要对材质做一次 Blend，又导致采样翻倍了。\n一些 Cheaper 的崖壁替代方案以及问题。\n团队想到一种 Crazy 的方案，使用随机 Blending 替代 Alpha Blending，从像素级别上看，随机 Blending 效果是不对的，但是平均来看，是大致正确的。\n于是崖壁的 Shading 就不再每个像素都采多次 Splat Map 了，而是每个像素随机选择，然后只采一次 Splat Map，采样数直接降低到 4，但是效果不太行。\nNoise Function 的选择会直接决定质量，无论是 Screen Space 还是 World Space 的 Noise Function，都有优劣。\n最终选了 NVIDIA 的一篇论文中的算法。\n但是不幸的是噪点还是太多了，于是团队开始尝试将随机 Blending 和 Alpha Blending 结合起来。\n对于远处的崖壁，有前面说的 Tiling 的问题，所以就按之前说的，在两个材质中各随机一次，然后再做 Alpha Blending，这样采样数就变成了 8。\nDebugDraw 下看，其实还是有噪点的。\n但是关了 DebugDraw 之后，感觉可以接受。\n考虑到崖壁接近相机的情况，在这个距离下，其实不需要下面的材质混合，但是随机选一个方向作为最后的结果效果不太行，所以还是做了完整的 Tri-Planar 混合。\n这里采样数应该写反了，应该是近处 12，远处 8。\n实测下来没发现太大的问题，但是依然不完美。这种随机 Blending 中的任何噪点带来的变化实际上都是材质的变化（Splat Map 采的是 Material Id），拉近了看实际上是能看见材质的细微变化的。\n地形之外的一些东西，主要是贴花和地形相关的 Mesh。\nFar Cry 5 的贴花系统是基于 VT 的，团队改进了这套贴花系统，并称其 Terrain Displacement Decals。就是在传统 VT 贴花的基础上，加了贴花对地形 Mesh 的影响。\n放置贴花的时候，贴花 Mesh 会附着在地形上，Pixel Shader 阶段直接采地形的 VT 就可以了，因为贴花的纹理已经被画在 VT 上了。\nDisplacement Mesh 还没开的时候，其实就能看见传统 VT 贴花的效果了，只是开了之后贴花物体的形状会更加清晰（好像看不出来 \u0026hellip;\u0026hellip;）。\n优缺点，主要缺点是由于不是 Tessellation，所以需要人摆，当然也可以程序化生成。\n崖壁会走程序化生成管线生成 Mesh，看起来会比高度图渲染的崖壁更真实。\n另一个例子。\n屏幕空间 Shading。\n整个屏幕空间通常能看见的东西有这么几种，每一种都是不同的 Shading Flavors。因为彼此需要混合，最终有 31 种 Shader 变体。有一些 Shader 变体的开销会比其他的 Expensive 很多，为了保持 GPU 效率，需要保证对每一块地形都使用 Cheapest 的 Shader 变体。\n最简单的方法就是根据 Patch 选择 Shader ID，但是这种做法并不一定最优因为 Patch 的范围其实还挺大的。\n最终决定按屏幕空间的 Tile 来进行 Shader ID 的选择。\n在 Geometry Pass 中使用 MRT 输出一张 8Bit 的 Classification RT，其中保存了 5 种 Shading Flavors 的 Bitmask。\n接下来是一个 Full Screen 的 Compute Pass 被称为 Terrain Classification Pass，读取前面的 Classification RT，按照 8x8 的 Tile 来合并具有相同 Shader Id 的 Tile，并输出 Indirect Args 给下一步使用。\n然后就是渲染 G-Buffer。\n整套流程的 Overview。\n采样 Terrain 纹理的过程是先从深度 Buffer 中取出 World Position，然后通过 Terrain Sector Data 来获取具体的纹理信息。\nTerrain Sector Data 是一个 160x160 的 64Bits 的 Buffer，对应 160x160 Sectors，每一个单元保存了这个 Sector 需要的 Atlas Texture Ids，拿 World Position 在 Buffer 里找就能拿到对应信息。\n在 Shading Pass 需要用到 Texture 导数（类似 ddx、ddy？只不过是 Texture 空间的）。因为地形相关的纹理的 UV 其实都是 World Space Position 的线性映射，所以只要求出 World Space Position 的导数，就可以求出 Texture 导数。\n对于屏幕空间的像素（x, y），先从深度获取 World Space Position，然后拿到 World Space Normal，用拿到的 Normal 构建一个平面，拿着相机到像素（x, y+1）的射线与平面求交，交点就是屏幕空间 World Space Position 在 y 方向上的导数，同理，拿 （x+1, y）来求 x 方向上的导数。\n刚刚说过崖壁等会替换成特定的 Mesh，这种情况下就不再适用了。\n解决方法是在 Terrain Geometry Pass 中用 MRT 输出一张 Normal 纹理。\n然鹅 Normal 会被插值，插值之后可能就不对了。\n解决方法是把三角形的 Normal 也输出到 RT 里，然后把两个 Normal 编码到 32Bit 里，每个 Normal 16 Bits。\n最终流程。\n优缺点。\n性能。\n一些基于地形的效果。\n回顾下前面的 Terrain Scetor Data，只要有 World Position，就可以拿到地形上任意一个点对应的纹理信息（Height、Albedo、Normal、Splat 等）。\n其中一个作用就是在树根的 Shading 里，可以在 Vertex Shader 中采样地形的高度图来做与地表的混合。\n碎石也用了类似的处理。\n最后一级 LOD 的草也用了地形高度图，比较近的草需要比较高的渲染精度，但是离远了就直接换成与地形高度、颜色匹配的 Quads。\n这些草的生成是使用 Compute Shader 在每一帧去采样地形材质的类型、Height、Color、Normal 等，然后生成 Indirect Args，最后一次 Indirect Draw 完成绘制，可以看到开关后的对比。\n总结。\n","date":"2022-02-21T00:00:00Z","permalink":"https://www.kindem.xyz/post/52/","title":"GDC 笔记 - Terrain Rendering in 'Far Cry 5'"},{"content":" 使用的版本：UE5 Early Access\n地形系统介绍 UE 可以直接在编辑器中创建并编辑地形，编辑地形的模式有两种：Sculpt 和 Paint。\nSculpt 的作用是对地形进行造型和雕刻，Sculpt 对地形产生的修改最终会体现在 Heightmap 即高度图中，UE 会在运行时对这张图进行采样，从而产生地形 Mesh，很经典的做法。 Paint 则可以让开发者对地表进行绘制，开发者可以创建多个 Landscape Layer，每一个 Layer 可以使用不同的纹理，比如雪地、草地、土壤等，在 Paint 模式下，用户可以选择不同的 Layer 对地形进行绘制，绘制完成后，会根据 Layer 的数量生成对应的 Weightmap 即权重图，其中保存了每一个 Layer 的权重，由于 Weightmap 有 RGBA 四个通道，一张 Weightmap 至多能保存四个 Layer，每四个 Layer 会额外生成一张 Weightmap，Layer 数量越多，显存消耗越大。在运行时，UE 会对当前地块的 Weightmap 和 Layer 纹理进行采样，并进行混合，最终形成地表。 在创建地形的时候，有 Section 的概念，Section 可以认为是一块地形，每一个地形 Component 可以选择保存 1x1 或者 2x2 块 Section，创建地形的时候，需要输入 Section 的大小和 Component 的数量，来决定最终地形的大小。\n要在 UE 中创建地形，需要先切换到 Landscape Editing Mode：\nLandscape Editing Mode 在 Manage 面板，我们可以输入参数创建新的地形：\nLandscape Manage 完成创建后，会生成一个 Landscape 的 Actor：\nLandscape 之后切换到 Sculpt 模式即可进行雕刻，有很多工具可供选择，我这里随便整了个地形：\nSculpt 下一步就是刷地表，在刷地表之前，我们先要为每一层 Layer 创建一个 MaterialFunction，每个 MaterialFunction 使用 Landscape TexCoord 采样自己需要的纹理，然后输出一个 MaterialAttribute，我这里为了简单起见，直接用 LandscapeCoords 采 BaseColor 然后返回，Normal 给 (0, 0, 1)，实际上做的时候材质是会很复杂的（要注意不光 BaseColor 会做混合，而是所有的 MaterialAttribute 都会做混合）：\nLayer Grass 做完了草，再做几层其他的，也是类似的：\nLayers 接下来我们需要创建地形的材质，并在其中使用 LandscapeLayerBlend 节点对多层地表进行混合：\nLandscapeLayerBlend 注意材质选项中勾选 Use Material Attributes 来直接输出 Material Attributes，然后 MF_ 开头的三个就是我们之前创建的三个 Layer，在 Landscape Layer Blend 节点中填写 LayerName 并把对应的 Layer 连上来即可。\n接下来选中 Landscape Actor，将其材质设置成我们刚刚创建的这个材质：\nLandscape Material 这时候你可以注意到，左边的 Paint 面板已经自动识别到了我们刚刚创建的几个 Layer：\nPaint Layers 我们需要为每一层 Layer 创建一个 LayerInfo Object，后面 UE 将使用这个信息来创建 Weightmap，点击右边的 + 号，然后选择 Weight-Blended Layer 即可：\nLayer Infos 这时候你会发现地形从黑色变成了第一层 Layer，这是因为当识别到有 LayerInfo Object 时，如果各层权重之和不为 1，UE 会默认使用第一层 Layer 来填满剩余的权重。\n最后选中不同的 Layer 即可直接在地形上绘制地表，我这随便画了点：\nPainting 地形的基本功能就是这样了，原谅我的美术水平实在太糟糕 \u0026hellip;..\nRenderDoc 分析 先抓一帧：\nLandscape DrawCalls 可以看见最终是一个 Component 一个 DrawCall，一次只画一块，接下来可以看看 Heightmap 和 Weightmap：\nHeightmap \u0026amp; Weightmap Landscape 的 DrawCall 中可以清楚地看见 Heightmap 和 Weightmap，上面那张就是 Heightmap，整个地形一张，而下面的 Weightmap 则是按 Component 来的，每个 Component 一张。\n","date":"2021-12-05T00:00:00Z","permalink":"https://www.kindem.xyz/post/50/","title":"UE5 地形系统初探"},{"content":" 原文请参考 GPU Pro 1, Engel W . Chapter 1. As Simple as Possible Tessellation for Interactive Applications. 2010.\n笔记 文章提出了一种新的曲面细分方法，可以在运行时增加新的顶点，提高几何细节，被称为 Phong Tessellation，下面是普通渲染与曲面细分的对比图：\nPhong Shading / Phong Tessellation 在介绍 Phong Tessellation 之前，先介绍了一波前人的工作，首先是 Linear Tessellation：\nLinear Tesselation Expr 其中 Pi, Pj, Pk 为三角面片的三个顶点 Position，u, v, w 是一个可调整的权重值，满足 u + v + w = 1，P(u, v) 是生成的新的顶点的 Position，Linear Tessellation 可以在三角面片上生成一个新的顶点。但是在面片上生成新的顶点实际上并没啥用 \u0026hellip;.\n接着是按照类似的思路提出的 Phong Normal Tessellation，它的思路为新顶点产生插值的 Normal，从 Normal 的角度来丰富细节，公式和上面的类似，只是最后还要做一次 Normalize：\nPhong Normal Tessellation Expr 作者按照他们的思路，提供了一次非三角面片上的曲面细分，也就是开始说的 Phong Tessellation：\nPhong Tessellation Expr 其中 alpha 是一个 0~1 之间的权重，通常取 3/4，P(u, v) 是上面 Linear Tessellation 的结果，PI 是 P(u, v) 点在三角面片的三个顶点所决定的平面（Position + Normal 可以决定平面）上的投影。看图更好理解：\nPhong Tesselation Desc 作者还给了 Shader：\nPhong Tesselation Shader 然后作者又了提一句，说 Phong Normal Tessellation 已经能提供不错的细节提升了，而且相对他们这个算法来说开销更小，不一定所有顶点都需要使用 Phong Tessellation。Phong Tessellation 在轮廓上的表现会比 Phong Normal Tessellation 更好，所以只需要在轮廓上采用 Phong Normal Tessellation 就行了，然后给了一个计算“轮廓度”的计算公式：\nSilhouetteness Expr 其中 c 是相机位置，m 是深度。\n最后作者说他们这个算法不止可以用于 Triangle Polygon，还可以给 Quad Polygon 用，效果如下：\nFrom Triangle To Quat Quat Effects 总结 相对来说比较平平无奇的一个曲面细分算法，实际上原理很简单，可以考虑手动实现一波试试手。\n","date":"2021-11-25T00:00:00Z","permalink":"https://www.kindem.xyz/post/49/","title":"GPU Pro 1 笔记 - As Simple as Possible Tessellation for Interactive Applications"},{"content":"介绍 std::unique_ptr 是 c++ 11 添加的智能指针之一，是裸指针的封装，我们可以直接使用裸指针来构造 std::unique_ptr：\nstruct TestStruct { int a; int b; }; class TestClass { public: TestClass() = default; TestClass(int a, int b) : a(a), b(b) {} private: int a; int b; }; std::unique_ptr\u0026lt;int\u0026gt; p0 = std::unique_ptr\u0026lt;int\u0026gt;(new int { 1 }); std::unique_ptr\u0026lt;TestStruct\u0026gt; p1 = std::unique_ptr\u0026lt;TestStruct\u0026gt;(new TestStruct { 1, 2 }); std::unique_ptr\u0026lt;TestClass\u0026gt; p2 = std::unique_ptr\u0026lt;TestClass\u0026gt;(new TestClass(1, 2)); 在 c++ 14 及以上，可以使用 std::make_unique 来更方便地构造 std::unique_ptr，参数列表需匹配创建对象的构造函数：\nstd::unique_ptr\u0026lt;int\u0026gt; p0 = std::make_unique\u0026lt;int\u0026gt;(1); std::unique_ptr\u0026lt;TestStruct\u0026gt; p1 = std::make_unique\u0026lt;TestStruct\u0026gt;(TestStruct { 1, 2 }); std::unique_ptr\u0026lt;TestClass\u0026gt; p2 = std::make_unique\u0026lt;TestClass\u0026gt;(1, 2); 除了保存普通对象，std::unique_ptr 还能保存数组，这时 std::make_unique 的参数表示数组的长度：\nstd::unique_ptr\u0026lt;int[]\u0026gt; p0 = std::make_unique\u0026lt;int[]\u0026gt;(1); std::unique_ptr\u0026lt;TestStruct[]\u0026gt; p1 = std::make_unique\u0026lt;TestStruct[]\u0026gt;(2); std::unique_ptr\u0026lt;TestClass[]\u0026gt; p2 = std::make_unique\u0026lt;TestClass[]\u0026gt;(3); std::unique_ptr 重载了 operator-\u0026gt;，你可以像使用普通指针一样使用它：\nstd::unique_ptr\u0026lt;TestStruct\u0026gt; p = std::make_unique\u0026lt;TestStruct\u0026gt;(TestStruct { 1, 2 }); std::cout \u0026lt;\u0026lt; \u0026#34;a: \u0026#34; \u0026lt;\u0026lt; p-\u0026gt;a \u0026lt;\u0026lt; \u0026#34;, b: \u0026#34; \u0026lt;\u0026lt; p-\u0026gt;b \u0026lt;\u0026lt; std::endl; // 输出： // a: 1, b: 2 当然，直接使用 nullptr 对其赋值，或者拿 std::unique_ptr 与 nullptr 进行比较，都是可以的：\nstd::unique_ptr\u0026lt;TestClass\u0026gt; p = nullptr; std::cout \u0026lt;\u0026lt; (p == nullptr) \u0026lt;\u0026lt; std::endl; p = std::make_unique\u0026lt;TestClass\u0026gt;(); std::cout \u0026lt;\u0026lt; (p == nullptr) \u0026lt;\u0026lt; std::endl; // 输出： // 1 // 0 std::unique_ptr 在离开其作用域时，所保存的对象会自动销毁：\nstd::cout \u0026lt;\u0026lt; \u0026#34;block begin\u0026#34; \u0026lt;\u0026lt; std::endl; { auto p = std::make_unique\u0026lt;LifeCycleTestClass\u0026gt;(); p-\u0026gt;PrintHello(); } std::cout \u0026lt;\u0026lt; \u0026#34;block end\u0026#34; \u0026lt;\u0026lt; std::endl; // 输出 // block begin // constructor // hello // destructor // block end 比较重要的一点是 std::unique_ptr 删除了拷贝构造，所有它对对象的所有权是独享的，你没有办法直接将 std::unique_ptr 相互拷贝，而只能通过 std::move 来转移所有权：\nauto p1 = std::make_unique\u0026lt;TestClass\u0026gt;(); // 编译错误：Call to deleted constructor of \u0026#39;std::unique_ptr\u0026lt;TestClass\u0026gt;\u0026#39; auto p2 = p1; 正确的做法是：\nauto p1 = std::make_unique\u0026lt;TestClass\u0026gt;(); auto p2 = std::move(p1); 因为触发了移动语义，转移所有权期间，对象不会重新构造。\n除了上面这些特性，std::unique_ptr 还提供了一些与裸指针相关的成员函数，你可以使用 get() 来直接获取裸指针：\nauto p = std::make_unique\u0026lt;TestClass\u0026gt;(); TestClass* rawP = p.get(); 也可以使用 release() 来释放裸指针，在释放后，原来的 std::unique_ptr 会变成 nullptr：\nauto p = std::make_unique\u0026lt;TestClass\u0026gt;(); TestClass* rawP = p.release(); 要注意的是，get() 和 release() 都不会销毁原有对象，只是单纯对裸指针进行操作而已。\n在实际编程实践中，std::unique_ptr 要比 std::shared_ptr 更实用，因为 std::unique_ptr 对对象的所有权是明确的，销毁时机也是明确的，可以很好地避免使用 new。\n源码解析 下面的源码解析基于 MSVC 16 2019 (64-Bit)，其他编译器可能有所不同。\n_Compressed_pair _Compressed_pair 是 std::unique_ptr 内部用于存储 deleter 和裸指针的工具，从字面意思来看，它实现的功能和 std::pair 是类似的，但是有所差异的一点是在某些场景下，_Compressed_pair 相比 std::pair 做了额外的压缩，我们先来看看源码：\nstruct _Zero_then_variadic_args_t { explicit _Zero_then_variadic_args_t() = default; }; // tag type for value-initializing first, constructing second from remaining args struct _One_then_variadic_args_t { explicit _One_then_variadic_args_t() = default; }; // tag type for constructing first from one arg, constructing second from remaining args template \u0026lt;class _Ty1, class _Ty2, bool = is_empty_v\u0026lt;_Ty1\u0026gt; \u0026amp;\u0026amp; !is_final_v\u0026lt;_Ty1\u0026gt;\u0026gt; class _Compressed_pair final : private _Ty1 { // store a pair of values, deriving from empty first public: _Ty2 _Myval2; using _Mybase = _Ty1; // for visualization template \u0026lt;class... _Other2\u0026gt; constexpr explicit _Compressed_pair(_Zero_then_variadic_args_t, _Other2\u0026amp;\u0026amp;... _Val2) noexcept( conjunction_v\u0026lt;is_nothrow_default_constructible\u0026lt;_Ty1\u0026gt;, is_nothrow_constructible\u0026lt;_Ty2, _Other2...\u0026gt;\u0026gt;) : _Ty1(), _Myval2(_STD forward\u0026lt;_Other2\u0026gt;(_Val2)...) {} template \u0026lt;class _Other1, class... _Other2\u0026gt; constexpr _Compressed_pair(_One_then_variadic_args_t, _Other1\u0026amp;\u0026amp; _Val1, _Other2\u0026amp;\u0026amp;... _Val2) noexcept( conjunction_v\u0026lt;is_nothrow_constructible\u0026lt;_Ty1, _Other1\u0026gt;, is_nothrow_constructible\u0026lt;_Ty2, _Other2...\u0026gt;\u0026gt;) : _Ty1(_STD forward\u0026lt;_Other1\u0026gt;(_Val1)), _Myval2(_STD forward\u0026lt;_Other2\u0026gt;(_Val2)...) {} constexpr _Ty1\u0026amp; _Get_first() noexcept { return *this; } constexpr const _Ty1\u0026amp; _Get_first() const noexcept { return *this; } }; template \u0026lt;class _Ty1, class _Ty2\u0026gt; class _Compressed_pair\u0026lt;_Ty1, _Ty2, false\u0026gt; final { // store a pair of values, not deriving from first public: _Ty1 _Myval1; _Ty2 _Myval2; template \u0026lt;class... _Other2\u0026gt; constexpr explicit _Compressed_pair(_Zero_then_variadic_args_t, _Other2\u0026amp;\u0026amp;... _Val2) noexcept( conjunction_v\u0026lt;is_nothrow_default_constructible\u0026lt;_Ty1\u0026gt;, is_nothrow_constructible\u0026lt;_Ty2, _Other2...\u0026gt;\u0026gt;) : _Myval1(), _Myval2(_STD forward\u0026lt;_Other2\u0026gt;(_Val2)...) {} template \u0026lt;class _Other1, class... _Other2\u0026gt; constexpr _Compressed_pair(_One_then_variadic_args_t, _Other1\u0026amp;\u0026amp; _Val1, _Other2\u0026amp;\u0026amp;... _Val2) noexcept( conjunction_v\u0026lt;is_nothrow_constructible\u0026lt;_Ty1, _Other1\u0026gt;, is_nothrow_constructible\u0026lt;_Ty2, _Other2...\u0026gt;\u0026gt;) : _Myval1(_STD forward\u0026lt;_Other1\u0026gt;(_Val1)), _Myval2(_STD forward\u0026lt;_Other2\u0026gt;(_Val2)...) {} constexpr _Ty1\u0026amp; _Get_first() noexcept { return _Myval1; } constexpr const _Ty1\u0026amp; _Get_first() const noexcept { return _Myval1; } }; 可以看到，_Compressed_pair 在满足条件 is_empty_v\u0026lt;_Ty1\u0026gt; \u0026amp;\u0026amp; !is_final_v\u0026lt;_Ty1\u0026gt; 时，会走上面的定义，使用 Empty base optimization 即空基类优化，不满足时，则走下面的特化，退化成普通的 pair，我们来通过一段示例代码看一下压缩效果：\nstd::cout \u0026lt;\u0026lt; sizeof(std::pair\u0026lt;A, int\u0026gt;) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; sizeof(std::_Compressed_pair\u0026lt;A, int\u0026gt;) \u0026lt;\u0026lt; std::endl; // 输出 // 8 // 4 当 A 为空类时，由于 c++ 的机制，会为其保留 1 字节的空间，A 和 int 联合存放在 std::pair 里时，因为需要进行对齐，就变成了 4 + 4 字节，而 _Compressed_pair 则通过空基类优化避免了这个问题。\nunique_ptr 先来看看保存普通对象的 std::unique_ptr 的定义：\ntemplate \u0026lt;class _Ty, class _Dx = default_delete\u0026lt;_Ty\u0026gt;\u0026gt; class unique_ptr; 这里的模板参数 _Ty 是保存的对象类型，_Dx 是删除器类型，默认为 default_delete\u0026lt;_Ty\u0026gt;，下面是具体的定义：\ntemplate \u0026lt;class _Ty\u0026gt; struct default_delete { // default deleter for unique_ptr constexpr default_delete() noexcept = default; template \u0026lt;class _Ty2, enable_if_t\u0026lt;is_convertible_v\u0026lt;_Ty2*, _Ty*\u0026gt;, int\u0026gt; = 0\u0026gt; default_delete(const default_delete\u0026lt;_Ty2\u0026gt;\u0026amp;) noexcept {} void operator()(_Ty* _Ptr) const noexcept /* strengthened */ { // delete a pointer static_assert(0 \u0026lt; sizeof(_Ty), \u0026#34;can\u0026#39;t delete an incomplete type\u0026#34;); delete _Ptr; } }; 很简单，只是一个重载了 operator() 的结构体而已，operator() 中则直接调用 delete。\nstd::unique_ptr 中定义了几个 using：\ntemplate \u0026lt;class _Ty, class _Dx_noref, class = void\u0026gt; struct _Get_deleter_pointer_type { // provide fallback using type = _Ty*; }; template \u0026lt;class _Ty, class _Dx_noref\u0026gt; struct _Get_deleter_pointer_type\u0026lt;_Ty, _Dx_noref, void_t\u0026lt;typename _Dx_noref::pointer\u0026gt;\u0026gt; { // get _Dx_noref::pointer using type = typename _Dx_noref::pointer; }; using pointer = typename _Get_deleter_pointer_type\u0026lt;_Ty, remove_reference_t\u0026lt;_Dx\u0026gt;\u0026gt;::type; using element_type = _Ty; using deleter_type = _Dx; 这里 element_type 为元素类型，deleter_type 为删除器类型，我们主要关注 pointer，pointer 的类型由 _Get_deleter_pointer_type 决定，我们可以发现它有两个定义，前者是默认定义，当删除器中没有定义 pointer 时会 fallback 到这个定义，如果删除器定义了 pointer，则会使用删除器中的 pointer 类型。下面是一段实验代码：\ntemplate \u0026lt;class Ty\u0026gt; struct deleter { using pointer = void*; constexpr deleter() noexcept = default; template \u0026lt;class Ty2, std::enable_if_t\u0026lt;std::is_convertible_v\u0026lt;Ty2*, Ty*\u0026gt;, int\u0026gt; = 0\u0026gt; explicit deleter(const deleter\u0026lt;Ty2\u0026gt;\u0026amp;) noexcept {} void operator()(Ty* Ptr) const noexcept /* strengthened */ { // delete a pointer delete Ptr; } }; struct A {}; int main(int argc, char* argv[]) { std::cout \u0026lt;\u0026lt; typeid(std::_Get_deleter_pointer_type\u0026lt;A, std::remove_reference_t\u0026lt;std::default_delete\u0026lt;A\u0026gt;\u0026gt;\u0026gt;::type).name() \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; typeid(std::_Get_deleter_pointer_type\u0026lt;A, std::remove_reference_t\u0026lt;deleter\u0026lt;A\u0026gt;\u0026gt;\u0026gt;::type).name() \u0026lt;\u0026lt; std::endl; } 输出结果：\nstruct A * __ptr64 void * __ptr64 然后我们来看一下 std::unique_ptr 的 private block：\nprivate: template \u0026lt;class, class\u0026gt; friend class unique_ptr; _Compressed_pair\u0026lt;_Dx, pointer\u0026gt; _Mypair; 只是定义了一个 _Compressed_pair 来同时保存删除器和裸指针，这里要注意的是，pair 中保存的顺序，first 是删除器，second 是 pointer。\n接下来看一下 std::unique_ptr 的各种构造和 operator=，首先是默认构造：\ntemplate \u0026lt;class _Dx2 = _Dx, _Unique_ptr_enable_default_t\u0026lt;_Dx2\u0026gt; = 0\u0026gt; constexpr unique_ptr() noexcept : _Mypair(_Zero_then_variadic_args_t{}) {} 这里的 _Zero_then_variadic_args_t 在上面也出现过，是一个空结构体，作用于用于标记参数数量，然后决定具体使用 _Compressed_pair 的哪一个构造。\n接下来是 nullptr_t 的构造和 operator=：\ntemplate \u0026lt;class _Dx2 = _Dx, _Unique_ptr_enable_default_t\u0026lt;_Dx2\u0026gt; = 0\u0026gt; constexpr unique_ptr(nullptr_t) noexcept : _Mypair(_Zero_then_variadic_args_t{}) {} unique_ptr\u0026amp; operator=(nullptr_t) noexcept { reset(); return *this; } 主要是针对空指针的处理，当使用空指针进行构造和赋值的时候，相当于把 std::unique_ptr 重置。\n接下来是更常用的构造：\ntemplate \u0026lt;class _Dx2\u0026gt; using _Unique_ptr_enable_default_t = enable_if_t\u0026lt;conjunction_v\u0026lt;negation\u0026lt;is_pointer\u0026lt;_Dx2\u0026gt;\u0026gt;, is_default_constructible\u0026lt;_Dx2\u0026gt;\u0026gt;, int\u0026gt;; template \u0026lt;class _Dx2 = _Dx, _Unique_ptr_enable_default_t\u0026lt;_Dx2\u0026gt; = 0\u0026gt; explicit unique_ptr(pointer _Ptr) noexcept : _Mypair(_Zero_then_variadic_args_t{}, _Ptr) {} template \u0026lt;class _Dx2 = _Dx, enable_if_t\u0026lt;is_constructible_v\u0026lt;_Dx2, const _Dx2\u0026amp;\u0026gt;, int\u0026gt; = 0\u0026gt; unique_ptr(pointer _Ptr, const _Dx\u0026amp; _Dt) noexcept : _Mypair(_One_then_variadic_args_t{}, _Dt, _Ptr) {} template \u0026lt;class _Dx2 = _Dx, enable_if_t\u0026lt;conjunction_v\u0026lt;negation\u0026lt;is_reference\u0026lt;_Dx2\u0026gt;\u0026gt;, is_constructible\u0026lt;_Dx2, _Dx2\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; unique_ptr(pointer _Ptr, _Dx\u0026amp;\u0026amp; _Dt) noexcept : _Mypair(_One_then_variadic_args_t{}, _STD move(_Dt), _Ptr) {} template \u0026lt;class _Dx2 = _Dx, enable_if_t\u0026lt;conjunction_v\u0026lt;is_reference\u0026lt;_Dx2\u0026gt;, is_constructible\u0026lt;_Dx2, remove_reference_t\u0026lt;_Dx2\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; unique_ptr(pointer, remove_reference_t\u0026lt;_Dx\u0026gt;\u0026amp;\u0026amp;) = delete; 单参数的构造只传入指针，当满足删除器类型不是指针而且可默认构造的情况下启用，直接把传入的裸指针存入 pair，这时候由于删除器是可默认构造的，pair 中保存的删除器会被直接默认构造。另外的三个也需要满足一定条件，这时可以从外部传入删除器，并将其保存至 pair 中。\n然后是移动构造：\ntemplate \u0026lt;class _Dx2 = _Dx, enable_if_t\u0026lt;is_move_constructible_v\u0026lt;_Dx2\u0026gt;, int\u0026gt; = 0\u0026gt; unique_ptr(unique_ptr\u0026amp;\u0026amp; _Right) noexcept : _Mypair(_One_then_variadic_args_t{}, _STD forward\u0026lt;_Dx\u0026gt;(_Right.get_deleter()), _Right.release()) {} template \u0026lt;class _Ty2, class _Dx2, enable_if_t\u0026lt; conjunction_v\u0026lt;negation\u0026lt;is_array\u0026lt;_Ty2\u0026gt;\u0026gt;, is_convertible\u0026lt;typename unique_ptr\u0026lt;_Ty2, _Dx2\u0026gt;::pointer, pointer\u0026gt;, conditional_t\u0026lt;is_reference_v\u0026lt;_Dx\u0026gt;, is_same\u0026lt;_Dx2, _Dx\u0026gt;, is_convertible\u0026lt;_Dx2, _Dx\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; unique_ptr(unique_ptr\u0026lt;_Ty2, _Dx2\u0026gt;\u0026amp;\u0026amp; _Right) noexcept : _Mypair(_One_then_variadic_args_t{}, _STD forward\u0026lt;_Dx2\u0026gt;(_Right.get_deleter()), _Right.release()) {} #if _HAS_AUTO_PTR_ETC template \u0026lt;class _Ty2, enable_if_t\u0026lt;conjunction_v\u0026lt;is_convertible\u0026lt;_Ty2*, _Ty*\u0026gt;, is_same\u0026lt;_Dx, default_delete\u0026lt;_Ty\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; unique_ptr(auto_ptr\u0026lt;_Ty2\u0026gt;\u0026amp;\u0026amp; _Right) noexcept : _Mypair(_Zero_then_variadic_args_t{}, _Right.release()) {} #endif // _HAS_AUTO_PTR_ETC template \u0026lt;class _Ty2, class _Dx2, enable_if_t\u0026lt;conjunction_v\u0026lt;negation\u0026lt;is_array\u0026lt;_Ty2\u0026gt;\u0026gt;, is_assignable\u0026lt;_Dx\u0026amp;, _Dx2\u0026gt;, is_convertible\u0026lt;typename unique_ptr\u0026lt;_Ty2, _Dx2\u0026gt;::pointer, pointer\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; unique_ptr\u0026amp; operator=(unique_ptr\u0026lt;_Ty2, _Dx2\u0026gt;\u0026amp;\u0026amp; _Right) noexcept { reset(_Right.release()); _Mypair._Get_first() = _STD forward\u0026lt;_Dx2\u0026gt;(_Right._Mypair._Get_first()); return *this; } template \u0026lt;class _Dx2 = _Dx, enable_if_t\u0026lt;is_move_assignable_v\u0026lt;_Dx2\u0026gt;, int\u0026gt; = 0\u0026gt; unique_ptr\u0026amp; operator=(unique_ptr\u0026amp;\u0026amp; _Right) noexcept { if (this != _STD addressof(_Right)) { reset(_Right.release()); _Mypair._Get_first() = _STD forward\u0026lt;_Dx\u0026gt;(_Right._Mypair._Get_first()); } return *this; } 条件判断比较多，不过归根到底都是直接移动删除器，然后调用原 std::unique_ptr 的 release() 释放裸指针，再将裸指针填入新的 pair 中。\n最后，有关构造和赋值比较重要的是被删除的两个方法：\nunique_ptr(const unique_ptr\u0026amp;) = delete; unique_ptr\u0026amp; operator=(const unique_ptr\u0026amp;) = delete; 这直接决定了 std::unique_ptr 没办法复制与相互赋值，这是语义上独享内存所有权的基石。\n我们再看析构：\n~unique_ptr() noexcept { if (_Mypair._Myval2) { _Mypair._Get_first()(_Mypair._Myval2); } } 比较简单，先判断 pair 中保存的裸指针是否为空，不为空的话则调用 pair 中保存的 deleter 来释放内存。\nstd::unique_ptr 和大部分 stl 类一样提供了 swap() 方法：\nvoid swap(unique_ptr\u0026amp; _Right) noexcept { _Swap_adl(_Mypair._Myval2, _Right._Mypair._Myval2); _Swap_adl(_Mypair._Get_first(), _Right._Mypair._Get_first()); } 有关删除器，std::unique_ptr 还提供了 getter 方法来获取删除器：\n_NODISCARD _Dx\u0026amp; get_deleter() noexcept { return _Mypair._Get_first(); } _NODISCARD const _Dx\u0026amp; get_deleter() const noexcept { return _Mypair._Get_first(); } 接下来看与指针息息相关的几个操作符重载：\n_NODISCARD add_lvalue_reference_t\u0026lt;_Ty\u0026gt; operator*() const noexcept /* strengthened */ { return *_Mypair._Myval2; } _NODISCARD pointer operator-\u0026gt;() const noexcept { return _Mypair._Myval2; } explicit operator bool() const noexcept { return static_cast\u0026lt;bool\u0026gt;(_Mypair._Myval2); } 这使得我们可以像使用普通指针一样使用 std::unique_ptr。\n最后是三个对裸指针的直接操作：\n_NODISCARD pointer get() const noexcept { return _Mypair._Myval2; } pointer release() noexcept { return _STD exchange(_Mypair._Myval2, nullptr); } void reset(pointer _Ptr = nullptr) noexcept { pointer _Old = _STD exchange(_Mypair._Myval2, _Ptr); if (_Old) { _Mypair._Get_first()(_Old); } } 从代码上可以看出来，get() 和 release() 并不会触发内存销毁，而 reset() 的内存销毁也是有条件的，只有 reset() 为空指针时才会触发销毁。\n整体上来看 std::unique_ptr 的代码并不算复杂，只是裸指针的一层封装而已。\nunique_ptr\u0026lt;_Ty[], _Dx\u0026gt; std::unique_ptr 还有另外一个定义，即：\ntemplate \u0026lt;class _Ty, class _Dx\u0026gt; class unique_ptr\u0026lt;_Ty[], _Dx\u0026gt;; 这个定义是针对数组的。大部分代码其实都跟前面相同，我们主要关注不一样的地方，首先是 default_delete 的特化：\ntemplate \u0026lt;class _Ty\u0026gt; struct default_delete\u0026lt;_Ty[]\u0026gt; { // default deleter for unique_ptr to array of unknown size constexpr default_delete() noexcept = default; template \u0026lt;class _Uty, enable_if_t\u0026lt;is_convertible_v\u0026lt;_Uty (*)[], _Ty (*)[]\u0026gt;, int\u0026gt; = 0\u0026gt; default_delete(const default_delete\u0026lt;_Uty[]\u0026gt;\u0026amp;) noexcept {} template \u0026lt;class _Uty, enable_if_t\u0026lt;is_convertible_v\u0026lt;_Uty (*)[], _Ty (*)[]\u0026gt;, int\u0026gt; = 0\u0026gt; void operator()(_Uty* _Ptr) const noexcept /* strengthened */ { // delete a pointer static_assert(0 \u0026lt; sizeof(_Uty), \u0026#34;can\u0026#39;t delete an incomplete type\u0026#34;); delete[] _Ptr; } }; 针对数组，这里的 operator() 的实现由 delete 改成了 delete[]。\n然后是一些操作符重载上的不同：\n_NODISCARD _Ty\u0026amp; operator[](size_t _Idx) const noexcept /* strengthened */ { return _Mypair._Myval2[_Idx]; } explicit operator bool() const noexcept { return static_cast\u0026lt;bool\u0026gt;(_Mypair._Myval2); } 与普通的 std::unique_ptr 不同的是，它不再提供 operator* 和 operator-\u0026gt;，取而代之的是 operator[]，这也与普通数组的操作一致。\n其他的一些代码，主要是构造、析构、operator=，基本都与普通的定义一致，就不再赘述了。\nmake_unique / make_unique_for_overwrite std::make_unique 的用法在前面也说过了，主要是用于更优雅地构造 std::unique_ptr 的，代码其实也很简单，只是一层简单的透传：\n// FUNCTION TEMPLATE make_unique template \u0026lt;class _Ty, class... _Types, enable_if_t\u0026lt;!is_array_v\u0026lt;_Ty\u0026gt;, int\u0026gt; = 0\u0026gt; _NODISCARD unique_ptr\u0026lt;_Ty\u0026gt; make_unique(_Types\u0026amp;\u0026amp;... _Args) { // make a unique_ptr return unique_ptr\u0026lt;_Ty\u0026gt;(new _Ty(_STD forward\u0026lt;_Types\u0026gt;(_Args)...)); } template \u0026lt;class _Ty, enable_if_t\u0026lt;is_array_v\u0026lt;_Ty\u0026gt; \u0026amp;\u0026amp; extent_v\u0026lt;_Ty\u0026gt; == 0, int\u0026gt; = 0\u0026gt; _NODISCARD unique_ptr\u0026lt;_Ty\u0026gt; make_unique(const size_t _Size) { // make a unique_ptr using _Elem = remove_extent_t\u0026lt;_Ty\u0026gt;; return unique_ptr\u0026lt;_Ty\u0026gt;(new _Elem[_Size]()); } template \u0026lt;class _Ty, class... _Types, enable_if_t\u0026lt;extent_v\u0026lt;_Ty\u0026gt; != 0, int\u0026gt; = 0\u0026gt; void make_unique(_Types\u0026amp;\u0026amp;...) = delete; 在 C++ 20 之后，标准库还提供了 std::make_unique_for_overwrite 来构造 std::unique_ptr，与 std::make_unique 的区别在于，它不需要传递额外参数，直接使用目标类型的默认构造，下面是源码：\n#if _HAS_CXX20 // FUNCTION TEMPLATE make_unique_for_overwrite template \u0026lt;class _Ty, enable_if_t\u0026lt;!is_array_v\u0026lt;_Ty\u0026gt;, int\u0026gt; = 0\u0026gt; _NODISCARD unique_ptr\u0026lt;_Ty\u0026gt; make_unique_for_overwrite() { // make a unique_ptr with default initialization return unique_ptr\u0026lt;_Ty\u0026gt;(new _Ty); } template \u0026lt;class _Ty, enable_if_t\u0026lt;is_unbounded_array_v\u0026lt;_Ty\u0026gt;, int\u0026gt; = 0\u0026gt; _NODISCARD unique_ptr\u0026lt;_Ty\u0026gt; make_unique_for_overwrite( const size_t _Size) { // make a unique_ptr with default initialization using _Elem = remove_extent_t\u0026lt;_Ty\u0026gt;; return unique_ptr\u0026lt;_Ty\u0026gt;(new _Elem[_Size]); } template \u0026lt;class _Ty, class... _Types, enable_if_t\u0026lt;is_bounded_array_v\u0026lt;_Ty\u0026gt;, int\u0026gt; = 0\u0026gt; void make_unique_for_overwrite(_Types\u0026amp;\u0026amp;...) = delete; #endif // _HAS_CXX20 也很简单，透传而已。\n总结 std::unique_ptr 有两个定义，分别针对普通类型和数组类型 std::unique_ptr 第二个模板参数是删除器，不传递的情况下使用的是 default_delete std::unique_ptr 重载了指针、数组相关的操作符，实现与裸指针类似的操作 std::unique_ptr 不允许拷贝，语义上表示一段内存的所有权，转移所有权需要使用 std::move 产生移动语义 std::unique_ptr 提供了 get() 和 release() 来直接对裸指针进行操作 std::unqiue_ptr 可以直接与 nullptr 比较，也可以使用 nullptr 赋值 可以使用 std::make_unique 和 std::make_unique_for_overwrite 来更方便地构造 std::unique_ptr ","date":"2021-09-26T00:00:00Z","permalink":"https://www.kindem.xyz/post/48/","title":"MSVC std::unique_ptr 源码解析"},{"content":"序 起因就是最近在做新版博客 KindemBlog 的 SEO 优化，工作之后也没时间耐心地做引流了，看能不能想想其他方法稍微拯救下博客惨淡的 PV。\n印象中百度的自动推送 URL 功能在今年还是去年的时候翻新了一次，翻新后的 API 不再是 GET 请求，而是 POST，再加上辣鸡百度新 API 的 Host 给的协议是 HTTP，这么一来使用 HTTPS 协议的站点就直接暴毙，没法再通过前端来发送 Ajax 请求来推送了，这对静态博客用户（比如我）可是毁灭性打击。\n一番思考后，我想到了 GitHub Actions，没错，就没有 Actions 搞不定的事情。整个方案的思路是先写一个 JavaScript 脚本来完成博客仓库下所有博客的扫描，扫描完成后把所有 URL 通过 POST 请求上报到百度的服务器去，然后再用 GitHub Actions 每日定时执行脚本即可。\n扫描与推送脚本 其实用 Python 写也可以，但一想到这又是一个展现我非凡的 JavaScript 技术的时候，就有点小激动，果断在博客根目录下：\nnpm init 之后先把依赖安装一哈：\nnpm install axios 然后编写脚本，放在 /scripts/baidu-auto-commit.js：\nconst Axios = require(\u0026#39;axios\u0026#39;); const FileSystem = require(\u0026#39;fs\u0026#39;); const config = { postDir: \u0026#39;content/post\u0026#39;, basePostUrl: \u0026#39;https://www.kindem.xyz/post\u0026#39;, targetHost: \u0026#39;http://data.zz.baidu.com/urls?site=https://www.kindem.xyz\u0026amp;token=lDsJO81mKXxekZI6\u0026#39;, fixedUrls: [ \u0026#39;https://www.kindem.xyz\u0026#39; ] }; function collectUrls() { const posts = FileSystem.readdirSync(config.postDir); return posts.map(post =\u0026gt; `${config.basePostUrl}/${post}`).concat(config.fixedUrls); } function concatUrls(urls) { let result = \u0026#39;\u0026#39;; urls.forEach(url =\u0026gt; { result += `${url}\\n`; }); return result; } async function commitData(data) { try { const result = await Axios({ url: config.targetHost, method: \u0026#39;post\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;plain/text\u0026#39; }, method: \u0026#39;post\u0026#39;, data: data }); const ret = result.data; console.log(\u0026#39;commit success\u0026#39;); console.log(`- success: ${ret.success}`); console.log(`- remain: ${ret.remain}`); } catch(e) { console.log(\u0026#39;failed to commit\u0026#39;); } } (async function() { const urls = collectUrls(); const data = concatUrls(urls); await commitData(data); })(); 很简单，就是先扫描目录下的所有文章，然后 mapped 成目标 URL，最后通过 Axios POST 到百度的服务器即可。token 字段来自于百度站长平台，其实这里可以稍微增加点安全性，把 token 通过命令行传递，然后再透过 GitHub 仓库的环境变量传进来，但我实在是懒，再说也没有人会无聊到连这都要攻击一把吧，我小破站也没啥好攻的，如果后面实在出问题了，再考虑改吧，现阶段能用就行。\nGitHub Actions 脚本链接在 KindemBlog/workflows/baidu-urls-auto-commit.yml，也可以直接看下面的代码：\nname: Baidu Urls Auto Commit on: workflow_dispatch: schedule: - cron: \u0026#39;0 2 * * *\u0026#39; jobs: build: runs-on: ubuntu-latest steps: - name: Checkout Repo uses: actions/checkout@v2 - name: Setup Node.js uses: actions/setup-node@v2 with: cache: \u0026#39;npm\u0026#39; - name: Install NPM dependencies run: npm install - name: Auto Commit Urls To Baidu Spider Server run: node scripts/baidu-auto-commit.js 很简单的 Actions，北京时间（+8 时区）上午 10 点自动执行，当然也可以手动 dispatch，Actions 触发后会自动安装 Node.js，然后安装依赖，最后执行上面写的脚本，这样整个流程就 OK 啦~\n效果 效果图 很明显可以看见，自从加上了这段脚本，妈妈再也不用担心百度不知道我刷新博客啦~\n","date":"2021-09-02T00:00:00Z","permalink":"https://www.kindem.xyz/post/47/","title":"使用 GitHub Actions 自动推送 URL 至百度站长平台"},{"content":"std::any 介绍 std::any 是 c++17 标准新提供的类，作用是存储任意类型的一段内存，并可以重复赋值，在赋值后可以使用 std::any_cast 将 std::any 所存储的值转换成特定类型，如果 std::any 中存储的值的类型与目标类型不匹配，则会抛出 std::bad_any_cast 异常。\n下面是一些简单的 Sample Code（MSVC 16 2019 64Bit 运行）：\nstd::any value = 1.0; // 1 std::cout \u0026lt;\u0026lt; any_cast\u0026lt;double\u0026gt;(value) \u0026lt;\u0026lt; std::endl; // 抛出 std::bad_any_cast 异常 std::cout \u0026lt;\u0026lt; any_cast\u0026lt;float\u0026gt;(value) \u0026lt;\u0026lt; std::endl; // 抛出 std::bad_any_cast 异常 std::cout \u0026lt;\u0026lt; any_cast\u0026lt;int\u0026gt;(value) \u0026lt;\u0026lt; std::endl; 指针示例：\nstd::any value1 = nullptr; // nullptr std::cout \u0026lt;\u0026lt; any_cast\u0026lt;nullptr_t\u0026gt;(value1) \u0026lt;\u0026lt; std::endl; // 抛出 std::bad_any_cast 异常 std::cout \u0026lt;\u0026lt; any_cast\u0026lt;int*\u0026gt;(value1) \u0026lt;\u0026lt; std::endl; std::any value2 = (int*) (nullptr); // 抛出 std::bad_any_cast 异常 std::cout \u0026lt;\u0026lt; any_cast\u0026lt;nullptr_t\u0026gt;(value2) \u0026lt;\u0026lt; std::endl; // 0000000000000000 std::cout \u0026lt;\u0026lt; any_cast\u0026lt;int*\u0026gt;(value2) \u0026lt;\u0026lt; std::endl; 空 std::any 示例：\nstd::any value; // 抛出 std::bad_any_cast 异常 std::cout \u0026lt;\u0026lt; any_cast\u0026lt;int\u0026gt;(value) \u0026lt;\u0026lt; std::endl; 结构体：\nstruct Hello { int a; int b; }; std::any value = Hello { .a = 1, .b = 2 }; auto v = any_cast\u0026lt;Hello\u0026gt;(value); // a: 1, b: 2 std::cout \u0026lt;\u0026lt; \u0026#34;a: \u0026#34; \u0026lt;\u0026lt; v.a \u0026lt;\u0026lt; \u0026#34;, b: \u0026#34; \u0026lt;\u0026lt; v.b \u0026lt;\u0026lt; std::endl; 需要注意的是，这里 any_cast 得到的是拷贝，如果需要更高效的操作，可以获取指针或者引用：\nstd::any value = Hello { .a = 1, .b = 2 }; auto* v0 = any_cast\u0026lt;Hello\u0026gt;(\u0026amp;value); // a: 1, b: 2 std::cout \u0026lt;\u0026lt; \u0026#34;a: \u0026#34; \u0026lt;\u0026lt; v0-\u0026gt;a \u0026lt;\u0026lt; \u0026#34;, b: \u0026#34; \u0026lt;\u0026lt; v0-\u0026gt;b \u0026lt;\u0026lt; std::endl; auto\u0026amp; v1 = any_cast\u0026lt;Hello\u0026amp;\u0026gt;(value); // a: 1, b: 2 std::cout \u0026lt;\u0026lt; \u0026#34;a: \u0026#34; \u0026lt;\u0026lt; v1.a \u0026lt;\u0026lt; \u0026#34;, b: \u0026#34; \u0026lt;\u0026lt; v1.b \u0026lt;\u0026lt; std::endl; 获取指针时，any_cast 的入参也需要是指针，而获取引用则 any_cast 的模板参数需要为引用类型。\n源码阅读 下面的源码解析基于 MSVC 16 2019，其他编译器可能略有不同。\n异常 先看看 any_cast 失败后抛出的异常 bad_any_cast：\n// CLASS bad_any_cast class bad_any_cast : public bad_cast { // thrown by failed any_cast public: _NODISCARD virtual const char* __CLR_OR_THIS_CALL what() const noexcept override { return \u0026#34;Bad any_cast\u0026#34;; } }; [[noreturn]] inline void _Throw_bad_any_cast() { _THROW(bad_any_cast{}); } 内存类型 std::any 将保存内容的内存形式分为了三种：\nSmall Trivial Big 定义如下：\nenum class _Any_representation : uintptr_t { _Trivial, _Big, _Small }; 划分规则为：\nconstexpr int _Small_object_num_ptrs = 6 + 16 / sizeof(void*); inline constexpr size_t _Any_trivial_space_size = (_Small_object_num_ptrs - 1) * sizeof(void*); template \u0026lt;class _Ty\u0026gt; inline constexpr bool _Any_is_trivial = alignof(_Ty) \u0026lt;= alignof(max_align_t) \u0026amp;\u0026amp; is_trivially_copyable_v\u0026lt;_Ty\u0026gt; \u0026amp;\u0026amp; sizeof(_Ty) \u0026lt;= _Any_trivial_space_size; inline constexpr size_t _Any_small_space_size = (_Small_object_num_ptrs - 2) * sizeof(void*); template \u0026lt;class _Ty\u0026gt; inline constexpr bool _Any_is_small = alignof(_Ty) \u0026lt;= alignof(max_align_t) \u0026amp;\u0026amp; is_nothrow_move_constructible_v\u0026lt;_Ty\u0026gt; \u0026amp;\u0026amp; sizeof(_Ty) \u0026lt;= _Any_small_space_size; 简单来说，满足 _Any_is_trivial 则为 Trivial 类型内存，满足 _Any_is_small 则为 Small 类型内存，其余的则为 Big 类型内存。\n在 64 位系统下，划分规则可以解释为：\n_Any_is_small：类型长度小于等于 48 字节，内存对齐长度小于等于 8 字节，拥有具备 nothrow 声明的移动构造 _Any_is_trivial：类型长度小于等于 56 字节，内存对齐长度小于等于 8 字节，可平凡拷贝（基本数据类型、可平凡拷贝的聚合类型、以上类型的数组等） 下面是一些 _Any_is_small 和 _Any_is_trivial 判断的实测值：\nstruct Test1 { char a[48]; }; struct Test2 { char a[56]; }; struct Test3 { Test3(Test3\u0026amp;\u0026amp; other) { memcpy(a, other.a, sizeof(Test3)); } char a[48] {}; }; struct Test4 { int\u0026amp; a; }; struct Test5 { virtual void a() = 0; }; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_small\u0026lt;char\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_small\u0026lt;int\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_small\u0026lt;double\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_small\u0026lt;Test1\u0026gt; \u0026lt;\u0026lt; std::endl; // 0, sizeof(Test2) \u0026gt; _Any_trivial_space_size std::cout \u0026lt;\u0026lt; std::_Any_is_small\u0026lt;Test2\u0026gt; \u0026lt;\u0026lt; std::endl; // 0, is_nothrow_move_constructible_v\u0026lt;_Ty\u0026gt; == false std::cout \u0026lt;\u0026lt; std::_Any_is_small\u0026lt;Test3\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_small\u0026lt;Test4\u0026gt; \u0026lt;\u0026lt; std::endl; // 0, is_nothrow_move_constructible_v\u0026lt;_Ty\u0026gt; == false std::cout \u0026lt;\u0026lt; std::_Any_is_small\u0026lt;Test5\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_trivial\u0026lt;char\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_trivial\u0026lt;int\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_trivial\u0026lt;double\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_trivial\u0026lt;Test1\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_trivial\u0026lt;Test2\u0026gt; \u0026lt;\u0026lt; std::endl; // 0, is_trivially_copyable_v == false std::cout \u0026lt;\u0026lt; std::_Any_is_trivial\u0026lt;Test3\u0026gt; \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; std::_Any_is_trivial\u0026lt;Test4\u0026gt; \u0026lt;\u0026lt; std::endl; // 0, is_trivially_copyable_v == false std::cout \u0026lt;\u0026lt; std::_Any_is_trivial\u0026lt;Test5\u0026gt; \u0026lt;\u0026lt; std::endl; RTTI Trivial 类型的内存是直接对拷的，对于这种内存无需再添加额外的生命周期指针。按照 Small 内存的定义，对于 Small 内存要添加 in_place 的销毁、拷贝、移动函数指针，而 Big 则需要保存堆内存的拷贝与销毁函数指针。源码中定义了 _Any_small_RTTI 和 _Any_big_RTTI 结构体，来存储这些指针：\nstruct _Any_big_RTTI { // Hand-rolled vtable for types that must be heap allocated in an any using _Destroy_fn = void __CLRCALL_PURE_OR_CDECL(void*) _NOEXCEPT_FNPTR; using _Copy_fn = void* __CLRCALL_PURE_OR_CDECL(const void*); template \u0026lt;class _Ty\u0026gt; static void __CLRCALL_PURE_OR_CDECL _Destroy_impl(void* const _Target) noexcept { ::delete static_cast\u0026lt;_Ty*\u0026gt;(_Target); } template \u0026lt;class _Ty\u0026gt; _NODISCARD static void* __CLRCALL_PURE_OR_CDECL _Copy_impl(const void* const _Source) { return ::new _Ty(*static_cast\u0026lt;const _Ty*\u0026gt;(_Source)); } _Destroy_fn* _Destroy; _Copy_fn* _Copy; }; struct _Any_small_RTTI { // Hand-rolled vtable for nontrivial types that can be stored internally in an any using _Destroy_fn = void __CLRCALL_PURE_OR_CDECL(void*) _NOEXCEPT_FNPTR; using _Copy_fn = void __CLRCALL_PURE_OR_CDECL(void*, const void*); using _Move_fn = void __CLRCALL_PURE_OR_CDECL(void*, void*) _NOEXCEPT_FNPTR; template \u0026lt;class _Ty\u0026gt; static void __CLRCALL_PURE_OR_CDECL _Destroy_impl(void* const _Target) noexcept { _Destroy_in_place(*static_cast\u0026lt;_Ty*\u0026gt;(_Target)); } template \u0026lt;class _Ty\u0026gt; static void __CLRCALL_PURE_OR_CDECL _Copy_impl(void* const _Target, const void* const _Source) { _Construct_in_place(*static_cast\u0026lt;_Ty*\u0026gt;(_Target), *static_cast\u0026lt;const _Ty*\u0026gt;(_Source)); } template \u0026lt;class _Ty\u0026gt; static void __CLRCALL_PURE_OR_CDECL _Move_impl(void* const _Target, void* const _Source) noexcept { _Construct_in_place(*static_cast\u0026lt;_Ty*\u0026gt;(_Target), _STD move(*static_cast\u0026lt;_Ty*\u0026gt;(_Source))); } _Destroy_fn* _Destroy; _Copy_fn* _Copy; _Move_fn* _Move; }; 结构体中首先有对应的函数指针，另外，还提供了带模板的静态实现方法，实际用法是定义模板变量来保存 RTTI 结构体实例，实例中保存对应模板静态方法的指针，来为不同的类型提供 RTTI 功能：\ntemplate \u0026lt;class _Ty\u0026gt; inline constexpr _Any_big_RTTI _Any_big_RTTI_obj = { \u0026amp;_Any_big_RTTI::_Destroy_impl\u0026lt;_Ty\u0026gt;, \u0026amp;_Any_big_RTTI::_Copy_impl\u0026lt;_Ty\u0026gt;}; template \u0026lt;class _Ty\u0026gt; inline constexpr _Any_small_RTTI _Any_small_RTTI_obj = { \u0026amp;_Any_small_RTTI::_Destroy_impl\u0026lt;_Ty\u0026gt;, \u0026amp;_Any_small_RTTI::_Copy_impl\u0026lt;_Ty\u0026gt;, \u0026amp;_Any_small_RTTI::_Move_impl\u0026lt;_Ty\u0026gt;}; any 分段来看 std::any 的源码，首先是构造：\nconstexpr any() noexcept {} any(const any\u0026amp; _That) { _Storage._TypeData = _That._Storage._TypeData; switch (_Rep()) { case _Any_representation::_Small: _Storage._SmallStorage._RTTI = _That._Storage._SmallStorage._RTTI; _Storage._SmallStorage._RTTI-\u0026gt;_Copy(\u0026amp;_Storage._SmallStorage._Data, \u0026amp;_That._Storage._SmallStorage._Data); break; case _Any_representation::_Big: _Storage._BigStorage._RTTI = _That._Storage._BigStorage._RTTI; _Storage._BigStorage._Ptr = _Storage._BigStorage._RTTI-\u0026gt;_Copy(_That._Storage._BigStorage._Ptr); break; case _Any_representation::_Trivial: default: _CSTD memcpy(_Storage._TrivialData, _That._Storage._TrivialData, sizeof(_Storage._TrivialData)); break; } } any(any\u0026amp;\u0026amp; _That) noexcept { _Move_from(_That); } template \u0026lt;class _ValueType, enable_if_t\u0026lt;conjunction_v\u0026lt;negation\u0026lt;is_same\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;, any\u0026gt;\u0026gt;, negation\u0026lt;_Is_specialization\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;, in_place_type_t\u0026gt;\u0026gt;, is_copy_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; any(_ValueType\u0026amp;\u0026amp; _Value) { // initialize with _Value _Emplace\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;(_STD forward\u0026lt;_ValueType\u0026gt;(_Value)); } template \u0026lt;class _ValueType, class... _Types, enable_if_t\u0026lt; conjunction_v\u0026lt;is_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;, _Types...\u0026gt;, is_copy_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; explicit any(in_place_type_t\u0026lt;_ValueType\u0026gt;, _Types\u0026amp;\u0026amp;... _Args) { // in-place initialize a value of type decay_t\u0026lt;_ValueType\u0026gt; with _Args... _Emplace\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;(_STD forward\u0026lt;_Types\u0026gt;(_Args)...); } template \u0026lt;class _ValueType, class _Elem, class... _Types, enable_if_t\u0026lt;conjunction_v\u0026lt;is_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;, initializer_list\u0026lt;_Elem\u0026gt;\u0026amp;, _Types...\u0026gt;, is_copy_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; explicit any(in_place_type_t\u0026lt;_ValueType\u0026gt;, initializer_list\u0026lt;_Elem\u0026gt; _Ilist, _Types\u0026amp;\u0026amp;... _Args) { // in-place initialize a value of type decay_t\u0026lt;_ValueType\u0026gt; with _Ilist and _Args... _Emplace\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;(_Ilist, _STD forward\u0026lt;_Types\u0026gt;(_Args)...); } 拷贝构造对应三种内存形态有着不同的拷贝方式，对于 Trivial 内存，直接 memcpy 对拷，对于 Small 和 Big 内存，则拷贝 RTTI 并调用 RTTI 结构体中对应的拷贝函数来做拷贝操作。移动构造和其他构造最终会调用到内部方法 _Move_from 和 _Emplace，下面是定义：\nvoid _Move_from(any\u0026amp; _That) noexcept { _Storage._TypeData = _That._Storage._TypeData; switch (_Rep()) { case _Any_representation::_Small: _Storage._SmallStorage._RTTI = _That._Storage._SmallStorage._RTTI; _Storage._SmallStorage._RTTI-\u0026gt;_Move(\u0026amp;_Storage._SmallStorage._Data, \u0026amp;_That._Storage._SmallStorage._Data); break; case _Any_representation::_Big: _Storage._BigStorage._RTTI = _That._Storage._BigStorage._RTTI; _Storage._BigStorage._Ptr = _That._Storage._BigStorage._Ptr; _That._Storage._TypeData = 0; break; case _Any_representation::_Trivial: default: _CSTD memcpy(_Storage._TrivialData, _That._Storage._TrivialData, sizeof(_Storage._TrivialData)); break; } } template \u0026lt;class _Decayed, class... _Types\u0026gt; _Decayed\u0026amp; _Emplace(_Types\u0026amp;\u0026amp;... _Args) { // emplace construct _Decayed if constexpr (_Any_is_trivial\u0026lt;_Decayed\u0026gt;) { // using the _Trivial representation auto\u0026amp; _Obj = reinterpret_cast\u0026lt;_Decayed\u0026amp;\u0026gt;(_Storage._TrivialData); _Construct_in_place(_Obj, _STD forward\u0026lt;_Types\u0026gt;(_Args)...); _Storage._TypeData = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;typeid(_Decayed)) | static_cast\u0026lt;uintptr_t\u0026gt;(_Any_representation::_Trivial); return _Obj; } else if constexpr (_Any_is_small\u0026lt;_Decayed\u0026gt;) { // using the _Small representation auto\u0026amp; _Obj = reinterpret_cast\u0026lt;_Decayed\u0026amp;\u0026gt;(_Storage._SmallStorage._Data); _Construct_in_place(_Obj, _STD forward\u0026lt;_Types\u0026gt;(_Args)...); _Storage._SmallStorage._RTTI = \u0026amp;_Any_small_RTTI_obj\u0026lt;_Decayed\u0026gt;; _Storage._TypeData = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;typeid(_Decayed)) | static_cast\u0026lt;uintptr_t\u0026gt;(_Any_representation::_Small); return _Obj; } else { // using the _Big representation _Decayed* const _Ptr = ::new _Decayed(_STD forward\u0026lt;_Types\u0026gt;(_Args)...); _Storage._BigStorage._Ptr = _Ptr; _Storage._BigStorage._RTTI = \u0026amp;_Any_big_RTTI_obj\u0026lt;_Decayed\u0026gt;; _Storage._TypeData = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;typeid(_Decayed)) | static_cast\u0026lt;uintptr_t\u0026gt;(_Any_representation::_Big); return *_Ptr; } } _Move_from 与拷贝构造中做的事情类似，只是操作改成了 _Move，另外，对于 Big 内存，直接拷贝指针，这个也很好理解。_Emplace 中则是针对不同内存创建 _Storage，这里要注意的是 _TypeData 的处理手法，是取类型对应的 std::type_info 指针并与 enum 定义指针相或，从而取得每个类型独一无二的一个 id。\n下面来看 _Storage 的定义：\nstruct _Small_storage_t { unsigned char _Data[_Any_small_space_size]; const _Any_small_RTTI* _RTTI; }; static_assert(sizeof(_Small_storage_t) == _Any_trivial_space_size); struct _Big_storage_t { // Pad so that _Ptr and _RTTI might share _TypeData\u0026#39;s cache line unsigned char _Padding[_Any_small_space_size - sizeof(void*)]; void* _Ptr; const _Any_big_RTTI* _RTTI; }; static_assert(sizeof(_Big_storage_t) == _Any_trivial_space_size); struct _Storage_t { union { unsigned char _TrivialData[_Any_trivial_space_size]; _Small_storage_t _SmallStorage; _Big_storage_t _BigStorage; }; uintptr_t _TypeData; }; static_assert(sizeof(_Storage_t) == _Any_trivial_space_size + sizeof(void*)); static_assert(is_standard_layout_v\u0026lt;_Storage_t\u0026gt;); union { _Storage_t _Storage{}; max_align_t _Dummy; }; 跟上面说的一样，Small 内存和 Big 内存还需要额外保存一个 RTTI 结构体指针，用于管理生命周期，_Storage_t 本身则是一个 union，由 _SmallStorage、_BigStorage、_TrivialData 组成，此外，还保存了一个 _TypeData，即一个唯一的类型 id，之后会用于 std::any_cast 的类型校验。\n再看其余部分就很简单了，首先是析构和 operator=：\n~any() noexcept { reset(); } // Assignment [any.assign] any\u0026amp; operator=(const any\u0026amp; _That) { *this = any{_That}; return *this; } any\u0026amp; operator=(any\u0026amp;\u0026amp; _That) noexcept { reset(); _Move_from(_That); return *this; } template \u0026lt;class _ValueType, enable_if_t\u0026lt;conjunction_v\u0026lt;negation\u0026lt;is_same\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;, any\u0026gt;\u0026gt;, is_copy_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; any\u0026amp; operator=(_ValueType\u0026amp;\u0026amp; _Value) { // replace contained value with an object of type decay_t\u0026lt;_ValueType\u0026gt; initialized from _Value *this = any{_STD forward\u0026lt;_ValueType\u0026gt;(_Value)}; return *this; } 然后是一些 std::any 提供的接口：\ntemplate \u0026lt;class _ValueType, class... _Types, enable_if_t\u0026lt; conjunction_v\u0026lt;is_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;, _Types...\u0026gt;, is_copy_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; decay_t\u0026lt;_ValueType\u0026gt;\u0026amp; emplace(_Types\u0026amp;\u0026amp;... _Args) { // replace contained value with an object of type decay_t\u0026lt;_ValueType\u0026gt; initialized from _Args... reset(); return _Emplace\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;(_STD forward\u0026lt;_Types\u0026gt;(_Args)...); } template \u0026lt;class _ValueType, class _Elem, class... _Types, enable_if_t\u0026lt;conjunction_v\u0026lt;is_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;, initializer_list\u0026lt;_Elem\u0026gt;\u0026amp;, _Types...\u0026gt;, is_copy_constructible\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;\u0026gt;, int\u0026gt; = 0\u0026gt; decay_t\u0026lt;_ValueType\u0026gt;\u0026amp; emplace(initializer_list\u0026lt;_Elem\u0026gt; _Ilist, _Types\u0026amp;\u0026amp;... _Args) { // replace contained value with an object of type decay_t\u0026lt;_ValueType\u0026gt; initialized from _Ilist and _Args... reset(); return _Emplace\u0026lt;decay_t\u0026lt;_ValueType\u0026gt;\u0026gt;(_Ilist, _STD forward\u0026lt;_Types\u0026gt;(_Args)...); } void reset() noexcept { // transition to the empty state switch (_Rep()) { case _Any_representation::_Small: _Storage._SmallStorage._RTTI-\u0026gt;_Destroy(\u0026amp;_Storage._SmallStorage._Data); break; case _Any_representation::_Big: _Storage._BigStorage._RTTI-\u0026gt;_Destroy(_Storage._BigStorage._Ptr); break; case _Any_representation::_Trivial: default: break; } _Storage._TypeData = 0; } void swap(any\u0026amp; _That) noexcept { _That = _STD exchange(*this, _STD move(_That)); } // Observers [any.observers] _NODISCARD bool has_value() const noexcept { return _Storage._TypeData != 0; } _NODISCARD const type_info\u0026amp; type() const noexcept { // if *this contains a value of type T, return typeid(T); otherwise typeid(void) const type_info* const _Info = _TypeInfo(); if (_Info) { return *_Info; } return typeid(void); } template \u0026lt;class _Decayed\u0026gt; _NODISCARD const _Decayed* _Cast() const noexcept { // if *this contains a value of type _Decayed, return a pointer to it const type_info* const _Info = _TypeInfo(); if (!_Info || *_Info != typeid(_Decayed)) { return nullptr; } if constexpr (_Any_is_trivial\u0026lt;_Decayed\u0026gt;) { // get a pointer to the contained _Trivial value of type _Decayed return reinterpret_cast\u0026lt;const _Decayed*\u0026gt;(\u0026amp;_Storage._TrivialData); } else if constexpr (_Any_is_small\u0026lt;_Decayed\u0026gt;) { // get a pointer to the contained _Small value of type _Decayed return reinterpret_cast\u0026lt;const _Decayed*\u0026gt;(\u0026amp;_Storage._SmallStorage._Data); } else { // get a pointer to the contained _Big value of type _Decayed return static_cast\u0026lt;const _Decayed*\u0026gt;(_Storage._BigStorage._Ptr); } } template \u0026lt;class _Decayed\u0026gt; _NODISCARD _Decayed* _Cast() noexcept { // if *this contains a value of type _Decayed, return a pointer to it return const_cast\u0026lt;_Decayed*\u0026gt;(static_cast\u0026lt;const any*\u0026gt;(this)-\u0026gt;_Cast\u0026lt;_Decayed\u0026gt;()); } static constexpr uintptr_t _Rep_mask = 3; _NODISCARD _Any_representation _Rep() const noexcept { // extract the representation format from _TypeData return static_cast\u0026lt;_Any_representation\u0026gt;(_Storage._TypeData \u0026amp; _Rep_mask); } _NODISCARD const type_info* _TypeInfo() const noexcept { // extract the type_info from _TypeData return reinterpret_cast\u0026lt;const type_info*\u0026gt;(_Storage._TypeData \u0026amp; ~_Rep_mask); } 也都不复杂， 就不再多说了。\nmake_any / any_cast 先看平时用的不多的 std::make_any：\ntemplate \u0026lt;class _ValueType, class... _Types\u0026gt; _NODISCARD any make_any(_Types\u0026amp;\u0026amp;... _Args) { // construct an any containing a _ValueType initialized with _Args... return any{in_place_type\u0026lt;_ValueType\u0026gt;, _STD forward\u0026lt;_Types\u0026gt;(_Args)...}; } template \u0026lt;class _ValueType, class _Elem, class... _Types\u0026gt; _NODISCARD any make_any(initializer_list\u0026lt;_Elem\u0026gt; _Ilist, _Types\u0026amp;\u0026amp;... _Args) { // construct an any containing a _ValueType initialized with _Ilist and _Args... return any{in_place_type\u0026lt;_ValueType\u0026gt;, _Ilist, _STD forward\u0026lt;_Types\u0026gt;(_Args)...}; } 就是将参数透传到 std::any 的初始化列表构造并执行。\n然后是 std::any_cast：\ntemplate \u0026lt;class _ValueType\u0026gt; _NODISCARD const _ValueType* any_cast(const any* const _Any) noexcept { // retrieve a pointer to the _ValueType contained in _Any, or null static_assert(!is_void_v\u0026lt;_ValueType\u0026gt;, \u0026#34;std::any cannot contain void.\u0026#34;); if constexpr (is_function_v\u0026lt;_ValueType\u0026gt; || is_array_v\u0026lt;_ValueType\u0026gt;) { return nullptr; } else { if (!_Any) { return nullptr; } return _Any-\u0026gt;_Cast\u0026lt;_Remove_cvref_t\u0026lt;_ValueType\u0026gt;\u0026gt;(); } } template \u0026lt;class _ValueType\u0026gt; _NODISCARD _ValueType* any_cast(any* const _Any) noexcept { // retrieve a pointer to the _ValueType contained in _Any, or null static_assert(!is_void_v\u0026lt;_ValueType\u0026gt;, \u0026#34;std::any cannot contain void.\u0026#34;); if constexpr (is_function_v\u0026lt;_ValueType\u0026gt; || is_array_v\u0026lt;_ValueType\u0026gt;) { return nullptr; } else { if (!_Any) { return nullptr; } return _Any-\u0026gt;_Cast\u0026lt;_Remove_cvref_t\u0026lt;_ValueType\u0026gt;\u0026gt;(); } } template \u0026lt;class _Ty\u0026gt; _NODISCARD remove_cv_t\u0026lt;_Ty\u0026gt; any_cast(const any\u0026amp; _Any) { static_assert(is_constructible_v\u0026lt;remove_cv_t\u0026lt;_Ty\u0026gt;, const _Remove_cvref_t\u0026lt;_Ty\u0026gt;\u0026amp;\u0026gt;, \u0026#34;any_cast\u0026lt;T\u0026gt;(const any\u0026amp;) requires remove_cv_t\u0026lt;T\u0026gt; to be constructible from \u0026#34; \u0026#34;const remove_cv_t\u0026lt;remove_reference_t\u0026lt;T\u0026gt;\u0026gt;\u0026amp;\u0026#34;); const auto _Ptr = _STD any_cast\u0026lt;_Remove_cvref_t\u0026lt;_Ty\u0026gt;\u0026gt;(\u0026amp;_Any); if (!_Ptr) { _Throw_bad_any_cast(); } return static_cast\u0026lt;remove_cv_t\u0026lt;_Ty\u0026gt;\u0026gt;(*_Ptr); } template \u0026lt;class _Ty\u0026gt; _NODISCARD remove_cv_t\u0026lt;_Ty\u0026gt; any_cast(any\u0026amp; _Any) { static_assert(is_constructible_v\u0026lt;remove_cv_t\u0026lt;_Ty\u0026gt;, _Remove_cvref_t\u0026lt;_Ty\u0026gt;\u0026amp;\u0026gt;, \u0026#34;any_cast\u0026lt;T\u0026gt;(any\u0026amp;) requires remove_cv_t\u0026lt;T\u0026gt; to be constructible from remove_cv_t\u0026lt;remove_reference_t\u0026lt;T\u0026gt;\u0026gt;\u0026amp;\u0026#34;); const auto _Ptr = _STD any_cast\u0026lt;_Remove_cvref_t\u0026lt;_Ty\u0026gt;\u0026gt;(\u0026amp;_Any); if (!_Ptr) { _Throw_bad_any_cast(); } return static_cast\u0026lt;remove_cv_t\u0026lt;_Ty\u0026gt;\u0026gt;(*_Ptr); } template \u0026lt;class _Ty\u0026gt; _NODISCARD remove_cv_t\u0026lt;_Ty\u0026gt; any_cast(any\u0026amp;\u0026amp; _Any) { static_assert(is_constructible_v\u0026lt;remove_cv_t\u0026lt;_Ty\u0026gt;, _Remove_cvref_t\u0026lt;_Ty\u0026gt;\u0026gt;, \u0026#34;any_cast\u0026lt;T\u0026gt;(any\u0026amp;\u0026amp;) requires remove_cv_t\u0026lt;T\u0026gt; to be constructible from remove_cv_t\u0026lt;remove_reference_t\u0026lt;T\u0026gt;\u0026gt;\u0026#34;); const auto _Ptr = _STD any_cast\u0026lt;_Remove_cvref_t\u0026lt;_Ty\u0026gt;\u0026gt;(\u0026amp;_Any); if (!_Ptr) { _Throw_bad_any_cast(); } return static_cast\u0026lt;remove_cv_t\u0026lt;_Ty\u0026gt;\u0026gt;(_STD move(*_Ptr)); } 所有 std::any_cast 最终都会先取保存的 std::type_info 然后与目标类型相比较，失败则抛出 std::bad_any_cast，否则则返回 value。这里要注意的是返回的类型会根据 std::any_cast 的入参产生变化：\nconst any* const -\u0026gt; const _ValueType* any* const _Any -\u0026gt; _ValueType* const any\u0026amp; _Any -\u0026gt; remove_cv_t\u0026lt;_Ty\u0026gt; any\u0026amp; _Any -\u0026gt; remove_cv_t\u0026lt;_Ty\u0026gt; any\u0026amp;\u0026amp; _Any -\u0026gt; remove_cv_t\u0026lt;_Ty\u0026gt; 总结起来就是入参的 std::any 为指针时，返回指针，否则返回 remove_cv_t\u0026lt;_Ty\u0026gt;，所以使用时如果对应的是结构体 / 类，应该尽量获取指针或者引用来保持高效，避免内存拷贝降低性能（例子可以看文首的介绍）。\n总结 std::any 可以用于保存任意内存 std::any 内部将内存分为 Trivial、Small、Big 三种，Trivial 内存直接对拷，Small 内存需要保存额外的拷贝、移动、销毁指针，具体操作是 in_place 的，Big 内存需要保存额外的拷贝、销毁指针，具体操作是堆内存的 new、delete std::any 内部保存了 std::type_info 的指针，用于 std::any_cast 校验类型 std::any_cast 会依据 std::type_info 做类型校验 std::any_cast 的返回值会根据入参类型发生变化，入参为指针则返回指针，否则返回 remove_cv_t\u0026lt;_Ty\u0026gt; ","date":"2021-08-28T00:00:00Z","permalink":"https://www.kindem.xyz/post/46/","title":"MSVC std::any 源码解析"},{"content":"编译期序列 最近看到一个很有意思的模板写法：\ntemplate \u0026lt;size_t... S\u0026gt; struct IndexSequence {}; template \u0026lt;size_t N, size_t... S\u0026gt; struct IndexSequenceMaker : public IndexSequenceMaker\u0026lt;N - 1, N - 1, S...\u0026gt; {}; template \u0026lt;size_t... S\u0026gt; struct IndexSequenceMaker\u0026lt;0, S...\u0026gt; { using Type = IndexSequence\u0026lt;S...\u0026gt;; }; template \u0026lt;size_t N\u0026gt; using MakeIndexSequence = typename IndexSequenceMaker\u0026lt;N\u0026gt;::Type; 乍一看啥玩意儿，仔细看会发现它的作用是生成一个编译期序列，如：\n// IndexSequence\u0026lt;0, 1, 2, 3, 4\u0026gt; MakeIndexSequence\u0026lt;5\u0026gt; 它的实现非常巧妙，我们以上面这个例子为切入点，按照它的思路去展开模板：\ntemplate \u0026lt;\u0026gt; struct IndexSequenceMaker\u0026lt;0, 0, 1, 2, 3, 4\u0026gt; { using Type = IndexSequence\u0026lt;0, 1, 2, 3, 4\u0026gt;; } template \u0026lt;\u0026gt; struct IndexSequenceMaker\u0026lt;1, 1, 2, 3, 4\u0026gt; : public IndexSequenceMaker\u0026lt;0, 0, 1, 2, 3, 4\u0026gt; {} template \u0026lt;\u0026gt; struct IndexSequenceMaker\u0026lt;2, 2, 3, 4\u0026gt; : public IndexSequenceMaker\u0026lt;1, 1, 2, 3, 4\u0026gt;; template \u0026lt;\u0026gt; struct IndexSequenceMaker\u0026lt;3, 3, 4\u0026gt; : public IndexSequenceMaker\u0026lt;2, 2, 3, 4\u0026gt;; template \u0026lt;\u0026gt; struct IndexSequenceMaker\u0026lt;4, 4\u0026gt; : public IndexSequenceMaker\u0026lt;3, 3, 4\u0026gt;; template \u0026lt;\u0026gt; struct IndexSequenceMaker\u0026lt;5\u0026gt; : public IndexSequenceMaker\u0026lt;4, 4\u0026gt; {} template \u0026lt;\u0026gt; using MakeIndexSequence\u0026lt;5\u0026gt; = typename IndexSequenceMaker\u0026lt;5\u0026gt;::Type; 秒懂了，利用继承关系来传递不断生成的序列可变参，最后以 N = 0 的特化来终止生成。\n使用编译期序列来做 std::tuple 遍历 编译期序列最大的作用就是用于 std::tuple 的遍历，下面是一段 c++ 11 的代码：\ntemplate \u0026lt;size_t... S\u0026gt; struct IndexSequence {}; template \u0026lt;size_t N, size_t... S\u0026gt; struct IndexSequenceMaker : public IndexSequenceMaker\u0026lt;N - 1, N - 1, S...\u0026gt; {}; template \u0026lt;size_t... S\u0026gt; struct IndexSequenceMaker\u0026lt;0, S...\u0026gt; { using Type = IndexSequence\u0026lt;S...\u0026gt;; }; template \u0026lt;size_t N\u0026gt; using MakeIndexSequence = typename IndexSequenceMaker\u0026lt;N\u0026gt;::Type; template \u0026lt;typename T, typename F\u0026gt; void ForEachTuple(T\u0026amp;\u0026amp; tuple, F\u0026amp;\u0026amp; consumer) { ForEachTupleInternal(std::forward\u0026lt;T\u0026gt;(tuple), std::forward\u0026lt;F\u0026gt;(consumer), MakeIndexSequence\u0026lt;std::tuple_size\u0026lt;T\u0026gt;::value\u0026gt; {}); } template \u0026lt;typename T, typename F, size_t... S\u0026gt; void ForEachTupleInternal(T\u0026amp;\u0026amp; tuple, F\u0026amp;\u0026amp; consumer, IndexSequence\u0026lt;S...\u0026gt;) { std::initializer_list\u0026lt;int\u0026gt; { (consumer(std::get\u0026lt;S\u0026gt;(tuple)), 0)... }; } struct Consumer { template \u0026lt;typename T\u0026gt; void operator()(T\u0026amp;\u0026amp; value) { std::cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; } }; int main(int argc, char* argv[]) { ForEachTuple(std::make_tuple(1, 2.1, \u0026#34;Hello\u0026#34;), Consumer {}); return 0; } 代码很简单，这里要注意的就是 std::get\u0026lt;\u0026gt;() 和 ... 的配合来不断消费 std::tuple 的元素，最后用 std::initializer_list\u0026lt;int\u0026gt; 来接收可变参防止编译错误。\n值得一提的是，c++ 14 已经内置了编译期序列，如果项目能支持到 c++ 14，则可以直接这么写：\ntemplate \u0026lt;typename T, typename F\u0026gt; void ForEachTuple(T\u0026amp;\u0026amp; tuple, F\u0026amp;\u0026amp; consumer) { // c++ 14 的 make_index_sequence ForEachTupleInternal(std::forward\u0026lt;T\u0026gt;(tuple), std::forward\u0026lt;F\u0026gt;(consumer), std::make_index_sequence\u0026lt;std::tuple_size\u0026lt;T\u0026gt;::value\u0026gt; {}); } template \u0026lt;typename T, typename F, size_t... S\u0026gt; void ForEachTupleInternal(T\u0026amp;\u0026amp; tuple, F\u0026amp;\u0026amp; consumer, std::index_sequence\u0026lt;S...\u0026gt;) { std::initializer_list\u0026lt;int\u0026gt; { (consumer(std::get\u0026lt;S\u0026gt;(tuple)), 0)... }; } int main(int argc, char* argv[]) { // c++ 14 的 lambda 中 auto 作为参数 ForEachTuple(std::make_tuple(1, 2.1, \u0026#34;Hello\u0026#34;), [](const auto\u0026amp; value) -\u0026gt; void { std::cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; }); return 0; } ","date":"2021-08-06T00:00:00Z","permalink":"https://www.kindem.xyz/post/45/","title":"C++ 模板黑魔法 —— 编译期序列与 std::tuple 遍历"},{"content":"前两个月在 Explosion 上下了不少功夫，好几周双休都抽出了一整天来开发引擎、做之后的设计，平日里下班了也是第一时间埋着头就开始写。直到这两周，Explosion 又暂停了下来，主要因为去杭州出差了，项目比较忙，没什么时间写。\n今天下班比较早，想起来了该要写笔记了，就提笔记录记录。\n近期进展 System / SystemGroup / SystemGraph ECS 框架我们是直接引用的 EnTT，但 EnTT 只提供了 Entity、Component 的概念，没有直接提供 System，它的本意是只负责 ECS 框架中最困难的内存管理部分，所以 System 的概念需要自己封装。\n在基础的 System 定义上，我们稍作了简化，并添加了 SystemGroup 和 SystemGraph 的概念，他们的定义如下：\nSystem：一个 Lambda 表达式，即代表一段可执行的逻辑。 SystemGroup：保存了一组 System 和一个 SystemGraph。 SystemGraph：描述了 SystemGroup 内部 System 之间的依赖关系。 另外，他们遵循如下规则：\nWorld#Tick() 会更新所有 SystemGroup，SystemGroup 具有优先级，SystemGroup 之间会按照优先级串行更新。 SystemGroup 内部的所有 System 会按照 SystemGraph 编译成一个 TaskFlow，用于描述一个更新任务。 TaskFlow Execute 的时候有依赖关系的 System 会进行软同步，按照先后顺序执行，没有依赖关系的 System 会并行执行。 System 之间可以拥有共享内存，也使用 Component 实现，我们称之为 SharedComponent，SystemGraph 产生的依赖关系可以保证这块内存的同步访问。 下面是部分定义以及 World#Tick() 的部分代码：\nusing System = std::function\u0026lt;void(Registry\u0026amp; registry, float time)\u0026gt;; struct SystemGroup { std::string name; uint32_t priority; std::unordered_map\u0026lt;std::string, System\u0026gt; systems; // SystemGraph 的简易实现，等完善的图模板库写出来之后替换掉 std::unordered_map\u0026lt;std::string, std::string\u0026gt; dependencies; }; void World::TickSystem(float time) { // update system group on by one for (const auto\u0026amp; systemGroup : systemGroups) { JobSystem::TaskFlow taskFlow; std::unordered_map\u0026lt;std::string, JobSystem::Task\u0026gt; tasks; for (const auto\u0026amp; sysIter : systemGroup.systems) { tasks[sysIter.first] = taskFlow.emplace([\u0026amp;sysIter, time, this]() -\u0026gt; void { sysIter.second(registry, time); }); } for (const auto\u0026amp; depIter : systemGroup.dependencies) { tasks[depIter.first].succeed(tasks[depIter.second]); } JobSystem::Executor executor; executor.run(taskFlow).wait(); } } 下面是一小段 ECS 的 UT：\nTEST(WorldTest, SystemDependenciesTest) { struct SharedComponent { uint32_t input; uint32_t transfer; }; struct OutputComponent { uint32_t value; }; World world; auto\u0026amp; registry = world.GetRegistry(); Entity entity1 = registry.CreateEntity(); registry.AddComponent\u0026lt;SharedComponent\u0026gt;(entity1, 1u, 0u); registry.AddComponent\u0026lt;OutputComponent\u0026gt;(entity1, 0u); Entity entity2 = registry.CreateEntity(); registry.AddComponent\u0026lt;SharedComponent\u0026gt;(entity2, 3u, 0u); registry.AddComponent\u0026lt;OutputComponent\u0026gt;(entity2, 0u); SystemGroup systemGroup {}; systemGroup.name = \u0026#34;group1\u0026#34;; systemGroup.priority = 1; systemGroup.systems[\u0026#34;middleSystem\u0026#34;] = [](Registry\u0026amp; registry, float time) -\u0026gt; void { auto view = registry.CreateView\u0026lt;SharedComponent\u0026gt;(); view.Each([](SharedComponent\u0026amp; sharedComp) -\u0026gt; void { sharedComp.transfer = sharedComp.input * 4; }); }; systemGroup.systems[\u0026#34;outputSystem\u0026#34;] = [](Registry\u0026amp; registry, float time) -\u0026gt; void { auto view = registry.CreateView\u0026lt;SharedComponent, OutputComponent\u0026gt;(); view.Each([](SharedComponent\u0026amp; sharedComp, OutputComponent\u0026amp; outputComp) -\u0026gt; void { outputComp.value = sharedComp.transfer + 3; }); }; systemGroup.dependencies[\u0026#34;outputSystem\u0026#34;] = \u0026#34;middleSystem\u0026#34;; world.AddSystemGroups(systemGroup); world.Tick(.16f); ASSERT_EQ(registry.GetComponent\u0026lt;SharedComponent\u0026gt;(entity1)-\u0026gt;input, 1); ASSERT_EQ(registry.GetComponent\u0026lt;SharedComponent\u0026gt;(entity1)-\u0026gt;transfer, 4); ASSERT_EQ(registry.GetComponent\u0026lt;OutputComponent\u0026gt;(entity1)-\u0026gt;value, 7); ASSERT_EQ(registry.GetComponent\u0026lt;SharedComponent\u0026gt;(entity2)-\u0026gt;input, 3); ASSERT_EQ(registry.GetComponent\u0026lt;SharedComponent\u0026gt;(entity2)-\u0026gt;transfer, 12); ASSERT_EQ(registry.GetComponent\u0026lt;OutputComponent\u0026gt;(entity2)-\u0026gt;value, 15); } 总体来说写起来还算可以，这么设计的初衷主要有两个：\n处理 System 依赖问题 处理 System 间传递数据问题 大道至简，我不想把一套本来很简单的机制设计的过于复杂，从而增加维护的难度，之后等渲染管线搭起来之后再测一测性能，天然的多线程支持应该不会慢到哪里去。另外就是这样的写法会非常自由，对之后写引擎核心的 CPU 端逻辑会产生更高的要求，后面实际写起来的时候再看看效果吧。\nExplosion 3rd Party Package 我本人其实是非常不想在 CI 上花太多时间的，但是 3rd Party Package 这个事情不搞又完全不行，因为越来越多的三方库直接源码引入，一是主仓体积逐渐增大，二是遇到一些巨大的库 （例如 V8），光是构建就需要两小时，不可能本地编译的，这个事情会很大程度上影响大家的工作效率。\n我们的解决方案是创建一个单独的仓库，即 Explosion3rd，它的任务如下：\n以 Git Sub-Module 的形式管理所有三方库源码，支持我们自己的侵入式修改。 支持一键构建所有三方库在各平台上（目前支持 MacOS、Visual Stdio 2019）的二进制包，并全自动打包成 Zip 发布到 Release 页面，用户在编译 Explosion 本体前需要自行下载、解压这个包。 管理三方库的版本与依赖关系，将其归档到 Release 包的 CMakeLists.txt 中。 这样一来，主仓就可以只管理 Explosion 的代码本身了。\nExplosion3rd 的打包流程完全基于 GitHub Actions 实现：\nActions 每次更新之后，只需要手动输入版本号并 Dispatch 一下，Actions 就会全自动地构建二进制包，并发布到 Release 页面，下面是其中一个平台自动构建、打包的 CI 代码：\njobs: release-windows: runs-on: windows-latest steps: - uses: actions/checkout@v2 - name: Update SubModules run: | git submodule init git submodule update - name: Install 7-zip run: | Invoke-WebRequest -Uri https://7-zip.org/a/7z1900-x64.msi -OutFile 7z.msi msiexec.exe /package 7z.msi /qn echo \u0026#34;C:\\Program Files\\7-Zip\u0026#34; | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append - name: Create Archive Directories run: | mkdir Win mkdir Win/entt mkdir Win/entt/Include mkdir Win/glm mkdir Win/glm/Include mkdir Win/rapidjson mkdir Win/rapidjson/Include mkdir Win/taskflow mkdir Win/taskflow/Include mkdir Win/glfw mkdir Win/glfw/Include mkdir Win/glfw/Lib mkdir Win/glfw/Lib/Debug mkdir Win/glfw/Lib/Release mkdir Win/gflags mkdir Win/gflags/Include mkdir Win/gflags/Lib mkdir Win/gflags/Lib/Debug mkdir Win/gflags/Lib/Release mkdir Win/assimp mkdir Win/assimp/Include mkdir Win/assimp/Lib mkdir Win/assimp/Lib/Debug mkdir Win/assimp/Lib/Release mkdir Win/googletest mkdir Win/googletest/Include mkdir Win/googletest/Lib mkdir Win/googletest/Lib/Debug mkdir Win/googletest/Lib/Release mkdir Win/glslang mkdir Win/glslang/Lib mkdir Win/glslang/Lib/Debug mkdir Win/glslang/Lib/Release - name: Archiving CMakeLists run: | cp CMakeLists.txt Win - name: Archiving EnTT run: | cp -r entt/single_include/entt Win/entt/Include - name: Archiving GLM run: | cp -r glm/glm Win/glm/Include/glm rm Win/glm/Include/glm/CMakeLists.txt - name: Archiving rapidjson run: | cp -r rapidjson/include/rapidjson Win/rapidjson/Include/rapidjson - name: Archiving TaskFlow run: | cp -r taskflow/taskflow Win/taskflow/Include/taskflow - name: Building GFlags run: | cmake -S gflags -B gflags/build-debug -DBUILD_SHARED_LIBS=OFF -DBUILD_STATIC_LIBS=ON -DBUILD_gflags_LIB=OFF -DBUILD_gflags_nothreads_LIB=ON -DBUILD_PACKAGING=OFF -DBUILD_TESTING=OFF -DINSTALL_HEADERS=ON -DINSTALL_SHARED_LIBS=OFF -DINSTALL_STATIC_LIBS=ON -DREGISTER_BUILD_DIR=OFF -DREGISTER_INSTALL_PREFIX=OFF -DCMAKE_INSTALL_PREFIX=gflags/build-debug/install cmake --build gflags/build-debug --config Debug -j 8 cmake --install gflags/build-debug --config Debug cmake -S gflags -B gflags/build-release -DBUILD_SHARED_LIBS=OFF -DBUILD_STATIC_LIBS=ON -DBUILD_gflags_LIB=OFF -DBUILD_gflags_nothreads_LIB=ON -DBUILD_PACKAGING=OFF -DBUILD_TESTING=OFF -DINSTALL_HEADERS=ON -DINSTALL_SHARED_LIBS=OFF -DINSTALL_STATIC_LIBS=ON -DREGISTER_BUILD_DIR=OFF -DREGISTER_INSTALL_PREFIX=OFF -DCMAKE_INSTALL_PREFIX=gflags/build-release/install cmake --build gflags/build-release --config release -j 8 cmake --install gflags/build-release --config release - name: Archiving GFlags run: | cp -r gflags/build-debug/install/include/* Win/gflags/Include cp -r gflags/build-debug/install/lib/* Win/gflags/Lib/Debug cp -r gflags/build-release/install/lib/* Win/gflags/Lib/Release - name: Building Assimp run: | cmake -S assimp -B assimp/build-debug -DBUILD_SHARED_LIBS=OFF -DASSIMP_BUILD_TESTS=OFF cmake --build assimp/build-debug --config Debug -j 8 cmake -S assimp -B assimp/build-release -DBUILD_SHARED_LIBS=OFF -DASSIMP_BUILD_TESTS=OFF cmake --build assimp/build-release --config Release -j 8 - name: Archiving Assimp run: | cp -r assimp/include/* Win/assimp/Include cp assimp/build-debug/include/assimp/config.h Win/assimp/Include/assimp cp assimp/build-debug/lib/Debug/assimp-vc142-mtd.lib Win/assimp/Lib/Debug cp assimp/build-debug/lib/Debug/assimp-vc142-mtd.pdb Win/assimp/Lib/Debug cp assimp/build-release/lib/Release/assimp-vc142-mt.lib Win/assimp/Lib/Release - name: Building GLFW run: | mkdir glfw/build-debug cmake -S glfw -B glfw/build -DGLFW_BUILD_EXAMPLES=false -DGLFW_BUILD_TESTS=false -DGLFW_BUILD_DOCS=false -DUSE_MSVC_RUNTIME_LIBRARY_DLL=OFF cmake --build glfw/build --config Debug -j 8 cmake --build glfw/build --config Release -j 8 - name: Archiving GLFW run: | cp glfw/build/src/Debug/glfw3.lib Win/glfw/Lib/Debug cp glfw/build/src/Debug/glfw3.pdb Win/glfw/Lib/Debug cp glfw/build/src/Release/glfw3.lib Win/glfw/Lib/Release cp -r glfw/include/GLFW Win/glfw/Include/GLFW - name: Building GoogleTest run: | mkdir googletest/build-debug cmake -S googletest -B googletest/build cmake --build googletest/build --config Debug -j 8 cmake --build googletest/build --config Release -j 8 - name: Archiving Google Test run: | cp googletest/build/lib/Debug/gtestd.lib Win/googletest/Lib/Debug cp googletest/build/lib/Debug/gmockd.lib Win/googletest/Lib/Debug cp googletest/build/lib/Debug/gtest_maind.lib Win/googletest/Lib/Debug cp googletest/build/lib/Debug/gmock_maind.lib Win/googletest/Lib/Debug cp googletest/build/lib/Debug/gtestd.pdb Win/googletest/Lib/Debug cp googletest/build/lib/Debug/gmockd.pdb Win/googletest/Lib/Debug cp googletest/build/lib/Debug/gtest_maind.pdb Win/googletest/Lib/Debug cp googletest/build/lib/Debug/gmock_maind.pdb Win/googletest/Lib/Debug cp googletest/build/lib/Release/gtest.lib Win/googletest/Lib/Release cp googletest/build/lib/Release/gmock.lib Win/googletest/Lib/Release cp googletest/build/lib/Release/gtest_main.lib Win/googletest/Lib/Release cp googletest/build/lib/Release/gmock_main.lib Win/googletest/Lib/Release cp -r googletest/googletest/include/gtest Win/googletest/Include/gtest cp -r googletest/googlemock/include/gmock Win/googletest/Include/gmock - name: Building Glslang run: | cmake -S glslang -B glslang/build-debug -DBUILD_TESTING=false -DENABLE_CTEST=false -DCMAKE_INSTALL_PREFIX=glslang/build-debug cmake --build glslang/build-debug --config Debug -j 8 cmake --install glslang/build-debug --config Debug cmake -S glslang -B glslang/build-release -DBUILD_TESTING=false -DENABLE_CTEST=false -DCMAKE_INSTALL_PREFIX=glslang/build-release cmake --build glslang/build-release --config Release -j 8 cmake --install glslang/build-release --config Release - name: Archiving Glslang run: | cp -r glslang/build-debug/lib Win/glslang/Lib/Debug cp -r glslang/build-release/lib Win/glslang/Lib/Release cp -r glslang/build-debug/include Win/glslang/Include - name: Zip Release Package run: 7z a Win.zip Win - name: Create Release id: create_release uses: actions/create-release@v1 if: ${{ github.event.inputs.version }} env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: tag_name: \u0026#34;Win-${{ github.event.inputs.version }}\u0026#34; release_name: \u0026#34;Win-${{ github.event.inputs.version }}\u0026#34; draft: false prerelease: false - name: Upload Release Assets uses: actions/upload-release-asset@v1 if: ${{ github.event.inputs.version }} env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: upload_url: ${{ steps.create_release.outputs.upload_url }} asset_path: Win.zip asset_name: Win.zip asset_content_type: application/zip 其实就是一堆 CMake 和 Make 指令，最后将所有需要的 Includes 和 Libs 归档到一个 Zip 中，然后调用 actions/upload-release-asset@v1 插件自动发布 Release。\n可以看看打包的 Zip 的内容：\nContents 主仓库那边的代码在 CMake 时需要添加一个 CMake 变量来指定这个包的路径，可以在命令行使用 -DEXP_3RD_ROOT=xxx 来传入，这样主库就会直接引入这边的三方库。\n下面是 Explosion3rd/CMakeLists.txt 的内容以及相关定义：\n// Explosion/cmake/Explosion.cmake function(exp_external_library) cmake_parse_arguments( PARAMS \u0026#34;\u0026#34; \u0026#34;NAME\u0026#34; \u0026#34;\u0026#34; ${ARGN} ) if (EXISTS \u0026#34;${EXP_3RD_ROOT}/${PARAMS_NAME}/Include\u0026#34;) set(\u0026#34;${PARAMS_NAME}_INCS\u0026#34; \u0026#34;${EXP_3RD_ROOT}/${PARAMS_NAME}/Include\u0026#34; CACHE STRING \u0026#34;include dirs of ${PARAMS_NAME} library\u0026#34;) endif() if (EXISTS \u0026#34;${EXP_3RD_ROOT}/${PARAMS_NAME}/Lib\u0026#34;) if (${WIN32}) set(LIBS \u0026#34;${EXP_3RD_ROOT}/${PARAMS_NAME}/Lib/${CMAKE_BUILD_TYPE}/*.lib\u0026#34;) else(${APPLE}) file(GLOB LIBS \u0026#34;${EXP_3RD_ROOT}/${PARAMS_NAME}/Lib/${CMAKE_BUILD_TYPE}/*.a\u0026#34;) endif () set(\u0026#34;${PARAMS_NAME}_LIBS\u0026#34; ${LIBS} CACHE STRING \u0026#34;include dirs of ${PARAMS_NAME} library\u0026#34;) endif() endfunction() // Explosion3rd/CMakeLists.txt exp_external_library(NAME entt) exp_external_library(NAME glfw) exp_external_library(NAME glm) exp_external_library(NAME glslang) exp_external_library(NAME googletest) exp_external_library(NAME rapidjson) exp_external_library(NAME taskflow) exp_external_library(NAME assimp) exp_external_library(NAME gflags) exp_external_library 会为每个库自动扫描 Includes 和 Libs 并将其路径填入对应的变量，主仓项目里直接使用这些变量去设置头文件目录和库路径即可，原理和 find_library 类似。\n至此，Explosion 的编译速度得到了巨大提升，然而，因为库太多，调试 Explosion3rd 的 CI 却变成了噩梦，一想到后面还要调编一次两小时的 V8 就头疼 \u0026hellip;\u0026hellip;\n留坑 手头还有一点新的思考，太晚了，先睡了，有空把念头落实了再记录下来，加油！\n","date":"2021-07-20T00:00:00Z","permalink":"https://www.kindem.xyz/post/44/","title":"Explosion 开发笔记 (四)"},{"content":" 每一个程序员都应该有机会重写三年前写下的代码 —— 鲁迅\n起因 GitHub 风格头像生成器 是我三年前写下的一个 Java 小程序，它的功能很简单，就是生成 GitHub 风格的头像。下午逛 GitHub 的时候突然看到之前写的辣鸡代码，工程管理和使用的库也相当混乱。\n离谱的事情是居然还有 30 来个小星星，一时间感觉受之有愧，决定花一个下午推倒重写 \u0026hellip;\u0026hellip;\n分析 首先是工程管理上的，老的工程是直接基于 IDEA 的默认 Java 工程搭建的，构建运行都相当依赖 IDEA，如果要命令行编译运行对不了解这块的网友来说还有有点麻烦的。我的想法是使用 Gradle 来进行工程管理，这样无论是命令行还是 IDE，构建和运行都相当方便。\n其次，使用的库非常离谱，三年前的我引入了 OpenCV 做图片读写，我现在也没法揣摩三年前的我出于何考虑，果断放弃，直接使用 Java 自带的 ImageIO 和 BufferedImage 替代。\n另外，原来的代码是写死输出文件的，也不支持自定义随机种子的配置。我决定在这次重构中添加这些功能。\n细节 命令行参数解析 命令行参数解析我直接使用的 Apache 的轮子 commons-cli，主程序就稍微写一丢丢代码就能完成解析：\npublic class Main { public static void main(String[] args) { Options options = new Options(); options.addOption(Option.builder(\u0026#34;o\u0026#34;).longOpt(\u0026#34;output\u0026#34;).hasArg().required().type(String.class).desc(\u0026#34;output file\u0026#34;).build()); options.addOption(Option.builder(\u0026#34;s\u0026#34;).longOpt(\u0026#34;seed\u0026#34;).hasArg().required().type(String.class).desc(\u0026#34;seed string\u0026#34;).build()); CommandLineParser commandLineParser = new DefaultParser(); CommandLine commandLine = null; try { commandLine = commandLineParser.parse(options, args); } catch (ParseException e) { System.out.println(\u0026#34;bad command line arguments\u0026#34;); } if (commandLine == null) { return; } Generator generator = new Generator(commandLine.getOptionValue(\u0026#34;s\u0026#34;)); Saver.saveImage(generator.nextAvatar(), commandLine.getOptionValue(\u0026#34;o\u0026#34;)); } } 没啥好说的，各种命令行参数解析工具的一贯用法，定义 Options，用 Parser 开始解析即可。\n种子与随机算法 这一次重构添加了自定义种子的功能，可以支持从命令行输入一个种子字符串，程序会把种子加上当前计数一起做 Hash，Hash 完了拿到 Bytes 生成一个 AvatarInfo，它的作用是记录本次生成过程中，需要采用的颜色和 5x5 方块矩阵中每一个矩阵是否要填充颜色，原理也不复杂，直接贴代码：\nprivate AvatarInfo nextAvatarInfo() { byte[] hash = nextHash(); // 3 byte for color, 15 byte for block int[] info = new int[18]; for (int i = 0; i \u0026lt; hash.length; i++) { int index = i % 18; info[index] = (info[index] + (hash[i] + 128)) % 256; } AvatarInfo avatarInfo = new AvatarInfo(new Color(info[0], info[1], info[2])); for (int i = 3; i \u0026lt; 18; i++) { avatarInfo.setBlockValue(i, info[i] \u0026gt; 127); } return avatarInfo; } private byte[] nextHash() { MessageDigest messageDigest = null; try { messageDigest = MessageDigest.getInstance(\u0026#34;SHA-256\u0026#34;); } catch (NoSuchAlgorithmException ignored) {} if (messageDigest == null) { return new byte[0]; } messageDigest.update((seed + count++).getBytes(StandardCharsets.UTF_8)); return messageDigest.digest(); } Gradle 采用 Gradle 进行工程管理后，既可以兼容 IDEA，又可以在命令行进行构建和运行，非常方便，如果你是 IDEA 用户，只要打开工程，点击右上角 Add Configuration 按钮，添加一个运行配置即可：\nConfigurations 把红框里的填一填就 OK 啦，尤其注意参数一栏要记得填东西，之后直接点击绿色小三角运行即可。\n如果是命令行用户，则直接使用 gradlew 指令构建运行即可：\n# build and install ./gradlew build ./gradlew install # run ./build/install/gh-avatar-generator/bin/gh-avatar-generator -s amazing_seed -o sample.png 展示 下面是重构之后用应用生成的一些 GitHub 风格头像：\nSample1 Sample2 Sample3 Sample4 Sample5 Sample6 喜欢的话可以 Clone 我的仓库体验一下，顺便给我个小星星~ 🤣\n","date":"2021-07-04T00:00:00Z","permalink":"https://www.kindem.xyz/post/43/","title":"GitHub Avatar Generator 重构计划"},{"content":"std::tuple 是泛化的 std::pair，用于存储一组任意类型的数据，可以通过 std::get 来访问其元素：\nint main(int argc, char* argv[]) { std::tuple\u0026lt;int, double, std::string\u0026gt; tuple = std::make_tuple(1, 2.0, \u0026#34;hello\u0026#34;); std::cout \u0026lt;\u0026lt; std::get\u0026lt;0\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::get\u0026lt;1\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::get\u0026lt;2\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; } 也可以使用类型来查找元素：\nint main(int argc, char* argv[]) { std::tuple\u0026lt;int, double, std::string\u0026gt; tuple = std::make_tuple(1, 2.0, \u0026#34;hello\u0026#34;); std::cout \u0026lt;\u0026lt; std::get\u0026lt;int\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::get\u0026lt;double\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::get\u0026lt;std::string\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; } 如果 std::tuple 中具有两个以上的相同类型的元素，则不能使用该类型进行查找：\nint main(int argc, char* argv[]) { std::tuple\u0026lt;int, int, std::string\u0026gt; tuple = std::make_tuple(1, 2, \u0026#34;hello\u0026#34;); // 编译期错误 std::cout \u0026lt;\u0026lt; std::get\u0026lt;int\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::get\u0026lt;int\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::get\u0026lt;std::string\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; } 可以使用 std::tie 来对 std::tuple 进行解包：\nint main(int argc, char* argv[]) { std::tuple\u0026lt;int, double, std::string\u0026gt; tuple = std::make_tuple(1, 2.0, \u0026#34;hello\u0026#34;); int a; double b; std::string c; std::tie(a, b, c) = tuple; std::cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; b \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; c \u0026lt;\u0026lt; std::endl; } 可以使用 std::tuple_cat 来合并多个 std::tuple：\nint main(int argc, char* argv[]) { auto tuple1 = std::make_tuple(1, 2.0); auto tuple2 = std::make_tuple(\u0026#34;hello\u0026#34;); auto tuple = std::tuple_cat(tuple1, tuple2); int a; double b; std::string c; std::tie(a, b, c) = tuple; std::cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; b \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; c \u0026lt;\u0026lt; std::endl; } 可以使用 std::tuple_size 来获取某个类型的 std::tuple 的长度：\nint main(int argc, char* argv[]) { std::cout \u0026lt;\u0026lt; std::tuple_size\u0026lt;std::tuple\u0026lt;int, double\u0026gt;\u0026gt;::value \u0026lt;\u0026lt; std::endl; } 也可以直接使用 std::tuple_size_v 替代：\nint main(int argc, char* argv[]) { std::cout \u0026lt;\u0026lt; std::tuple_size_v\u0026lt;std::tuple\u0026lt;int, double\u0026gt;\u0026gt; \u0026lt;\u0026lt; std::endl; } 通常用于元编程中获取模板参数中 std::tuple 的长度：\ntemplate \u0026lt;typename... Args\u0026gt; size_t GetTupleSize(const std::tuple\u0026lt;Args...\u0026gt;\u0026amp; tuple) { return std::tuple_size_v\u0026lt;std::tuple\u0026lt;Args...\u0026gt;\u0026gt;; } int main(int argc, char* argv[]) { auto tuple = std::make_tuple(1, 2.0); std::cout \u0026lt;\u0026lt; GetTupleSize(tuple) \u0026lt;\u0026lt; std::endl; } 可以在元编程中使用 std::tuple_element_t 提取 std::tuple 中元素的类型，下面是一个完整的例子：\ntemplate \u0026lt;uint32_t I, typename... Args\u0026gt; std::tuple_element_t\u0026lt;I, std::tuple\u0026lt;Args...\u0026gt;\u0026gt; GetTupleValue(const std::tuple\u0026lt;Args...\u0026gt;\u0026amp; tuple) { return std::get\u0026lt;I\u0026gt;(tuple); } int main(int argc, char* argv[]) { auto tuple = std::make_tuple(1, 2, \u0026#34;hello\u0026#34;); std::cout \u0026lt;\u0026lt; GetTupleValue\u0026lt;0\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; GetTupleValue\u0026lt;1\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; } 可以使用 std::forword_tuple 来将模板可变参转换成一个 std::tuple：\ntemplate \u0026lt;typename... Args\u0026gt; auto MakeTuple(const Args\u0026amp;... args) { return std::forward_as_tuple(args...); } int main(int argc, char* argv[]) { auto tuple = MakeTuple(1, 2.0, \u0026#34;hello\u0026#34;); std::cout \u0026lt;\u0026lt; std::get\u0026lt;0\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::get\u0026lt;1\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::get\u0026lt;2\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; } ","date":"2021-06-28T00:00:00Z","permalink":"https://www.kindem.xyz/post/42/","title":"std::tuple 学习笔记"},{"content":"介绍 Conventional Commits Conventional Commits (下称 CC) 是一套 git commit message 的规范，旨在让 commit message 能同时被人类和机器所接纳，也就是说满足可读性的同时增强规范性，它的官网在这里: Conventional Commits。\n目前来看 CC 标准已经被越来越多的人所接受，很多开源项目也积极采纳并推广这套标准（比如 Ant-Design、NaiveUI）。\n实话说我之前经常看到过这种 commit message 的写法，但是我还真不知道这种写法有一套专门的标准，偶然间逛 GitHub 发现了这个，决定好好学习一下，这样能帮助自己更好地融入开源社区。\n规范详解 CC 规范最重要的莫过于 git commit message 的格式：\n\u0026lt;type\u0026gt;[optional scope]: \u0026lt;description\u0026gt; [optional body] [optional footer(s)] 按照这种写法的优点在于 git 历史记录会相当规范，这很适合一些自动化工具去解析、生成这些提交信息，同时又不失可读性。\n其中 type 字段用于传达本笔提交大致的内容：\nfix 表示提交用于修复 bug feat 表示提交用于添加新功能 build 表示提交修改了构建系统或者外部依赖 ci 表示提交修改了持续构建、持续部署配置或脚本 docs 表示提交修改了文档 perf 表示提交进行了性能优化 refactor 表示提交进行了重构 style 表示提交修改了代码格式问题 test 表示提交添加或修改了测试用例 BREAKING CHANGE 表示提交进行了不兼容修改，需要在脚注中使用 type 字段后面还可以跟上 scope 以表示更精确的行为，如 feat(parser): add ability to parse arrays。\ndescription 字段是本次提交的概述，optional body 和 optional footer(s) 字段是可选的具体描述和脚注。\n另外，还可以使用 ! 来取代 BREAKING CHANGE 来表示不兼容修改。\n示例 最简单的例子：\ndocs: correct spelling of CHANGELOG 带 scope 的例子：\nfeat(lang): add polish language ! 表示不兼容修改：\nrefactor!: drop support for Node 6 BREAKING CHANGE 表示不兼容修改：\nfeat: allow provided config object to extend other configs BREAKING CHANGE: `extends` key in config file is now used for extending other config files ! 和 BREAKING CHANGE 同时使用：\nrefactor!: drop support for Node 6 BREAKING CHANGE: refactor to use JavaScript features not available in Node 6. 一个完整的例子：\nfix: correct minor typos in code see the issue for details on typos fixed. Reviewed-by: Z Refs #133 更多规范 CC 规范还有一些明文条例，具体参考 Specification\n","date":"2021-06-27T00:00:00Z","permalink":"https://www.kindem.xyz/post/41/","title":"Conventional Commits 介绍"},{"content":"进展概览 Repo 建设 先说说最近的进展吧，首先是 Repo 方面的建设，README 先写起来占坑了，顺便随手自己画了张 logo 图上丢上去占坑，可以简单看看现在的 README：\nREADME 回头还需要把中文版的 README 和其他的细节慢慢补起来，不过我们现在真没太多人力投入这块，要做的东西太多了，之后把引擎本身完善的差不多了之后再慢慢弄吧。\n工程管理 我们在团队内推崇大家使用 Issues 来交流、跟踪进展，使用 Project 来管理整个项目，大概效果是这样：\nIssues Project 提交 Issues 会自动关联到 Project，MR 中需要关联对应的 Issues，在 MR 关闭时，Issues 会自动跟随 MR 关闭，并移动到 Project 的 Done 一栏，这样我们就能方便地跟踪需求和进展。\nCI CI 方面我们目前使用的是 GitHub Actions，不得不说这玩意可塑性要比其他的 CI/CD 工具强很多，写起来也是比较方便的，目前 CI 就配置了一个 cmake 构建，覆盖平台有：\nUbuntu Windows 具体的代码在这：Actions Code，提交 MR 后自动触发，构建结果可以在 Actions 查询：\nAction Result 构建通过是合入的硬性指标。其实我在纠结 MacOS 要不要加，因为实际上从构建来说，MacOS 的编译器和 GCC 还是比较一致的，一般不会出什么大岔子，后面再说吧。\n构建系统优化 我抽空对所有的 CMake 进行了一次重构，主要做的事情是把常用的一些基本 CMake 指令做了一次封装，主要涉及：\nadd_executable add_library add_test 我把他们封装成了：\nexp_add_executable exp_add_library exp_add_test 其实做的事情很简单，就是在原有指令的基础上，把头文件目录、链接库这类必备的操作与其合并了，用起来会更方便些，下面是一段示例：\nexp_add_executable( NAME ${TARGET_NAME} SRCS ${TARGET_SOURCES} INC_DIRS ${TARGET_INCLUDE_DIRS} LIBS ${TARGET_LIBS} ) exp_add_library( NAME ${TARGET_NAME} TYPE ${TARGET_TYPE} SRCS ${TARGET_SOURCES} PRIVATE_INC_DIRS ${TARGET_PRIVATE_INCLUDE_DIRS} PUBLIC_INC_DIRS ${TARGET_PUBLIC_INCLUDE_DIRS} LIB ${TARGET_LIBS} ) exp_add_test( NAME ${TARGET_NAME} WORKING_DIR ${TARGET_WORKING_DIR} SRCS ${TARGET_SOURCES} INC_DIRS ${TARGET_INCLUDE_DIRS} LIB ${TARGET_LIBS} ) 目的就是统一大家写 CMake 的风格。\n代码质量控制 经过一番考量，我暂时选用了 Codacy 作为我们的静态检查工具，因为是纯在线的工具，完全不需要集成，只需要按步骤启用 GitHub App 即可启用扫描，可以在 Codacy Dashboard - Explosion 找到静态扫描结果：\nCodacy Dashboard 主干的代码提交以及 MR 会自动触发静态扫描，之后评级会自动刷新，然后同步到 README 的 Badge 中：\nCodacy Badge 至于代码风格、安全问题、圈复杂度、重复率的扫描要不要整合到 CI 中，之后再考虑吧，现在来说已经够用了~\nRHI 重构 最近投入 Explosion 的时间并不是很多，RHI 重构算是最近的主要进展了，我之前写过一篇文章叫做 《醒醒吧，静态多态根本没有这么香》，其实主要纠结的地方在于要不要追求极限性能，把 RHI 的主要架子完全用模板实现，但我最后还是放弃了。\n模板在大型的架构设计与代码量级下会带来很多负面影响，主要会直接影响到接口的设计，虽然性能高，但我最后还是决定使用传统的 OOP 来完成 RHI 的编写。\n抛开这些，我总算是决定先把 VulkanDriver 拆分出来了，抽象了一套公共的 Driver 接口，用于以后实现 DX12 和 Metal 后端，我很庆幸先做了这件事，不然后面改起来估计更蛋疼。\n目前封装的类有：\nDriver Device CommandBuffer Buffer Sampler Image ImageView FrameBuffer SwapChain RenderPass GraphicsPipeline ComputePipeline DescriptorPool DescriptorSet Signal 封装粒度还是相对比较细的，之后准备通过脚本 / 插件的形式将 RHI 和 RPI 一起提供出去，为用户自己造 Renderer 提供可能性（咱们之后的 DefaultRenderer 本身就会作为一个插件提供）。\nRHI 要走的路还很长，不过我打算小步快跑，先用 VulkanDriver 顶着，慢慢把上面的代码也写起来，让其他团队成员也能快速地参与进来。\nRPI / FrameGraph RPI / FrameGraph 主要由 bluesky013 操刀，思路主要参考 GDC 2017 寒霜引擎的一次 Talk，可以在 GDC Vault - FrameGraph 找到这次 Talk 的 PPT。\n我们设计的蓝本就是这个 Talk，目前逻辑差不多写完了，不过 AsyncComputePass 和 TransitionResources 处理上还有点小问题。\n下面简单讲讲 FrameGraph：\nFrameGraph Goals FrameGraph 的目标很简单，就是用一种合理、可预测的方式去维护 Renderer 中繁重不堪的资源与 RenderPass 的依赖关系。从另外一种角度讲，FrameGraph 的作用是让渲染流程更清晰、可维护。下面是一个简单的例子：\nFramGraph Example 黄色的节点是 RenderPass，蓝色的节点是资源，红色节点是送显，它很好地描述了一帧中资源和渲染流程的关系（但是要注意的是它并不维护具体的渲染任务，也就是它不管 Pipeline）。下面是几张资源和 RenderPass 的图：\nFrameGraph Resources FrameGraph Examples FrameGraph SetUp FrameGraph RenderPass 资源这里就不多说了，可以自己看看原 Talk，主要是 RenderPass，FrameGraph 用一个结构体来描述 RenderPass 节点的输入输出资源，用两个 Lambda 表达式来描述 RenderPass 节点的 SetUp 和 Execute 流程，这里的 Execute 实际上就是真正的绘制过程了，FrameGraph 和 RHI 就是在这里结合的。\nFrameGraph 是 RPI 的重要组成部分，可以说它是 Renderer 的骨架，而 RHI 则是 Renderer 的血肉，它俩配合可以为可编程渲染管线提供强大的支持。\n思考 反射系统搭建 我很喜欢拿反射系统说事，之前也写过 一篇对反射系统的剖析，不过那是针对 UnrealEngine 的。反射系统在游戏引擎中最大的作用，无非就两个：\n自动序列化 脚本符号注册 我们目前准备使用 rttr 或者 meta，rttr 应该不说我多说了，老牌反射框架了，meta 是 entt 内置的反射框架，作者 skypjack 觉得市面上没什么好的反射框架然后自己写的。其实从工程建设角度看我更认可 meta 一些，但是 meta 提供的接口实在是不好用：\nstd::hash\u0026lt;std::string_view\u0026gt; hash{}; meta::reflect\u0026lt;my_type\u0026gt;(hash(\u0026#34;reflected\u0026#34;)) .data\u0026lt;\u0026amp;my_type::static_variable\u0026gt;(hash(\u0026#34;static\u0026#34;)) .data\u0026lt;\u0026amp;my_type::data_member\u0026gt;(hash(\u0026#34;member\u0026#34;)) .data\u0026lt;\u0026amp;global_variable\u0026gt;(hash(\u0026#34;global\u0026#34;)); 他这里的写法非常巧妙，用地址（地址本身也是一个 uint32_t 或者 uint64_t）来作为模板参数，我第一开始愣是没看懂这写法，不过仔细读一读还好，相当于一口气完成了地址与类型的双重注册，不过我想诟病的地方在于作者为了追求极限性能，连 identity 参数都用了 hash + string_view，就离谱 \u0026hellip;\u0026hellip;\n如果我们最终使用 meta 的话，还是要再封装一层。rttr 的话，接口是比较好用的，但我接受不了的是 rttr 的工程竟然用 cmake 去检查 README 和 LICENSE 符不符合它的要求 \u0026hellip;\u0026hellip;\n具体使用哪个写到反射系统的时候再挑选吧，实在不行自己写一个也不是什么麻烦事，我是比较倾向于静态反射的，而 UE 的反射系统是动态反射，实现起来还稍微有些区别，性能上也要差一截，优点就是动态反射对脚本很友好，看完下一小节你就知道我说的是什么了。\n脚本如何与 ECS 融合呢？ 其实我早就说了，引擎本身按照 ECS 逻辑编写并不代表脚本也要套 ECS。如果是从头到尾都用 ECS 的话，那么用户必须要接受的是改变以前写 GameObject 的风格，投入编写 Component 和 System 的怀抱。\n设想反射系统最后是用纯静态反射，ECS 也在 C++ 层开始构建，脚本完全 ECS 化，那么我们就避不开一个大问题 —— “用户自定义的 Component 要怎么被下面 C++ 所感知到？”\n假设用户在脚本里面定义了一个 Component 和一个 System：\nconst helloComp = { a: 1, b: 2, c: 3 }; const helloSystem = (registry, time) =\u0026gt; { // systen logic }; 这里用户自定义的 HelloComp 对应的 C++ 的 Archetype 很明显是：\nstruct HelloComp : public Comp { int a; int b; int c; } 但不巧的是脚本是弱类型的，C++ 根本就没办法感知到类型好嘛？那实际上填充数据的时候，entt 可是需要这样的：\nentt::registry registry; const auto entity = registry.create(); registry.emplace\u0026lt;HelloComp\u0026gt;(1, 2, 3); 这里的模板参数根本就没法填 \u0026hellip;\u0026hellip;\n我和 bluesky013 讨论后，我们一起得到一个可行的方案，就是用户将 Component 和 System 分开为两个文件编写，System 部分不动，Component 部分修改成下面这样：\n// hello.comp.js export const entry = (componentManager) =\u0026gt; { componentManager.define({ name: \u0026#34;Hello\u0026#34;, attrs: { a: DataType.Int, b: DataType.Int, c: DataType.Int } }); }; 然后我们需要经过一轮预编译，我们的预编译器会执行所有的 .comp.js 文件，然后找到 entry 方法进行调用，执行完所有类型的注册之后，预编译期会从 componentManager 中取出所有的 Component 类型信息，生成一系列头文件和代码\n// hello.generated.h struct Hello : public Comp { int a; int b; int c; } // hello.generated.cpp extern \u0026#34;C\u0026#34; { void RegisterComp() { // 一些初始化的事情，会在库被加载时被自动执行 } } 这样就能让脚本系统里面定义的类型也被 C++ 感知到了，这个思路其实和 QT、UE 很想，只不过他们是对 C++ 进行元编译，我们是对脚本语言而已~\n脚本语言和引擎的选择 我是狂热的 JavaScript 爱好者，所以 Explosion 的脚本语言当然要使用 JavaScript 啦~\n兜了一圈我看了很多小型嵌入式 JavaScript 引擎，不过说实话质量都一般般，挣扎了一波后我还是准备把这个大家伙给带进来：V8\n经过这波调研我才发现，果真 V8 出来都没人敢做 JavaScript 引擎了，它的统治地位真没啥好说的 \u0026hellip;\u0026hellip;\n简单看了一下集成指南 —— Getting started with embedding V8，官方例子如下：\n// Copyright 2015 the V8 project authors. All rights reserved. // Use of this source code is governed by a BSD-style license that can be // found in the LICENSE file. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026#34;include/libplatform/libplatform.h\u0026#34; #include \u0026#34;include/v8.h\u0026#34; int main(int argc, char* argv[]) { // Initialize V8. v8::V8::InitializeICUDefaultLocation(argv[0]); v8::V8::InitializeExternalStartupData(argv[0]); std::unique_ptr\u0026lt;v8::Platform\u0026gt; platform = v8::platform::NewDefaultPlatform(); v8::V8::InitializePlatform(platform.get()); v8::V8::Initialize(); // Create a new Isolate and make it the current one. v8::Isolate::CreateParams create_params; create_params.array_buffer_allocator = v8::ArrayBuffer::Allocator::NewDefaultAllocator(); v8::Isolate* isolate = v8::Isolate::New(create_params); { v8::Isolate::Scope isolate_scope(isolate); // Create a stack-allocated handle scope. v8::HandleScope handle_scope(isolate); // Create a new context. v8::Local\u0026lt;v8::Context\u0026gt; context = v8::Context::New(isolate); // Enter the context for compiling and running the hello world script. v8::Context::Scope context_scope(context); // Create a string containing the JavaScript source code. v8::Local\u0026lt;v8::String\u0026gt; source = v8::String::NewFromUtf8(isolate, \u0026#34;\u0026#39;Hello\u0026#39; + \u0026#39;, World!\u0026#39;\u0026#34;, v8::NewStringType::kNormal) .ToLocalChecked(); // Compile the source code. v8::Local\u0026lt;v8::Script\u0026gt; script = v8::Script::Compile(context, source).ToLocalChecked(); // Run the script to get the result. v8::Local\u0026lt;v8::Value\u0026gt; result = script-\u0026gt;Run(context).ToLocalChecked(); // Convert the result to an UTF8 string and print it. v8::String::Utf8Value utf8(isolate, result); printf(\u0026#34;%s\\n\u0026#34;, *utf8); } // Dispose the isolate and tear down V8. isolate-\u0026gt;Dispose(); v8::V8::Dispose(); v8::V8::ShutdownPlatform(); delete create_params.array_buffer_allocator; return 0; } 说实话其实和 Lua 差不多，应该难度不高，但还是要先试试，不知道这么大体量的怪物会不会有什么天坑 \u0026hellip;\u0026hellip;\n最后，还是跟自己和 Explosion 说一声加油~\n参考资料 GDC Vault - FrameGraph rttr EnTT meta V8 JavaScript Engine Embedded V8 Sample ","date":"2021-05-27T00:00:00Z","permalink":"https://www.kindem.xyz/post/40/","title":"Explosion 开发笔记 (三)"},{"content":"CRTP CRTP 全称 Curiously Recurring Template Pattern，即奇异递归模板模式，是一种经典的 C++ 设计模式，听起来很反人类，我们先来看一段代码：\n#include \u0026lt;iostream\u0026gt; template \u0026lt;class T\u0026gt; class Base { public: void Foo() { static_cast\u0026lt;T*\u0026gt;(this)-\u0026gt;FooImpl(); } }; class Child1 : public Base\u0026lt;Child1\u0026gt; { public: void FooImpl() { std::cout \u0026lt;\u0026lt; \u0026#34;hello1\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Child2 : public Base\u0026lt;Child2\u0026gt; { public: void FooImpl() { std::cout \u0026lt;\u0026lt; \u0026#34;hello2\u0026#34; \u0026lt;\u0026lt; std::endl; } }; template \u0026lt;class T\u0026gt; void Print(Base\u0026lt;T\u0026gt;\u0026amp; base) { base.Foo(); } int main(int argc, char* argv[]) { Child1 child1; Child2 child2; Print(child1); Print(child2); } 这是一个 CRTP 的典型使用场景 —— 静态多态，其实很容易理解，如果需要在编译期让父类的某个方法调用子类的方法，那必然需要让父类能够感知到子类的类型信息，因为你需要将 this 指针转换成子类指针才能调用对应方法。\n看起来相当美好，因为让编译器打工可以省去运行时的开销，这里很明显就是使用构建时间去换取虚函数表的开销。但我想说的是，静态多态是个伪命题。\n模板的传染性 我之所以说静态多态是伪命题，是因为从本质上来看，静态多态其实不能算作真正的多态，其实从某种意义上来说，只是让编译期帮你 Hard Code 而已~\n注意上面我写的那段代码：\ntemplate \u0026lt;class T\u0026gt; void Print(Base\u0026lt;T\u0026gt;\u0026amp; base) { base.Foo(); } 我为什么需要使用一个模板方法来做 Base::Foo() 的调用？很明显是因为虽然 Child1 和 Child2 同源自 Bsae\u0026lt;T\u0026gt;，但实际上他俩的基类完全是不同类型！\nclass Child1 : public Base\u0026lt;Child1\u0026gt; {} class Child2 : public Base\u0026lt;Child2\u0026gt; {} 既然是不同类型，那么我就无法将内存从父类和子类之间自由转换，也就无法完成传统意义上的多态。\n解决办法是什么呢，很简单，就是再加一个方法，把它的入参也变成模板，然后在入参处加上限定符，完成类似 Concept 的概念，这就是我说的模板的传染性，一旦你采用模板来构建你的代码，那么你就要做好从头到尾都使用模板的准备。\n其实这一特点单单影响方法还好，模板方法不嫌多，但是如果我想要使用静态多态实现的类有多层继承关系呢？看看下面这段代码：\n#include \u0026lt;iostream\u0026gt; template \u0026lt;class T\u0026gt; class Base { public: void Foo() { static_cast\u0026lt;T*\u0026gt;(this)-\u0026gt;FooImpl1(); } }; template \u0026lt;class T\u0026gt; class Middle : public Base\u0026lt;Middle\u0026lt;T\u0026gt;\u0026gt; { public: void FooImpl1() { static_cast\u0026lt;T*\u0026gt;(this)-\u0026gt;FooImpl2(); } }; class Child1 : public Middle\u0026lt;Child1\u0026gt; { public: void FooImpl2() { std::cout \u0026lt;\u0026lt; \u0026#34;hello1\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Child2 : public Middle\u0026lt;Child2\u0026gt; { public: void FooImpl2() { std::cout \u0026lt;\u0026lt; \u0026#34;hello2\u0026#34; \u0026lt;\u0026lt; std::endl; } }; template \u0026lt;class T\u0026gt; void Print(Base\u0026lt;Middle\u0026lt;T\u0026gt;\u0026gt;\u0026amp; obj) { obj.Foo(); } int main(int argc, char* argv[]) { Child1 child1; Child2 child2; Print(child1); Print(child2); } 我 TM 打个 hello 都嵌套两层模板了 \u0026hellip;\u0026hellip; 我为什么不用虚函数表呢？\n总结 模板很好，是 C++ 元编程的基石，在写基础库的时候非常实用，而且让编译期打工能大大减少运行时开销，但是模板的传染性是一个大问题，类型的缺失会不断传染，在设计时需要提前考虑，在合适的场景使用合适的设计。\n","date":"2021-05-16T00:00:00Z","permalink":"https://www.kindem.xyz/post/39/","title":"醒醒吧，静态多态根本没有这么香"},{"content":"SPA 它真的香吗？ 我喜欢用三个里程碑来界定目前 Web 发展的历史：\nHTML + CSS + JavaScript 模式的诞生 -\u0026gt; 静态页面时代 Server-Side-Render (SSR) 的诞生 -\u0026gt; 动态页面时代 React / Vue / Angular 的普及 -\u0026gt; SPA 时代 在远古时期，网页的组成其实非常简单，简单来说以前的服务器其实就是简单的文件服务器，上面只存放 HTML、CSS、JavaScript 文件，而用户通过浏览器去访问页面，实际上就是把文件下载下来跑起来而已。\nSSR 的诞生，催化了 Web 的极速发展，实际上跟静态页面的变化只是之前固定的 HTML 页面变成了由服务器根据模板引擎动态拼接 HTML 字符串返回而已，但仅仅是这么一点变化，就让原本静态的网页，产生了丰富多彩的组合，各种论坛像雨后春笋一样狂野生长，这段时间也诞生了一大批轮子，WordPress、JavaWeb、.NetWeb，可以说这些轮子是那个年代 Web 人的烂漫。\n近几年 React / Vue 一类的 SPA 框架出来之后，可以说一时间前端界为之癫狂，再加上 Node.js / NPM 生态的繁荣，一时间乱花渐欲迷人眼，所有人都被 SPA 惊艳到了。\n所谓 SPA，全称 Single-Page-Application，简单来说就是把部分以前 Server-Side 做的事情放到了 Browser-Side，服务器只负责把静态资源 (HTML, CSS, JavaScript, Images) 打包好返回给前端，然后由前端自己来进行 HTML Document 的渲染。\n从架构上来看，SPA 简直酷炫无比，因为它的设计原则是把整个网站当成一个应用来看待，加载站点的过程实际上就像下载一个资源包，下载好资源包之后就把控制权完全交由应用，让应用自己负责，服务器只负责提供资源和处理一些 Ajax 数据请求。\n听起来是不是无限美好？符合人类思维的设计理念、丰富的轮子、组件化的开发、强大的工具链，简直不要太完美。事实上也如此，看 React / Vue 的 Star 和 NPM 下载量就能看出来人们对 SPA 有多热衷了：\nReact GitHub Vue GitHub React NPM Vue NPM 我曾经也是 SPA 的忠实拥趸，尤其是 React，Prop、State 的设计让我癫狂，让我迷恋。可是用的越久，我发现的问题越多。\n聊聊我个人的经历 我大概是 17 年开始使用 React 的，到现在为止已经 4 年了，而事实上，我制作的大部分页面都是使用 React 编写的，就拿我博客来说，我的博客到现在已经是第五版了，站点的重写经历如下：\nBlogV1 (源码已丢失): WordPress + Custom Theme BlogV2: Django + Materialize BlogV3: Koa + React + Ant.Design BlogV4: Egg + Next + React + Ant.Design BlogV5: Hugo + Stack Theme 其中第三第四版两版加起来运行了三年之久，两版的前端都是基于 React，但我想说的是，他俩绝对是我这么多年来投入心血最多却带的最差的两届学生。\n为什么这么说呢，主要问题有两点：\n首屏性能过差 SEO 极度不友好 在 V2 时代，我有一套不是很完善但功能完备的博客系统，SEO 优化效果也还可以，百度收录量一度达到 50+，排名也比较靠前，而根据我的印象，我其实完全没特意地去做 SEO 优化，也没做什么性能优化。\n然后就是 React 的普及让我心动，我果断上车，编写了 V3，当时后端是采用 Koa 加我自研的 MVC 架构，纯 SPA，无 SSR，上线之后收录量狂掉，直到 1 为止，然后首屏性能离谱到在水管服务器上要比原来慢 10 倍不止，后来分析其实主要是因为 Ant.Design 的庞大加上我自己代码优化粒度不够。\n我开始意识到，纯 SPA 是走不通的，因为 SPA 其实是为小程序、Web 应用一类的场景设计的，博客、展示类页面使用 SPA 其实只有死路一条。但我抱着对 React 的无限期望，依然走了下去，接着我编写了 V4，V4 的存在意义就是解决 V3 时代的那两个痛点。\n事实上我也取得了一定成果，切换成 Next.js 后，React SSR 变成了开箱即用的功能，再加上 SSR 不需要传输所有资源，性能也一下子上去了。\n但 SEO 的问题还是解决不了，归根到底还是百度的爬虫对 SPA 支持是真的不太好，同样的站点， Google 爬的好好的，百度却怎么提交都一动不动。后来我才了解到，哪怕采用了 SSR 也没办法完全解决 SPA 的软肋，因为毕竟你是 Hook 的，怎么可能有土著动态页面这么快。 我尝试着在 Google Search Engine 中体检了一把，性能得分只有 36 (后来的静态页面 V5 能到 96 分，满分 100)。\n当然我也不是说 SPA 就一定不好，SPA 在做 Web 应用、小程序一类的场景有着超强的能力，而且这类应用其实本来就不需要很好的 SEO 效果，只需要首页排名靠前就已经足够了。我想表达的是采用 SPA 之后，你需要为你的站点付出很多额外的心思，举例来说，SPA 的搜索引擎快照一般都会不正确，因为动态渲染 HTML 导致很多错乱，但你去打开知乎某个页面的快照，你会发现它的快照却正常的很，我猜测知乎的做法是维护 SPA 站点的同时生成一个静态站，导引爬虫去爬静态站，因为这样是最稳妥的办法。\n那我我想说，既然已经花费了这么多心思去操劳，那为什么不一开始在技术选型的时候就将其放弃呢？既然一开始就要落回静态页面 / 动态页面，那为什么还要不断尝试不可能的 SPA 呢?\n这也是我 V5 博客的初心，不要把本来简单的事情变得复杂，不要因为热爱就犯傻，V5 已经落回静态页面了，采用的技术栈是 Hugo + Stach Theme，没什么花里胡哨的，两小时建站，督促自己把注意力集中在写博客本身上，而不是一天又一天地去优化看不见的站点基础设施。\n聊聊静态页面框架 如果经历过 WordPress 时代，相信大家都听过这么一句都市传说：\n世界上 80% 的页面都是由 WordPress 搭建的\n我其实很赞同这句话，WordPress 是一个优秀的 SSR 框架，在那个年代基本你看见一个网站，就可以看见下面标注着：\n自豪地采用 WordPress\n其实可以说 SPA 的崛起直接导致了 WordPress 的消亡。人们开始把注意力集中在 SPA 上，不断尝试新前端带来的新机遇，接受新前端带来的新挑战，而逐渐遗忘了以前的大哥们。\n可是近来，静态页面框架以肉眼可见的速度增长，从开始的 Jekyll 到 Hexo，再到 Hugo，越来越多的站点开始 ServerLess，静态页面又开始流行了起来。其实我认为这完全是可以理解的，我自认为自己是一个老前端了（虽然我多数时候没有靠前端吃饭），就我的经历而言，我对 SPA 是期待、狂热再到失望，可能大家也都发现了，技术的酷炫并不能带来什么，优质的内容才是站点的核心，大家都更愿意复用轮子，不走弯路，专注于自己本该关注的事情本身。\n再提一句，如果你使用过 Hexo、Hugo，你就能体会我说的话了，主题一堆随便挑，两小时建站，( 逃：\nHexo Themes Hugo Themes 写在最后 想说 React 是我三年的挚爱，不过只能说好钢没用对地方，如果让我自己创业布设网站的话，我还是会毫不犹豫地选择 React / Vue 一类的 SPA 框架，因为当你拥有足够的资源、时间去优化、调试、强化，SPA 会给你带来很多效益。\n但对我来说，我的体验只能是 “React，爱你在心口难开”。\n我相信，静态页面的文艺复兴只是一个信号，会逐渐让大家相信，每一种技术都有它自己的存在意义与适用场景，就像打工人，专业对口才是真正的奥义~。\n","date":"2021-05-11T00:00:00Z","permalink":"https://www.kindem.xyz/post/38/","title":"Web 杂记 | 为什么我称这个 Web 时代是静态页面的文艺复兴？"},{"content":"第一个三角形！ 先说说近期的进展吧，最大头的成果就是趁着五一假期把 VulkanDriver 基本写完了，经典三角形：\nTriangle 基本的接口封的差不多了，后面的小问题再慢慢修修补补吧。\n然后就是工程建设方面的，差不多这段时间把这些东西搞起来了：\nCI (GitHub Action) 三方库 Git SubModule 支持 README / WiKi 单元测试框架本来想加上，但想到目前也只有 Driver，没什么写 UT 的必要性，想想也就算了，等到后面慢慢有需要再加吧，反正集成 UT 框架也就是几行 CMake 的事情。\n接下来要做的是 RPI、Runtime、场景管理等，还得把预置的 Components、Systems 给加上，总之好好加油吧。\n不省心的 RHI RHI 是写引擎绕不开的巨坑，时常想吐槽这么多 API，你们相互之间打一架好不好，这么多年了也一直搞不出一个统一的 API，各个平台都想围绕自己打造封闭的生态。\n写 RHI 最难的事情就是要拿一套统一的接口去封装多个图形 API，于是乎割舍功能和删删改改变成了常态，称 RHI 为脏活累活一点不过分。对各个 API 的了解程度将直接决定 RHI 最终接口的实用程度。\n别的很多东西其实可以借鉴老哥们，但是针对 RHI 这层来说，老大哥们的封装其实也不咋地，因为以前的 API 粒度毕竟是较 High Level 的（如 OpenGL、DX9 一类的），很多情况下无法发挥完全能效，再或者看看 CryEngine，索性直接 typedef 实现多态，硬生生把 RHI 和 RPI 糊在一起，只要我没有 RHI，最不存在烦恼，嗯，没毛病。\n之前也听同事吐槽过，自己造引擎如果从底层开始写，写到最后发现自己删了好几遍代码，写来写去最后还是一个三角形，上面的啥也没写。\n我目前的想法是先按照 Vulkan 的概念简单封装后搭建 Driver 的公共接口，这样上面的 RPI 和游戏逻辑框架也可以先写起来了，日后再慢慢补充 DX12Driver 和 MetalDriver。\n目前 VulkanDriver 封装的概念如下：\nDriver Device SwapChain Image ImageView Sampler RenderPass FrameBuffer GraphicsPipeline ComputePipeline DescriptorPool DescriptorSet GpuBuffer CommandBuffer CommandEncoder Signal Fence 基本涵盖了 Vulkan 的大部分概念，实现的过程中发现主要是 Enum 的转换与 Flags 的处理比较恶心，而且日后这部分在其他 Driver 的兼容性上估计也会出岔子，我目前的想法是尽量使用继承和多态将复杂的 Flags 组合给完全屏蔽掉，来提高兼容性。\n目前 VulkanDriver 已经基本实现完全了，争取不再往上面放太多精力，先关注上面那些没做的东西，等到 DX12 和 Metal 也添加进来后，再慢慢开始写 RHI 线程管理、内存管理、 CommandQueue 一类的功能。\nECS, 曙光还是末日? 介绍 ECS 前，我们先简单回顾下传统的 GameObject 游戏编程范式，在 GameObject 的世界里，游戏对象被称为 GameObject，而 Component 被称为组件，组件是承载数据和逻辑的单位，一个 GameObject 可以挂载各种 Component 来实现不同的功能。\n像这样：\nPlayer |- TransformComponent |- PhysicsComponent |- ScriptComponent 脚本系统中往往会给一些生命周期方法和一些工具方法，来给开发者提供控制 GameObject 的能力，比如实现一个自转的功能你需要这么写（伪代码）：\npublic float SPEED = 1.f; void onStart() { // ... } void onUpdate(float deltaTime) { this.getComponent\u0026lt;Transform\u0026gt;().rotate(Vector3.UP, deltaTime * SPEED); } 可以看见之所以我说 GameObject 既承载数据，又承载逻辑，是因为多数引擎把脚本本身也作为了一种 Component，由此产生了无穷的变化，数据流变得不可预测，难以控制。\n但是很明显，老朋友 GameObject 的有点在于好用，我甚至可以在任意 GameObject 上挂载一个脚本，然后用这个脚本去影响 World 中的一分一毫，基本可以说是毫无规则可言。\n由此，大厂们提出了一种更为先进的编程范式，称之为 ECS，关于介绍可以看 Unity 的介绍：Unity - ECS，Unity 画了几张漫画来介绍 ECS，我认为非常生动形象：\nECS Summary Entity Component System 概念如下：\nEntity：实体，只是一个 Id，不保存任何数据，也没有任何逻辑 Component：组件，是数据的集合，不存储逻辑，数据排布按照高效的内存访问方式设计 System：系统，是处理数据的逻辑，每一个系统只处理自己所关心（订阅）的组件，多数情况下系统之间还能并发 这样有什么好处呢？\n其实可以很明显的看出来，Component 可以以一种高效的方式存储，所有类似的 Component 可以存在相邻的内存空间中，这样当 System 去尝试遍历一种类型的 Component 并处理时，大部分的 Component 都会被 Cache 在 CPU 的 LN Cache 中，大大地提高速度（当然不光这一种内存管理方法，比如 Unity 采用的方法是所有具有相同 ArcheType 的 Entity 的 Components 按照顺序存放）。\n再加上每个 System 只关心自己所订阅的 Components，这样一来没有依赖的 System 之间本身可以并发，可以把 CPU 多核的能力利用起来，这也是以往的游戏引擎正欠缺的，因为多数情况下，脚本如果并发可能会导致很多问题。\n所以，“快”，就是 ECS 最大的优势。\n如果使用 ECS 的方法来改造章节开头的例子，那就会变成这样：\nPlayerEntity |- RotateComponent struct RotateComponent { float speed; }; class RotateSystem { void onUpdate(float deltaTime, Registry registry) { let view = registry.view\u0026lt;RotateComponent, TransformComponent\u0026gt;(); view.forEach((entity, rotateComp, tranComp) -\u0026gt; { Math.rotate(tranComp, Vector3.UP, deltaTime * rotateComp.speed); }); } }; 写起来明显变得更操蛋了，这也是 ECS 一直被诟病的地方，学习成本高、难用，而且由于 Component、System 完全可以交由用户自定义，有时候写着写着会违背原则，产生一些垃圾代码，所以 ECS 推广了这么多年了也一直没真正地流行起来。\n回到标题，我写的标题叫做 “ECS，曙光还是末日？” 我指的其实是对开发者来说的，从正面看，ECS 是明显的数据驱动范式，能够把数据和逻辑完全解耦，从长远来看是能提高工程的质量的，而且加上正确操作下 ECS 确确实实能提高 CPU 这边逻辑的运行速度。但是从反面来看，使用 ECS 从编程思维上就完全升维了，很多开发者很难适应，就算适应了，要写出来高质量的代码，还需要一定的学习成本，所以说，ECS 能带来曙光，也完全能带来末日。\n我自己是忠实的 ECS 拥趸，我的观念中，ECS 带来的利是远远大于弊的，速度是一方面，我认为更重要的是 ECS 那种数据驱动、数据 / 逻辑分离的思想，对提高工程中代码质量、降低维护成本都是很有帮助的。\n总而言之，期待 ECS 之后的发展，也期待 Explosion 与 ECS 碰撞出奇妙的火花。\n","date":"2021-05-04T00:00:00Z","permalink":"https://www.kindem.xyz/post/37/","title":"Explosion 开发笔记 (二)"},{"content":"安装依赖 需要安装的依赖如下：\nautoconf automake Qt5 其中 Qt5 是 RenderDoc 的界面库，autoconf 和 automake 在构建 c 胶水层生成工具 swig 会使用到。\n我们可以直接使用 brew 依次安装所有依赖：\nbrew install autoconf brew install automake brew install qt5 完成安装后，还需要配置一下 Qt5 的 bin 目录到 PATH 中：\nexport PATH=\u0026#34;/usr/local/opt/qt@5/bin:$PATH\u0026#34; 编译 RenderDoc 首先下载源码，可以直接去 github 下载最新的 release 版本：GitHub - RenderDoc：\nRenderDoc - Downloads 下载完成后解压：\ntar -xvf renderdoc-1.13.tar.gz 完成后进入 RenderDoc 源码目录使用 CMake 开始构建：\ncd renderdoc-1.13 mkdir build cd build cmake .. cmake --build . -j 16 建议构建时开启 VPN，因为会去墙外下载他们修改过的 swig 源码并当场构建，网络不好可能会构建失败。\n运行 完成构建后可以在 build/bin 目录下找到构建完成的 RenderDoc App：\nBuild Result 运行即可：\nRenderDoc ","date":"2021-05-03T00:00:00Z","permalink":"https://www.kindem.xyz/post/36/","title":"MacOS 编译 RenderDoc"},{"content":"Explosion 是我新开发的游戏引擎，GitHub 地址在这里： Explosion，预计是一个大大的工程，我也将持续开发与维护，欢迎志同道合的朋友加入与我一同创造新的游戏秩序。我会在博客中持续更新自己开发过程中的一些心得与思考，欢迎大家关注，Explosion 的故事将由此开始。\n为什么要做 Explosion 其实早在上大学那会，我就对计算机图形学和游戏开发有着浓厚的兴趣，大一的时候使用过 Unity 和 Unreal 开发过游戏，在计算机图形学课程设计中，也使用过 OpenGL 2.0，当时大二大三那会接触到了 Web 开发，后来就一直沉迷于 Web 无法自拔了。\n机缘巧合下，我的工作却恰好又是跟图形学相关，第一次接触可编程渲染管线（那会是使用 OpenGL）的时候，我仿佛打开了新世界的大门，复杂的游戏场景原来都是由这样的原语构成。\n加上自己的兴趣爱好（当然是电子游戏！）使然，组织架构调整的时候我毅然加入了实验室的渲染引擎组，开始参与渲染引擎的开发。\n再后来我接触到了 Vulkan、DX12、Metal 等更现代的 GraphicsAPI，同时也逐渐了解了硬件的工作原理，也逐渐理解了游戏底层神秘的引擎到底是怎么运作的，兴趣越来越浓。\n俗话说的好，认识一门技术最好的方法就是造轮子，于是我义务反顾地投入了游戏引擎开发大军。\n谈谈前辈们 我心目中的游戏引擎一哥当然是 Unreal，老二是 Unity，全封闭的引擎生态这里就不提了。\nUnreal 的优点当然是不需要做很多的额外开发，就能获得相当不错的画质效果，相反，缺点则是如果你不是很懂一些渲染的原理，Unreal 对你将会很不友好，很多时候，读它给的文档不如直接读源码。另外如果要加一些自己的扩展特性的话，一旦涉及到渲染管线，大概率要改代码然后再源码编引擎，不过，Unreal 自己的意思也很明确了，老子开源，给你看你不会改，怪谁？\nUnity 的话，对开发者的友好程度就要好很多了，文档、资料、教程相当多，C# 写起来也相对比较舒服。Unity 的画质不自己搞的话也就那样了，不过 Unity 也说了，我扩展性这么高，你自己不会写，怪谁？\n另外，值得一提的是，针对新的游戏架构 ECS，Unity 在这方面应该算是先驱了，自己已经弄了一套 ECS 的 Preview 接口了，有空可以详细聊聊 Unity 的 ECS。\nUnreal 和 Unity 的源码我都读过一部分，Unreal 和 Unity 只能说这种体量的东西是工程界的奇迹，只要架构没有腐坏到无可救药的程度，哪怕局部屎再多也能糊住，多数情况下，它们的代码看起来就是微观来看简直屎的不行，但从宏观架构来看还能过得去。\n再下来我了解到的一些引擎有 CryEngine、Cocos、Godot、KlayGE 等。\nCryEngine 的代码简直可以用灾难来形容，在其上搭建的 Amazon Lumberyard 也是一个灾难，相信我，只要你看一眼它的 CD3D9Renderer 你就知道我在说什么了。CryEngine 的文档也很差劲，不过好像它的忠实拥趸还挺多，但据我所知，买过它来做游戏的育碧和 EA 都跑路了，CryEngine，把你弄哭的引擎。\nCocos 的代码我没有读过，在国内流行度其实还算可以，早年只做 2D，近期开始投入 3D Creator 的开发，完成度还不够，不过 Cocos 的劣势在于其专攻在 Web 和移动端，使用的 GraphicsApi 是 WebGL。GL 系的 GraphicsApi 其实限制了引擎的发挥，而 WebKit 的设计上，GraphicsApi 目前来说又只有 WebGL 可以选用，因为可汗组织推出的 WebGPU 标准还未完全投入使用，可以期待 WebGPU 和 WebAssembly 的普及可以让 Cocos 这类的引擎用上 Vukan、DX12 和 Metal。\n另外的引擎就算比较小型的了，Godot、KlayGE 一类的，东西越小越好维护，代码越简单。虽然引擎本身可能并不适合商用，但很适合开发者去学习原理。\n我对 Explosion 的期待其实很简单，就是遵循前辈们开辟的道路一步步前进，取其精华去其糟粕，慢慢打造属于自己的引擎，不求以后能怎么样，但求能把功能做完整、做精致。\n初步计划 先抛开 IDE 不看，目前来看近期要做的最基础的功能如下：\nRender Hardware Interface (RHI) Render Pipeline Interface (RPI) ECS Material System Game Runtime Game Script System 先看前三项，RHI 层的作用很简单，就是抽象不同的 GraphicsApi，对 RPI 层提供统一的接口，目前我打算封装的 GraphicsApi 只有 Vulkan、DX12、Metal，其他的老一点的 Api 就不打算封了，推动技术前进的最好方法就是不要去兼容腐坏的技术。\nRPI 层封装渲染管线接口，在我的理解中，就是 Renderer 的核心逻辑的抽象。\nECS 是对外的逻辑接口总线，分为 Entity、Component、System 三块，我的目标是做成标准的 ECS，带内存管理的那种，高效利用 CPU Cache 的性能优势。目前准备直接集成 entt 开源库，日后可能自己再写一套。\nMaterial System，其实这是一大难题，多数引擎的做法是提供预制材质和自定义材质，不过自定义材质的封装感觉都很别扭，看看日后自己能不能在这方面找到突破。\nGame Runtime，游戏运行时，简单来说就是诸如 GC、反射一类的基础功能，对上会直接承接 Game Script System，对下承接 ECS。这块可以参考 Unreal 老大哥的做法，不过要写的更精简些。\nGame Script System，脚本系统，需要选择一种语言集成，按我的喜好来看，JavaScript / TypeScript 当然是首选，不过有了反射系统的机制，无论哪一种语言其实都很容易集成进来。\n最后，写给自己和 Explosion，加油。\n","date":"2021-04-15T00:00:00Z","permalink":"https://www.kindem.xyz/post/35/","title":"Explosion 开发笔记 (一)"},{"content":"1. 垃圾回收 垃圾回收（ GC ）可以说是现代编程语言的标配，GC 简单来说就是语言运行时自动判别申请的内存是否还在被使用，判断内存无用后则自动回收内存。内存管理从来就不是什么容易事，需要手动管理内存实际上也是 C/C++ 入门门槛高的一大原因，稍有不慎就会造成内存泄露。\nUnrealEngine4 在自己的 Runtime 中实现了 GC 功能，所有使用 NewObject() 或 LoadObject() 方法创建的对象都会受 GC 系统的管制，当对象无用后将会自动释放。\n2. UE4 GC 源码阅读 首先我们要知道，在 UE4 中，是不能通过 C++ 内置的操作符 new 来创建对象的，使用 new 创建的对象将不受 UE4 Runtime 的控制，正确的做法是使用 NewObject() 或者 LoadObject() 方法创建或加载对象。\n首先我们需要知道，当使用 NewObject() 创建对象后，真正的内存将会被保存至一个全局数组中，另外还需要在一个全局 Hash 表中保存一些其他信息，这部分代码在 /Engine/Source/Runtime/CoreUObject/Private/UObject/UObjectHash.cpp，我们需要关注两个关键信息：\nFUObjectArray GUObjectArray; class FUObjectHashTables { // ... static FUObjectHashTables\u0026amp; Get() { static FUObjectHashTables Singleton; return Singleton; } } 其中 GUObjectArray 就是全局对象数组，而 FUObjectHashTables 是一个单例，类内部维护了几张 Hash 表，存储了对象之间的关系。我们先看 GUObjectArray，它的类型是 FUObjectArray：\nFUObjectArray 可以看到内部封装了一个 FChunkedFixedUObjectArray，然后提供了一些 Index 与 对象之间转换的工具方法，我们再接着看 FChunkedFixedUObjectArray：\nFChunkedFixedUObjectArray Objects 就是真正申请的内存了，通过 NewObject() 创建的对象都会保存在指针数组中。接下来我们看 FUObjectHashTables：\nFUObjectHashTables 不用多少，内部保存了很多张 Hash 表来存储对象之间的关系，然后提供了摇树压缩和 Hash 表相关操作的方法。\n接下来，我们来看 GC 的整体流程，GC 的起点是 UWorld#Tick()，可以顺着我给的时序图来梳理整个流程：\nGC 在 UWorld#Tick() 中会调用 UEngine#ConditionalCollectGarbage() 来开始垃圾收集，其中又会调用全局方法 CollectGarbage()，其中会先获取全局锁，暂停主线程以外的所有线程，即 GC 中常见的 \u0026ldquo;Stop The World\u0026rdquo; 操作，此时主线程会完全被 GC 工作占用，其他线程被锁停止。\n开始 GC 后，会调用 FRealTimeGC#PerformReachabilityAnalysis() 方法来进行对象可达性分析，UE4 使用的 GC 算法是 \u0026ldquo;标记-清除\u0026rdquo; ，从后面调用的 MarkObjectsAsUnreachable() 和 CollectReferences() 也能看出端倪。\n在完成对象标记后，会调用 GatherUnreachableObjects() 方法来收集所有不可达的对象，并将其保存在一个临时数组中，之后会调用 UnhashUnreachableObjects() 方法来销毁所有不可达的对象，这一步中会调用到 UObject 的生命周期 BeginDestroy()，在基类的实现中有具体的销毁流程。\n最后调用 ShrinkUObjectHashTables() 方法针对全局 Hash 表 FUObjectHashTables 进行摇树压缩，完成后释放 GC 锁，这样就完成了一轮 GC 的所有流程。\n","date":"2021-02-16T00:00:00Z","permalink":"https://www.kindem.xyz/post/34/","title":"UnrealEngine4 源码剖析 (二) 垃圾回收"},{"content":"1 自省、反射 我们先来看一下 Java 中的反射机制定义：\nJava 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性。\n定义的前半句即自省，而后半句即反射。使用 UE4 的朋友应该大多数都是 C++ 开发者，但是如果大家使用过一些 C++ 之外的现代语言，就会明白自省和反射的重要性。\n自省与反射的用途非常广泛，比如很多语言（如 Python）的命令行脚本解释器、对象的自动序列化（通过自省遍历属性并依次序列化）、QT 的信号槽等，都是基于自省与反射实现的。\n仔细想一想，其实要实现语言层面的自省与反射，是很简单的，只需要在编译字节码 / 二进制的时候额外写入类、属性、方法的类型信息即可。但是 C++ 由于年龄实在太大，在设计之初并没有考虑如此基础的功能，以至于到现在为止，C++ 也没在标准中提供自省与反射的语言支持。\n但是人们的智慧是无穷无尽的，很多使用 C++ 构建的软件都会选择自己实现一套反射系统。目前已知的套路有两种：\n手动注册类型信息 预编译器生成类型信息 手动注册类型信息就显得很简单粗暴了，这里有一个有名的库，叫做 rttr，上一段代码，你就秒懂他的原理了：\n#include \u0026lt;rttr/registration\u0026gt; using namespace rttr; struct MyStruct { MyStruct() {}; void func(double) {}; int data; }; RTTR_REGISTRATION { registration::class_\u0026lt;MyStruct\u0026gt;(\u0026#34;MyStruct\u0026#34;) .constructor\u0026lt;\u0026gt;() .property(\u0026#34;data\u0026#34;, \u0026amp;MyStruct::data) .method(\u0026#34;func\u0026#34;, \u0026amp;MyStruct::func); } 这里使用 rttr 库注册了一个名为 MyStruct 的结构体，代码很简单，就是在一个静态块中手动注册了 MyStruct 的属性与方法。在完成注册之后，就可以开始经典的反射操作了，如遍历属性：\ntype t = type::get\u0026lt;MyStruct\u0026gt;(); for (auto\u0026amp; prop : t.get_properties()) std::cout \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; prop.get_name(); for (auto\u0026amp; meth : t.get_methods()) std::cout \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; meth.get_name(); 这种方法相当简单，但是问题也很明显，设想如果我写了一个类但是忘了写注册代码，岂不是裂开？另外，我也不能改一下类定义又立马去比对差异然后把类型信息也加上吧。所以相比于上面这种原始而粗暴的方法，预编译器 生成类型信息往往更得到大项目的青睐。\n著名的 C++ 跨平台 GUI 框架 QT 使用的则是这种方法，先看一段 QT 的代码：\nclass SampleWidget : QWidget { Q_OBJECT ... } QT 有一个自己的预编译器，叫做 MOC，在源码输入编译器之前，会先经过 MOC 处理一遍，Q_OBJECT 是一个空宏，它的作用很简单，就是告诉 MOC 分析头文件中的类、属性、方法的类型信息，然后生成对应的宏展开，再把这些额外生成的宏展开一起丢进编译器编译，最后全自动生成类型信息，这样就可以使用反射系统了，具体的原理大家可以自己去了解一下。\n当然 UE4 使用的也是预编译器生成类型信息的方案，UE4 的预编译叫 UHT (Unreal Header Tool)，我们后面会做一期专题详细聊聊它。读 UObject 的源码，了解到这里就够了。\n2. UObject 在 UE4 中，所有游戏线程的对象都会继承自 UObject 类，UObject 类提供了三大功能：\n自省与反射 GC 序列化 序列化和 GC 我会在下一节中统一分析，本篇将着墨讲自省反射。\nUObject 的代码在 /Source/Runtime/CoreUObject/Public/UObject/UObject.h，先来看看 UObject 的继承关系：\nUObject Class 其中，UObjectBase 提供了四个核心属性：\nInternalIndex：对象在全局表中的唯一索引 ClassPrivate：对象的 UClass 类型 NamePrivate：对象名，也是全局唯一 OuterPrivate：对象所属的 Outer 对象，即对象所在的 UPackage UObjectBaseUtility 没有额外属性，提供了一系列引擎内部使用的方法，我们不必太关心。\nUObject 扩展出了一些生命周期方法，以及最重要的序列化方法 Serialize()，调用 UObject#Serialize() 即可完成对象的序列化或反序列化。\n另外全局对象表代码在 /Source/Runtime/CoreUObject/Private/UObject/UObjectHash.cpp，进入文件我们可以找到两个关键类：\nFUObjectArray FUObjectHashTables 可以理解 FUObjectArray 是一个全局指针数组，存储了所有使用 NewObject 创建的对象。而 FUObjectHashTables 记录了对象间的各种关系，在 GC 销毁对象时，会释放 FUObjectArray 中的内存和 FUObjectHashTables 的对象关系。\n3. UField、类型系统及反射 想要实现反射，一套用于描述类型的数据结构是必不可少的，UE4 中当然也定义了这么一套类型系统用于描述 C++ 的所有类型。\nUE4 的类型数据结构统一继承自 UField，由于代码比较多，我们先看一下整体的类图：\nUField 上来第一眼，大家可能好奇的是为什么 UField 要继承自 UObject，这里可以参考一下 Java 的 Class 也是继承自 Object 的，之前也说了 UObject 除了反射，还提供了序列化和 GC 两大功能，让 UField 继承自 UObject 则可以直接让类型系统的类也享受到这两个功能。\n接下来我们说说 UField 的子类都是做什么的：\nUProperty: 表示 C++ 中的属性，即类或结构体的成员变量。 UEnum: 表示 C++ 中的枚举，内部保存了一个 TMap，维护了 Name、Value、Index 三大信息的对应关系，联想一下 C++ 的枚举就能明白。 UStruct: 表示 C++ 中的复杂类型，包含函数、类、结构体三种。内部维护了所表示类型的所有 UProperty。 UFunction: 表示 C++ 中的函数，内部维护了函数指针、栈帧、参数返回值信息，还提供了反射执行所表示函数的方法。 UClass：表示 C++ 中的类，在 UStruct 的基础上扩展了 UFunction 的保存与查找方法。 UScriptStruct: 表示 C++ 中的结构体，只是在 UStruct 的基础上增加了一些工具方法而已。 结合我提供的类图和说明，就能大致了解到类型系统的全貌了。这里要注意的一点是 UStruct 并不代表 C++ 中得到结构体，而是代表复杂类型，更坑爹的是 UFunction 居然继承自 UStruct。我理解的是 UFunction 复用 UStruct 中的 UProperty 信息的方式是把自己的参数作为属性来保存，我认为 UE4 完全可以把 UStruct 改成 UPolymer (聚合类型) 或者 UComplexType (复杂类型)，然后把 UScriptStruct 改成 UStruct。但是估计这其中有一些历史原因吧。\n到这里为止，其实大家就能明白类型系统是如何支撑反射系统工作的了，对于任意一个 UObject，我都可以拿到它所对应的 UClass，而 UClass 又可以拿到任意 UProperty、UFunction。而反过来说，我反序列化之后拿到类型信息，对于任意一段内存，都可以取得想要的属性、调用想要的方法。这就是 UE4 反射系统的原理。\n","date":"2021-02-10T00:00:00Z","permalink":"https://www.kindem.xyz/post/33/","title":"UnrealEngine4 源码剖析 (一) UObject 概览及反射系统"},{"content":"PlantUML 介绍 PlantUML 是一款优秀的 UML 图绘制工具，使用它可以方便快捷地绘制 UML 图。我个人认为它的存在意义与 Markdown 非常相似，Markdown 的功能是流式描述文档，而 PlantUML 的功能是流式描述 UML 图，用户只需要把精力放在 UML 图的描述上，而无需关心排版。\nPlantUML 使用 Graphviz 作为 绘图引擎，通过 PlantUML 语言来构建 UML 图逻辑，稍后我们将做详细介绍。\nPlantUML 绘图环境搭建 首先，我们需要安装绘图引擎 Graphviz，官网在这：Graphviz，可以选择源码编译或者二进制包，我自己使用的操作系统是 MacOS，所以这里直接使用 brew 工具安装：\nbrew install graphviz 完成安装后，我们来搭建 PlantUML 环境，PlantUML 官方针对不同的编辑器提供了不同的插件，我自己使用的是 Visual Studio Code，在扩展中寻找 PlantUML 并安装即可：\nPlantUML Extension 到这里 PlantUML 绘图环境的搭建就完成了。\n开始绘图 PlantUML 官方的语法说明在这：PlantUML，支持的 UML 图种类有很多，这里以序列图为例，给一个简单的例子：\n@startuml A -\u0026gt; B : hello() B -\u0026gt; C : hello2() B \u0026lt;-- C A \u0026lt;-- B @enduml 新建一个文件并在其中贴上上面这段，敲 Ctrl + Shift + P (MacOS 用户是 Command + Shift + P)，然后键入 PlantUML，选择 Preview Current Diagram 项并回车，就可以看到 UML 图效果了：\nPreview 其他的 UML 图也类似，快去官网学习一下语法，然后体验极速绘图的快乐吧。\n","date":"2021-02-10T00:00:00Z","permalink":"https://www.kindem.xyz/post/32/","title":"使用 PlantUML 享受流式绘图"},{"content":"💡 背景 随着 JetBrains 查水表越来越严，各种 License Server、激活码都不管用了，而我是重度 JetBrains 用户，离开 JetBrains 系列 IDE 直接寸步难行。俗话说的好：“早买早享受，晚买免费送。”我可一定要找一个能让 JetBrains 官方送我 License 的方法。\n经过一番寻找之后，我发现了 JetBrains Open Source Project，看页面最底端：\nOpen Source License 简单来说就是只要你是一个符合条件的开源项目贡献者，你就可以获得免费的 License。\n🍙 申请 Open Source License 进入 Open Source License 页面：\nRequest 可以看见，对项目的要求有：\n满足开源项目的定义 项目启动至少三个月，并且三个月内必须有积极的提交 项目正在积极开发中 项目不能从属于商业公司或组织 项目不能提供商业服务 对申请人的要求有：\n不能贿赂项目的核心开发者 是项目的创建者或者核心贡献者 只能使用 License 开发非商业项目 不能分享 License License 的有效期为一年，一年后可以酌情延长。我们可以进入 Open Source License Request 页面开始填写申请：\nRequest 需要填写的内容有：\n项目名 项目使用的语言 项目年限 项目主页 项目仓库地址 项目 License 地址 国家 / 地区 申请 License 数量 项目描述（小作文） 邮箱 姓名 GitHub 主页 填写完成之后提交即可，一到两周后 JetBrains 会发送邮件告知申请结果。\n🍤 喜提 License 我申请时使用的项目是我个人的新博客项目 blog-v4，申请后一周即收到了 JetBrains 的回信：\nEmail 激活后即可使用 JetBrains 旗下任意产品：\nActivation 可以看到 License 上还标注了申请的项目和申请人，非常 Nice，License 使用期为一年。当然，JetBrains 官方还是希望使用者也给他们打一波广告的，于是我在项目的 README.md 中加入了 JetBrains 的赞助信息。\n到这里 Open Source License 的申请就结束了，最后还是希望大家多多支持正版，毕竟 JetBrains 为我们提供了这么优秀的工具，真的不容易。\n","date":"2021-01-19T00:00:00Z","permalink":"https://www.kindem.xyz/post/31/","title":"JetBrains 激活黑科技 - Open Source License"},{"content":"💡 背景 突然需要一个后端发送邮箱验证码的功能，我使用的后端框架是基于 Node.js 搭建的，所以准备找一个合适的能够调用 SMTP 服务发送邮件的轮子。\n一番寻找之后，我找到了 emailjs，下面简单介绍一下用法。\n📦 安装 最经典的 npm/yarn 安装：\n# Yarn yarn add emailjs # Npm npm install emailjs 📮 配置邮箱 接下来需要一个可以使用的邮箱账户，因为我不准备以个人邮箱发送验证码，我使用了免费的 腾讯企业邮箱，注册了一个企业账户，当然你可以使用任意支持 SMTP 服务的邮箱。\n接下来需要在邮箱后台配置开启 SMTP 服务：\nEmail Config 有一些邮箱对于三方客户端采取了高级的安全登录策略，不允许直接使用密码登录，而是使用 token，腾讯企业邮箱就采取了这样的方案：\nLogin Config 这时候我们需要生成一个新的 token 用于 emailjs 使用 SMTP 服务：\nToken Generate 复制客户端密码，准备使用 emailjs 发送邮件。\n🎯 Emailjs 使用 emailjs 是基于 SMTP 服务发送邮件的，我们需要先查询对应邮箱服务器的 SMTP 服务端口与地址，腾讯企业邮箱有一个 配置指南，通过配置指南我们可以得到以下信息：\nSMTP 发送服务器地址：smtp.exmail.qq.com 端口号：465 SSL：开启 接下来编写 Node.js 代码：\nconst { SMTPClient } = require(\u0026#39;emailjs\u0026#39;); const client = new SMTPClient({ user: `${senderEmail}`, password: `${password}`, host: \u0026#39;smtp.exmail.qq.com\u0026#39;, port: 465, ssl: true }); (async function () { try { await client.sendAsync({ text: \u0026#39;Hello World!\u0026#39;, from: `${senderName} \u0026lt;${senderEmail}\u0026gt;`, to: `${receiverEmail}`, subject: \u0026#39;Test Email\u0026#39; }); } catch (e) { console.log(e); } })(); 其中你需要替换这些变量：\n${senderName}：你想展示的笔名 ${senderEmail}：你的发送邮箱 ${password}：上一节申请的登录 token 或邮箱密码 ${receiverEmail}：接收者邮箱 接下来登录接收者邮箱，即可看到邮件发送成功：\nEmail Detail 如果想了解更详细的用法，可以在 github 上查看 emailjs 更详细的文档。\n","date":"2021-01-14T00:00:00Z","permalink":"https://www.kindem.xyz/post/30/","title":"使用 Emailjs 发送邮件"},{"content":"🔌 认识插件化 想必大家都知道，在 Android 系统中，应用是以 Apk 的形式存在的，应用都需要安装才能使用。但实际上 Android 系统安装应用的方式相当简单，其实就是把应用 Apk 拷贝到系统不同的目录下、然后把 so 解压出来而已。\n常见的应用安装目录有：\n/system/app：系统应用 /system/priv-app：系统应用 /data/app：用户应用 那可能大家会想问，既然安装这个过程如此简单，Android 是怎么运行应用中的代码的呢，我们先看 Apk 的构成，一个常见的 Apk 会包含如下几个部分：\nclasses.dex：Java 代码字节码 res：资源目录 lib：so 目录 assets：静态资产目录 AndroidManifest.xml：清单文件 其实 Android 系统在打开应用之后，也只是开辟进程，然后使用 ClassLoader 加载 classes.dex 至进程中，执行对应的组件而已。\n那大家可能会想一个问题，既然 Android 本身也是使用类似反射的形式加载代码执行，凭什么我们不能执行一个 Apk 中的代码呢？\n这其实就是插件化的目的，让 Apk 中的代码（主要是指 Android 组件）能够免安装运行，这样能够带来很多收益，最显而易见的优势其实就是通过网络热更新、热修复，想象一下，你的应用拥有 Native 应用一般极高的性能，又能获取诸如 Web 应用一样的收益。\n嗯，理想很美好不是嘛？\n🎯 难点在哪 大家其实都知道，Android 应用本身是基于魔改的 Java 虚拟机的，动态加载代码简直不要太简单，只需要使用 DexClassLoader 加载 Apk，然后反射里面的代码就可以了。\n但是光能反射代码是没有意义的，插件化真正的魅力在于，可以动态加载执行 Android 组件（即 Activity、Service、BroadcastReceiver、ContentProvider、Fragment）等。\n仔细想一下，其实要做到这一点是有难度的，最主要的阻碍是，四大组件是在系统里面中注册的，具体来说是在 Android 系统的 ActivityManagerService (AMS) 和 PackageManagerService (PMS) 中注册的，而四大组件的解析和启动都需要依赖 AMS 和 PMS，如何欺骗系统，让他承认一个未安装的 Apk 中的组件，就是插件化的最大难点。\n另外，资源（特指 R 中引用的资源，如 layout、values 等）也是一大问题，想象一下你在宿主进程中使用反射加载了一个插件 Apk，代码中的 R 对应的 id 却无法引用到正确的资源，会产生什么后果。\n总结一下，其实做到插件化的要点就这几个：\n反射并执行插件 Apk 中的代码（ClassLoader Injection） 让系统能调用插件 Apk 中的组件（Runtime Container） 正确识别插件 Apk 中的资源（Resource Injection） 当然还有其他一些小问题，但可能不是所有场景下都会遇到，我们后面再单独说。\n🎊 解决方案 首先来谈一谈常见插件化框架的整体架构，市面上的插件化框架实际很多，如 Tecent 的 Shadow、Didi 的 VirtualApk、360 的 RePlugin，我自己也写了一个简单的插件化框架 Zed。他们各有各的长处，不过大体上差不多，如果要具体学习，我推荐 Shadow，它的优势在于 0 Hook，没有使用私有 API 意味着可以走的很远，不会被 Google 搞。\n他们大体原理其实都差不多，运行时会有一个宿主 Apk 在进程中跑，宿舍 Apk 是真正被安装的应用，宿主 Apk 可以加载插件 Apk 中的组件和代码运行，插件 Apk 可以任意热更新。\n接下来我们按照上面要点的顺序，大致讲一下每一个方面怎么攻克。\nClassLoader Injection 简单来说，插件化场景下，会存在同一进程中多个 ClassLoader 的场景：\n宿主 ClassLoader：宿主是安装应用，运行即自动创建 插件 ClassLoader：使用 new DexClassLoader 创建 我们称这个过程叫做 ClassLoader 注入。完成注入后，所有来自宿主的类使用宿主的 ClassLoader 进行加载，所有来自插件 Apk 的类使用插件 ClassLoader 进行加载，而由于 ClassLoader 的双亲委派机制，实际上系统类会不受 ClassLoader 的类隔离机制所影响，这样宿主 Apk 就可以在宿主进程中使用来自于插件的组件类了。\nRuntime Container 上面说到只要做到 ClassLoader 注入后，就可以在宿主进程中使用插件 Apk 中的类，但是我们都知道 Android 组件都是由系统调用启动的，未安装的 Apk 中的组件，是未注册到 AMS 和 PMS 的，就好比你直接使用 startActivity 启动一个插件 Apk 中的组件，系统会告诉你无法找到。\n我们的解决方案很简单，即运行时容器技术，简单来说就是在宿主 Apk 中预埋一些空的 Android 组件，以 Activity 为例，我预置一个 ContainerActivity extends Activity 在宿主中，并且在 AndroidManifest.xml 中注册它。\n它要做的事情很简单，就是帮助我们作为插件 Activity 的容器，它从 Intent 接受几个参数，分别是插件的不同信息，如：\npluginName pluginApkPath pluginActivityName 等，其实最重要的就是 pluginApkPath 和 pluginActivityName，当 ContainerActivity 启动时，我们就加载插件的 ClassLoader、Resource，并反射 pluginActivityName 对应的 Activity 类。当完成加载后，ContainerActivity 要做两件事：\n转发所有来自系统的生命周期回调至插件 Activity 接受 Activity 方法的系统调用，并转发回系统 我们可以通过复写 ContainerActivity 的生命周期方法来完成第一步，而第二步我们需要定义一个 PluginActivity，然后在编写插件 Apk 中的 Activity 组件时，不再让其继承 android.app.Activity，而是继承自我们的 PluginActivity，后面再通过字节码替换来自动化完成这部操作，后面再说为什么，我们先看伪代码。\npublic class ContainerActivity extends Activity { private PluginActivity pluginActivity; @Override protected void onCreate(Bundle savedInstanceState) { String pluginActivityName = getIntent().getString(\u0026#34;pluginActivityName\u0026#34;, \u0026#34;\u0026#34;); pluginActivity = PluginLoader.loadActivity(pluginActivityName, this); if (pluginActivity == null) { super.onCreate(savedInstanceState); return; } pluginActivity.onCreate(); } @Override protected void onResume() { if (pluginActivity == null) { super.onResume(); return; } pluginActivity.onResume(); } @Override protected void onPause() { if (pluginActivity == null) { super.onPause(); return; } pluginActivity.onPause(); } // ... } public class PluginActivity { private ContainerActivity containerActivity; public PluginActivity(ContainerActivity containerActivity) { this.containerActivity = containerActivity; } @Override public \u0026lt;T extends View\u0026gt; T findViewById(int id) { return containerActivity.findViewById(id); } // ... } // 插件 `Apk` 中真正写的组件 public class TestActivity extends PluginActivity { // ...... } Emm，是不是感觉有点看懂了，虽然真正搞的时候还有很多小坑，但大概原理就是这么简单，启动插件组件需要依赖容器，容器负责加载插件组件并且完成双向转发，转发来自系统的生命周期回调至插件组件，同时转发来自插件组件的系统调用至系统。\nResource Injection 最后要说的是资源注入，其实这一点相当重要，Android 应用的开发其实崇尚的是逻辑与资源分离的理念，所有资源（layout、values 等）都会被打包到 Apk 中，然后生成一个对应的 R 类，其中包含对所有资源的引用 id。\n资源的注入并不容易，好在 Android 系统给我们留了一条后路，最重要的是这两个接口：\nPackageManager#getPackageArchiveInfo：根据 Apk 路径解析一个未安装的 Apk 的 PackageInfo PackageManager#getResourcesForApplication：根据 ApplicationInfo 创建一个 Resources 实例 我们要做的就是在上面 ContainerActivity#onCreate 中加载插件 Apk 的时候，用这两个方法创建出来一份插件资源实例。具体来说就是先用 PackageManager#getPackageArchiveInfo 拿到插件 Apk 的 PackageInfo，有了 PacakgeInfo 之后我们就可以自己组装一份 ApplicationInfo，然后通过 PackageManager#getResourcesForApplication 来创建资源实例，大概代码像这样：\nPackageManager packageManager = getPackageManager(); PackageInfo packageArchiveInfo = packageManager.getPackageArchiveInfo( pluginApkPath, PackageManager.GET_ACTIVITIES | PackageManager.GET_META_DATA | PackageManager.GET_SERVICES | PackageManager.GET_PROVIDERS | PackageManager.GET_SIGNATURES ); packageArchiveInfo.applicationInfo.sourceDir = pluginApkPath; packageArchiveInfo.applicationInfo.publicSourceDir = pluginApkPath; Resources injectResources = null; try { injectResources = packageManager.getResourcesForApplication(packageArchiveInfo.applicationInfo); } catch (PackageManager.NameNotFoundException e) { // ... } 拿到资源实例后，我们需要将宿主的资源和插件资源 Merge 一下，编写一个新的 Resources 类，用这样的方式完成自动代理：\npublic class PluginResources extends Resources { private Resources hostResources; private Resources injectResources; public PluginResources(Resources hostResources, Resources injectResources) { super(injectResources.getAssets(), injectResources.getDisplayMetrics(), injectResources.getConfiguration()); this.hostResources = hostResources; this.injectResources = injectResources; } @Override public String getString(int id, Object... formatArgs) throws NotFoundException { try { return injectResources.getString(id, formatArgs); } catch (NotFoundException e) { return hostResources.getString(id, formatArgs); } } // ... } 然后我们在 ContainerActivity 完成插件组件加载后，创建一份 Merge 资源，再复写 ContainerActivity#getResources，将获取到的资源替换掉：\npublic class ContainerActivity extends Activity { private Resources pluginResources; @Override protected void onCreate(Bundle savedInstanceState) { // ... pluginResources = new PluginResources(super.getResources(), PluginLoader.getResources(pluginApkPath)); // ... } @Override public Resources getResources() { if (pluginActivity == null) { return super.getResources(); } return pluginResources; } } 这样就完成了资源的注入。\n🧨 黑科技 —— 字节码替换 上面其实说到了，我们被迫改变了插件组件的编写方式：\nclass TestActivity extends Activity {} -\u0026gt; class TestActivity extends PluginActivity {} 有没有什么办法能让插件组件的编写与原来没有任何差别呢？\nShadow 的做法是字节码替换插件，我认为这是一个非常棒的想法，简单来说，Android 提供了一些 Gradle 插件开发套件，其中有一项功能叫 Transform Api，它可以介入项目的构建过程，在字节码生成后、dex 文件生成钱，对代码进行某些变换，具体怎么做的不说了，可以自己看文档。\n实现的功能嘛，就是用户配置 Gradle 插件后，正常开发，依然编写：\nclass TestActivity extends Activity {} 然后完成编译后，最后的字节码中，显示的却是：\nclass TestActivity extends PluginActivity {} 到这里基本的框架就差不多结束了。\n✨ 写在最后 插件化是一门很有意思的学问，Emm，怎么说呢，用一句话来形容就是偷天换日灯下黑，在各种坑的限制下不断跟系统博弈寻找出路。随着了解的深入，大家肯定能理解我这句话，本文也只是抛砖引玉，更多的乐趣还是要自己去发掘。\n","date":"2021-01-03T00:00:00Z","permalink":"https://www.kindem.xyz/post/29/","title":"浅谈 Android 插件化原理"},{"content":"准备工作 首先确认自己的 MacOS 上已经安装了 gcc：\ngcc --version 可以看到版本号：\nkindem@JohndeMacBook-Pro ~ % gcc --version Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applic ations/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++ /4.2.1 Apple clang version 11.0.3 (clang-1103.0.32.59) Target: x86_64-apple-darwin19.3.0 Thread model: posix InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin kindem@JohndeMacBook-Pro ~ % 如果没有安装的话会上面的指令会自动触发 XCode 下载并安装，根据提示安装完成之后再使用上面的指令检查一遍即可。\n接着安装 CLion，个人是极其推荐使用 JetBrain 家的 IDE 进行开发的，可以在如下网站下载：CLion - JetBrain，下载完成后自行完成安装与激活即可。\n安装完 CLion 之后，可以在 Settings 中检查 Toolchain 是否正确识别，如下：\nToolchain 通常来说只需要安装好 gcc 即可，因为 cmake 会在 CLion 中自带，而 make 会在 MacOS 系统中提供。\n下载依赖库 通常来说，搭建 OpenGL 的开发环境需要两剑客：\nGLFW: 提供跨平台的 OpenGL 上下文初始化与窗口创建等功能 GLAD: 提供跨平台的 OpenGL 函数指针加载等功能 我们按照顺序分别下载这些库，首先是 GLFW，地址在这：Download - GLFW，GLFW 在不同的平台上都有预编译好的包，我们根据我们的系统下载 MacOS 版本的预编译包：\nGLFW Download 接下来是 GLAD 的下载与配置，GLAD 作为一个加载器，根据不同的系统与 OpenGL，库本身都有所变化，需要灵活配置，官方提供了一个在线配置与生成库的网站：GLAD Config，我们根据我们的需要进行选择：\nGLAD Config 按照上面的图配置就行，这里的 gl 版本不一定要 3.3，我们可以根据我们的需要进行配置，完成配置之后点击 generate，可以看到：\nGLAD Lib 下载图中的 glad.zip 即可。\n将下载的 GLFW 和 GLAD 库分别解压出来并重命名，放到某个固定的目录，比如我放在 ~/Lib，接下来配置两条环境变量：\nexport GLFW_HOME=\u0026#34;/Users/kindem/Lib/GLFW\u0026#34; export GLAD_HOME=\u0026#34;/Users/kindem/Lib/GLAD\u0026#34; 推荐将这两条命令写入 ~/.bash_profile，然后使用指令刷新环境变量：\nsource ~/.bash_profile 自此库的下载的配置就完成了。\n创建与配置项目 首先使用 CLion 创建一个 C/C++ 工程，创建完成之后应该可以看到项目根目录下有一个 CMakeLists.txt 文件，这时候我们可以按照如下配置修改：\ncmake_minimum_required(VERSION 3.15) project(gl_playground) set(CMAKE_CXX_STANDARD 11) # 检查环境变量 if (NOT DEFINED ENV{GLFW_HOME}) message(FATAL_ERROR \u0026#34;found no env named GLFW_HOME\u0026#34;) endif() if (NOT DEFINED ENV{GLAD_HOME}) message(FATAL_ERROR \u0026#34;found no env named GLAD_HOME\u0026#34;) endif() # 暂存环境变量 set(GLFW_HOME $ENV{GLFW_HOME}) set(GLAD_HOME $ENV{GLAD_HOME}) # 设置头文件目录 include_directories(\u0026#34;${GLFW_HOME}/include\u0026#34;) include_directories(\u0026#34;${GLAD_HOME}/include\u0026#34;) # 添加 GLFW3 预编译库 add_library(glfw SHARED IMPORTED) SET_TARGET_PROPERTIES(glfw PROPERTIES IMPORTED_LOCATION \u0026#34;${GLFW_HOME}/lib-macos/libglfw.3.dylib\u0026#34;) # 编译 GLAD 库 add_library(glad SHARED \u0026#34;${GLAD_HOME}/src/glad.c\u0026#34;) # 创建可执行文件 add_executable(gl_playground main.cpp) # 链接 GLFW GLAD OpenGL target_link_libraries(gl_playground glfw glad \u0026#34;-framework OpenGL\u0026#34;) 编写完 CMakeLists.txt 之后，点击右上角的 Reload Changes，可以看见成功配置。\n编写测试代码 完成项目配置后，改写 main.cpp 来写一个测试小程序吧：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;glad/glad.h\u0026gt; #include \u0026lt;GLFW/glfw3.h\u0026gt; #define WINDOW_WIDTH 800 #define WINDOW_HEIGHT 600 #define WINDOW_TITLE \u0026#34;gl-playground\u0026#34; void init(); void draw_frame(); void on_input(GLFWwindow* window); void framebuffer_size_callback(GLFWwindow* window, int width, int height); int main() { glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); GLFWwindow* window = glfwCreateWindow(WINDOW_WIDTH, WINDOW_HEIGHT, WINDOW_TITLE, nullptr, nullptr); if (window == nullptr) { std::cout \u0026lt;\u0026lt; \u0026#34;failed to create GLFW window\u0026#34; \u0026lt;\u0026lt; std::endl; glfwTerminate(); return -1; } glfwMakeContextCurrent(window); if (!gladLoadGLLoader((GLADloadproc) glfwGetProcAddress)) { std::cout \u0026lt;\u0026lt; \u0026#34;failed to initialize GLAD\u0026#34; \u0026lt;\u0026lt; std::endl; glfwTerminate(); return -1; } glViewport(0, 0, WINDOW_WIDTH, WINDOW_HEIGHT); glfwSetFramebufferSizeCallback(window, framebuffer_size_callback); init(); while (!glfwWindowShouldClose(window)) { on_input(window); draw_frame(); glfwSwapBuffers(window); glfwPollEvents(); } glfwTerminate(); return 0; } void init() { } void draw_frame() { glClearColor(.2f, .3f, .3f, 1.f); glClear(GL_COLOR_BUFFER_BIT); } void on_input(GLFWwindow* window) { if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) { glfwSetWindowShouldClose(window, true); } } void framebuffer_size_callback(GLFWwindow* window, int width, int height) { glViewport(0, 0, width, height); } 点击 CLion 右上角的编译与运行，如果看到：\nHello GL 恭喜，到这里就成功啦！\nTips 可以直接 clone 这个仓库，来获取作者的示例工程：gl-macos-playground，另外推荐一个学习 OpenGL 的网站：LearnOpenGL CN\n","date":"2020-04-21T00:00:00Z","permalink":"https://www.kindem.xyz/post/26/","title":"MacOS 搭建 OpenGL 开发环境"},{"content":"🍙 整体图 话不多说，先上一张图：\nPreview 🍳 使用到的东东 Material Theme UI：一款 JetBrain 系列 IDE 可以使用的主题插件，里面内置了很多配色，可以自选。 Fira Code：一款好看的等宽连体字体。 🍔 配置 JetBrain 家的 IDE 都可以按照这个方式配置，如 IDEA、PyCharm、Android Studio、CLion 等。这里以 IDEA 为例：\n首先下载 Fira Code 字体：Fira Code - Github，点击图示按钮下载字体包：\nFira Code Download 下载完成字体包后自行字体即可。\n安装完字体后进入 IDE 设置，点击 Plugins 选项页，在搜索栏中输入 Material Theme UI，安装对应的插件，如下图：\nPlugin Install 安装完成之后需要重启 IDE，重启之后会进入一个欢迎页，便于你快速配置主题等，我们可以直接跳过，因为之后可以在设置里面手动配置。\n进入设置，搜索 material，进入图中的选项页，可以选择一些插件自带的配色：\nTheme 我最喜欢 Dracula，当然 One Dark Pro、Monokai Pro 等都是很不错的主题，可以根据自己喜欢来选择。\n配置完主题之后需要配置字体，在设置中搜索 font，找到图中的页面，但是先不要配置，点击图中的链接，进入 Color Scheme Font 的字体配置界面：\nIDE Font 点击链接后会进入下图的界面，这时候做真正的配置：\nColor Scheme Font 这里推荐配置 Font 为 Fira Code Retina，Fallback Font 为 Fira Code，字号的话 MacOS 为 15，Windows 为 14，行高 1.0，并且开启连体字功能。\n到这里就完成了配置，分享出来给大家，喜欢大家能喜欢。\n","date":"2020-04-04T00:00:00Z","permalink":"https://www.kindem.xyz/post/25/","title":"个人 JetBrain IDE 配色及字体分享"},{"content":"🧀 配置 apt-get Repo 首先打开网站 MySQL APT Repo，下载 MySQL APT 仓库描述文件：\nMySQL APT Repo 右键 No thanks, just start my download 链接，选择复制链接：\nDownload 进入服务器终端，进入工作目录：\ncd ~ 使用 wget 下载刚刚复制的 deb 文件链接：\nwget https://dev.mysql.com/get/mysql-apt-config_0.8.15-1_all.deb 版本号可能不一定相同，以你自己复制的为准。下载完成后可以看到新增的文件，使用 dpkg 将仓库添加到 apt-get 中：\nsudo dpkg -i ./mysql-apt-config_0.8.15-1_all.deb 过程中会弹窗：\nRepo Request 选择最后一项继续，完成选择后再更新一把 apt-get 的源：\nsudo apt-get update 完成后可以开始正式的安装了：\n🍙 安装 sudo apt-get install mysql-server 中途会提示输入创建数据库 root 用户密码，创建后继续即可。\n🍥 基本操作 开启服务：\nsudo service mysql start 关闭服务：\nsudo service mysql stop 重启服务：\nsudo service mysql restart 登录：\nmysql -u $username -p 🍖 创建其他账户 尽量不要直接使用 root 账户，登录数据库后使用如下指令创建用户：\nmysql\u0026gt; CREATE USER \u0026#39;username\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39;; 分配所有权限（也可按需分配）：\nmysql\u0026gt; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;username\u0026#39;@\u0026#39;%\u0026#39;; 刷新权限：\nmysql\u0026gt; FLUSH PRIVILEGES; 修改 bind-address：\nsudo vim /etc/mysql/mysql.conf.d/mysqlld.cnf 更改：\n# By default we only accept connections from localhost - bind-address = 127.0.0.1 + bind-address = 0.0.0.0 这样就可以远程登录 MySQL 了，生产环境记得改回来。\n","date":"2020-02-22T00:00:00Z","permalink":"https://www.kindem.xyz/post/24/","title":"Ubuntu / Debian 安装 MySQL"},{"content":"🍖 安装 如果使用 Homebrew 官方的安装脚本进行安装，会发现安装十分缓慢，我们可以更换安装脚本中设置的仓库路径来加速安装过程。\n首先先将官方的脚本下载下来，命名为 install：\ncurl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install \u0026gt;\u0026gt; install 使用 vim 或者其他文本编辑器打开 install 脚本，修改：\nBREW_REPO 一行为：\nBREW_REPO = \u0026#34;https://mirrors.ustc.edu.cn/brew.git\u0026#34;.freeze 保存后重新使用 ruby 运行脚本：\nruby ./install 脚本会飞速安装，然后停顿在 homebrew-core 的下载过程，此时使用 ^C 快捷键强制结束进程，将 homebrew-core 手动下载到 homebrew 安装目录：\ngit clone git://mirrors.ustc.edu.cn/homebrew-core.git/ /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core --depth=1 🧀 换源 完成上面的步骤之后，使用如下命令完成换源：\n# change brew source cd $(brew --repo) git remote set-url origin https://mirrors.ustc.edu.cn/brew.git # change brew-core source cd \u0026#34;$(brew --repo)/Library/Taps/homebrew/homebrew-core\u0026#34; git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git 完成换源之后，再执行更新指令一次：\nbrew update 看看是不是比以前快了许多呢？\n","date":"2020-02-18T00:00:00Z","permalink":"https://www.kindem.xyz/post/23/","title":"MacOS Homebrew 安装、更新慢解决方法"},{"content":"🍥 问题简述 之前用 Linux 习惯于将环境变量统一配置在 ~/.bash_profile 中，最近工作流切换到 MacOS 上，发现之前的法子不管用了，每次重启之后之前配置的环境变量就会失效。\n网上的说法是用了 zsh 才会出现这种情况，但是我自己并没有配置 zsh。\n经过一番周折发现 MacOS 在 10.15 版本以上默认终端就切换到了 zsh，所以就算没有配，也会被坑 \u0026hellip;\n🍖 解决办法 先使用这条指令查看自己到底是什么终端：\nps -p $$ 比如我自己的：\nkindem@JohndeMBP platform-tools % ps -p $$ PID TTY TIME CMD 1274 ttys000 0:00.04 zsh 可以很明显的看到这里写的是 zsh，所以需要将 ~/.bash_profile 中配置的内容移动到 ~/.zshrc，或者将：\nsource ~/.bash_profile 写入 ~/.zshrc 即可。\n","date":"2020-01-23T00:00:00Z","permalink":"https://www.kindem.xyz/post/22/","title":"MacOS 环境变量重启失效问题解决"},{"content":"在 Android Studio 中，最基本的以 debug 模式运行程序并打断点进行调试，相比大家都会，不过，如果遇到一些特殊的调试场景，则需要运用一些特殊的调试技巧来进行调试。\n🍗 在程序运行之后打断点调试 有时候，我们需要对已经运行的程序进行调试，这时候应该使用 Android Studio 的 Attach 功能：\nAttach 点击工具栏中的 Attach Debugger to Android Process 按钮，会显示出可以 Attach 的进程：\n如果未勾选 Show All Processes 选项，则只会显示当前项目对应的进程，勾选 Show All Processes 选项之后，则会显示当前机器上跑着的所有进程（需要 root 权限）。\n在调试之前先打好断点，然后在这里选择目标进程之后，即可成功断上。\n🍥 等待调试 在某些场景下，部分代码可能在程序一启动就执行完了，这种情况下，可以使用 “等待调试” 功能来让程序暂时停住，等待调试器 Attach 之后再开始执行。\n第一种方法是直接在代码中添加：\nimport android.os.Debug; // ..... Debug.waitingForDebugger(); 编译运行后，当代码执行到这一句话之后，便会显示 Wait For Debugger 字样并且暂停执行，等待用户手动 Attach 之后才会接着执行，此时，就能断住之前执行太快断不住的代码进行调试了。\n另外一种方法是使用 adb 指令：\nadb shell am set-debug-app -w \u0026lt;packageName\u0026gt; 来设置待调试应用，设置了这一条语句之后启动对应应用之后则会停住，等待调试器 Attach，这种方法的好处是可以不用修改代码就让应用等待调试。\n🧀 调试 Android SDK 源码 在一些特殊的场景，需要调试 Android SDK 源码中产生的异常，通过 Android SDK 源码中产生的现象发现自己写的代码逻辑的问题。\n这种情况下，需要使用原生 Android ROM 来进行调试，因为通常来说，第三方产商自己的 ROM 都进行了不同程度的定制，一般第三方 ROM 的字节码都与 Android Studio 提供的 SDK 源码行号对应不上，导致无法调试。最简单的方法，就是使用模拟器进行调试，因为模拟器的 ROM 是官方提供的 AOSP 系统，行号能够对应。\n另外一点需要注意的是，如果需要调试 Android SDK 源码，需要保证 build.gralde 中配置的 minSdkVersion 与系统的版本相对应，如果临时需要调试 Android SDK 源码，可以先将 build.gradle 中的 minSdkVersion 调整到目标版本，完成调试之后再改回来。\n另外，调试某个版本的 Android SDK 源码，需要先下载源码，然后通过 IDE 的跳转功能进入源码，然后就像对普通正常代码一样进行调试即可：\nAndroid Sources 🍙 调试 NDK 代码 调试 NDK 代码其实与调试 Java 代码一样，只需要在调试前将 Run Configuration 中的 Debugger 标签页中的 Debug Type 一栏修改为 Auto 或者 Native 即可：\nRun Configuration 完成修改后像对普通代码一样调试即可。\n","date":"2019-12-30T00:00:00Z","permalink":"https://www.kindem.xyz/post/21/","title":"Android 调试技巧总结"},{"content":"🍜 预备知识 Visual Studio Code (VSCode) 是微软推出的一款开源编辑器，使用 Electron 打造，与 Atom 齐名，不过随着 Atom 社区的渐渐缩小，VSCode 的影响力开始越来越大了。VSCode 内置了 Markdown 语言及预览的支持，很适合用于编辑 Markdown 文档。\nMarkdown 是一种标记语言，可以在写文档的同时，通过添加一些特殊标记，快速完成文档的排版，很多程序员都喜欢使用 Markdown 来写文档，另外，github 也使用 Markdown 作为仓库 README 的标准语言，可以说是写技术文档的首选方案。关于 Markdown 的语法，可以在这里学习：菜鸟教程 - Markdown 教程\n🍨 搭建环境 首先当然是下载安装 VSCode 啦，官网在 Visual Studio Code，一路安装即可，完成安装之后，打开 VSCode 界面如下:\nVSCode UI 为了更好的编辑体验，我们可以先安装配色 One Dark Pro，这款配色沿袭自 Atom，是公认的比较舒服的几套配色之一，在侧边栏中的插件栏中搜索 One Dark Pro 并下载:\nPlugins 完成安装之后，在顶部工具栏中依次点击 File -\u0026gt; Preference -\u0026gt; Color Theme，选择 One Dark Pro，即可看到效果：\nOne Dark Pro 之后我们需要配置一款舒适的字体，这里推荐 Fira Code，下载地址如下：Fira Code，下载 TTF 字体并安装即可，之后在 File -\u0026gt; Preference -\u0026gt; Settings 中依次更改这几项：\nFont Size: 14 Font Family：'Fira Code', Consolas, 'Courier New', monospace, 微软雅黑 Font Ligatures：true 完成这几步之后，即可安装我们的核心插件 Markdown Preview Enhanced，参考之前的步骤：\nMarkdown Preview Enhanced 这样就完成了 Markdown 写作环境的搭建。\n🍳 写作示例 如果要开始写作，首先要创建一个文件夹作为工作区，在想要的位置创建一个项目文件夹，这里我建的项目名叫 MarkdownProject：\nMarkdown Project 右键 MarkdownProject 并点击 Open With Code，这样可以直接用 VSCode 打开项目文件夹。\n点击如下两个按钮可以创建文件和文件夹：\nCreate File \u0026amp; Folder 我们在项目根目录下创建一个目录叫做 img，接着在根目录下创建一个文件 xx.md，img 目录的作用是在本地存放图片，而 .md 文件则是文档的源文件，完成创建之后，即可在其中使用 Markdown 语法进行写作了：\nProject 如果需要添加图片，推荐的做法是将图片存放到 img 路径下，并在 .md 文档中使用相对路径的形式引用：\n![xx picture](./img/xx.png) 编辑的同时可以点击：\nExample 注意不要点击另外一个类似的按钮，红框中的按钮是 Markdown Preview Enhanced 插件提供的优化版预览，而另一个是 VSCode 原生提供的预览，效果不敢恭维，点击预览之后，即可在书写文档的同时看到效果。\n最后如果需要导出文档，则只需要在预览栏中点击右键：\nExport 这里有很多种支持的格式，其中推荐使用 eBook 中的 HTML 格式，这样导出的文档不需要将图片打包一起带走，而是直接将图片使用内置编码放在文档中。另外，如果导出成 PDF 的话可能会出现分页问题，由于 Markdown 本身的原理就是转换成 HTML 渲染，再加上 Markdown 也是流式文档，HTML 将会是最好的导出格式。导出的文档可以在 .md 的同路径下找到。\n😎 最后说几句 写得多才能写得好，多写文档，养成良好的习惯，文档写的越漂亮，才越会想写 🤣。希望各位能越写越好 👏\n","date":"2019-10-12T00:00:00Z","permalink":"https://www.kindem.xyz/post/19/","title":"用 Visual Studio Code 打造优雅的 Markdown 编辑环境"},{"content":"🤔 问题 如果在 Electron 中使用 React，在 React 组件中调用 Node.js 模块会抛出错误，告知你模块或者模块中的方法不存在，这是因为默认情况下 Electron 模拟的是纯浏览器环境，而浏览器中自然无法直接使用 Node.js 模块，如果需要使用 Node.js 模块，需要进行额外的配置。\n🎉 解决方法 在创建 Electron 中的 BrowserWindow 对象的时候，进行额外配置，启用 webPreferences 中的 nodeIntegration 和 nodeIntegrationInWorker，使之支持 Node.js 模块：\nlet window = new BrowserWindow({ width: 800, height: 600, webPreferences: { nodeIntegration: true, nodeIntegrationInWorker: true } }); 完成这一步后，如果使用了 babel 进行编译，则可以直接使用：\nimport path from \u0026#39;path\u0026#39;; 这样的形式引用 Node.js 模块，如果没有使用 babel，则需要使用：\nconst path = window.require(\u0026#39;path\u0026#39;); 来引用 Node.js 模块。\n","date":"2019-07-13T00:00:00Z","permalink":"https://www.kindem.xyz/post/18/","title":"在 Electron + React 中使用 Node.js 模块"},{"content":"🤔 起因 今天遇到一个玄学的 bug，主要是因为引入了 pinyin 包，这个包其中的一行代码会导致 Webpack 默认使用的 Minifier 失效，从而导致编译失败。\n经过一份排查和寻求帮助，我发现可以通过在 Webpack 中引入 uglifyjs 这一插件来解决。\n但是我使用的是 create-react-app 创建的 React 项目，这样一来 Webpack 的配置将会被隐藏，需要使用 react-app-rewired 来暴露位于 node_modules 目录下的 Webpack 配置，但是网上并没有找到关于在 react-app-rewired 中添加 uglifyjs 插件的方法。\n🎉 解决办法 在 npm 上搜寻了一番，找到了一个宝贝 \u0026ndash; react-app-rewire-uglifyjs，通过这个包可以直接在 react-app-rewired 中使用 uglifyjs，使用方法如下：\n在 react-app-rewired 的配置文件 /config-overrides.js 这样写：\nconst rewireUglifyjs = require(\u0026#39;react-app-rewire-uglifyjs\u0026#39;); module.exports = function override(config, env) { // use UglifyJS config = rewireUglifyjs(config); return config; }; 文档可以参考这里：npm - react-app-rewire-uglifyjs\n","date":"2019-03-22T00:00:00Z","permalink":"https://www.kindem.xyz/post/17/","title":"在 react-app-rewired 中使用 uglify.js"},{"content":"👦 用户类 新建用户：\nsudo useradd -m -s /bin/bash $username 移入 sudo 分组：\nsudo usermod -a -G sudo $username 为用户设置密码：\nsudo passwd $username 📦 包管理类 apt 更新源：\nsudo apt-get install update apt 更新软件包：\nsudo apt-get install upgrade 🥤 软件安装 Oh My ZSH 安装：\nsudo apt-get install zsh sh -c \u0026#34;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\u0026#34; vim ~/.zshrc # 修改 ZSH_THEME 即主题，我用的是 # 记得修改字体为 powerline 系列 git 初始配置：\n# 配置用户名邮箱 sudo git config --global user.name \u0026#34;$username\u0026#34; sudo git config --global user.email \u0026#34;$email\u0026#34; # 默认编辑器 sudo git config --global core.editor vim # 自动储存用户名和密码 sudo git config --global credential.helper store Node.js 安装，可以参考 Install Node.js via package manager：\ncurl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash - sudo apt-get install -y nodejs # 更改 ~/.confg 拥有者，否则试用 npm 可能会提示 Permisson Denied sudo chown -R $user ~/.npm sudo chown -R $user ~/.config MySQL(Debian/Ubuntu) 安装：Debian9安装MySQL\n☕ 杂项 更改主机名：\nsudo vim /etc/hosts sudo vim /etc/hostname # 然后修改所有原有主机名为你的主机名 sudo hostname $hostname systemctl 目录：\n/lib/systemd/system ","date":"2019-03-21T00:00:00Z","permalink":"https://www.kindem.xyz/post/16/","title":"Linux 备忘"},{"content":"🤔 Ajax跨域简介 所谓 Ajax 跨域指的是 Ajax 请求从其他的域获取数据或者传输数据\n所谓域同源，指的是两个服务器资源的根 url 的域名、端口、协议三者完全相同，只要三者中任何一个不同，则说明产生了跨域\n给一个例子，对于第一个服务器资源，其他一些 url 的同源情况如下:\nhttp://www.test.com/index.html http://www.test.com/index.js 同源 http://www.test.com/login/login.js 同源 https://www.test.com/index.html 跨域(协议) http://www.a.com/index.html 跨域(域名) http://a.com/index.html 跨域(不同子域) http://www.test.com:8080/index.html 跨域(端口) 🥤 常用跨域方法 CORS CORS 是一个 W3C 标准，其全称为 Cross-Origin Resource Sharing，即跨域资源共享。它允许浏览器向跨域服务器发送 XMLHttpRequest 请求，从而克服了 Ajax 只能同源使用的限制\nCORS 需要浏览器和服务器同时支持，目前主流浏览器都支持这个标准( IE\u0026gt;=10 )，所以 CORS 的关键主要在于服务器，要支持这个功能，往往开发者需要在服务器端进行额外设置\n另外，CORS 标准对用户来说是透明的，用户感知不到 CORS 的存在，一切都是浏览器自动完成。当浏览器检测到跨域的 Ajax 请求时，就会自动做出一些处理，使得请求能够跨域\n跨域的 Ajax 请求分为两种：\n简单请求: 请求方法为 HEAD、POST、GET 之一 HTTP 头字段只有 Accept、Accept-Language、Content-Language、Last-Event-ID、Content-Type 中的一种或多种 HTTP 头字段中的 Content-Type 字段的取值为 application/x-www-form-urlencoded、multipart/form-data、text/plain 之一 非简单请求: 所有不满足上述规则的请求 CORS 对于两种不同的请求的处理是不同的\n对于简单请求，一个跨域 Ajax 请求的处理流程如下:\n浏览器自动在本次请求的 HTTP 头中添加 Origin 字段，表示这次请求来自的域 服务器根据 Origin 字段判断这一次请求是否在许可范围内： 如果不在，返回一个正常的 HTTP 响应，只不过响应的 HTTP 头中没有 Access-Control-Allow-Origin 字段，浏览器将认为这一次跨域 Ajax 没能成功 如果在，服务器会在响应 HTTP 头中添加这几个字段 Access-Control-Allow-Origin: 这个字段标识服务器认同的 Origin，这个 Origin 为 * 时标识服务器认同所有源。只有请求的 HTTP 头的 Origin 与该字段同源时，浏览器才会认为这一次跨域 Ajax 请求成功了 Access-Control-Allow-Credentials: 这个字段标识服务器允许 Cookie，如果设置为 true 则标识允许，默认为不允许 Access-Control-Expose-Headers: 允许 XMLHttpRequest 获取的额外字段名 对于非简单请求，一个跨域 Ajax 请求的处理流程如下:\n浏览器在发送正式的 Ajax 请求之前，会提前发送一次 OPTIONS 请求，头信息中有: Origin: 请求的源 Access-Control-Request-Method: 浏览器会用的的 HTTP 方法 Access-Control-Request-Headers: 浏览器会额外发送的头信息字段 收到这个请求之后，服务器将会返回一些控制信息，最重要的仍然是上面说到的判定是否允许跨域的 Access-Control-Allow-Origin 如果服务器返回了一个正常的 HTTP 响应，则浏览器会认为 OPTIONS 请求成功，接下来则会进行真正的的请求 服务器正常处理真正的请求，并且在返回的 HTTP 响应中也带上 Access-Control-Allow-Origin，浏览器会再一次校验这一字段 可见 CORS 标准本身并不复杂，其核心是 服务器和浏览器验证域是否被允许\nJSONP JSONP 的全称为 JSON with Padding，是 JSON 数据的一种使用模式，JSONP 同样是为了支持跨域 Ajax 请求而生的，但是它相对 CORS 来说对古老的浏览器兼容性较好，也更加简单。\nJSONP 的原理是 JavaScrip t注入，在 html 中使用 script 标签引入 JavaScript 脚本是不会受到同源限制的，这意味着可以通过 script 标签引入来自跨域的脚本，像这样:\n\u0026lt;!-- origin: http://www.test.com --\u0026gt; \u0026lt;script\u0026gt; function dealData(jsonData) { // do something with jsonData } \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://www.a.com/data.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 想象一下如果引入的脚本是这样的:\ndealData({ username: \u0026#39;kindem\u0026#39;, age: 15, // ... }); 不是就相当于从服务器拿到一段数据并且进行处理了吗?\n接下来可以设想一下，假设服务器对于 src 指向的 url 的处理并不是返回一个静态文件，而是动态地组合出一段文本，这段文本一上面给的形式返回，里面的参数由服务器动态生成，而调用的函数则是前端约定好的函数，则相当于变相地返回了一段跨域的数据，这就是 JSONP 的核心思想\n","date":"2018-08-30T00:00:00Z","permalink":"https://www.kindem.xyz/post/14/","title":"Ajax 跨域"},{"content":"模板字符串是可以使用内嵌表达式的字符串，不少高级语言中都有这一特性，如 Python、Kotlin，JavaScript 也在 ES5 规范中加入了这一特性。\n☕ 语法 `text` `lin1 lin2` `text ${expr}` tag `text ${expr}` 🧀 详解 JavaScript 中的模板字符串使用反引号来包裹字符串内容而不是单引号或双引号。\n转义 因为模板字符串使用反引号来包裹字符串内容，所以在模板字符串内部使用反引号时需要转义，如下：\n`\\`` === \u0026#39;`\u0026#39; // true 多行字符串 如果使用模板字符串，任何被包裹在两个反引号之间的字符都会被认为是有效的字符串内容，包括换行字符。所以。\n`line1 line2` //等价于 \u0026#39;line1\\n\u0026#39; + \u0026#39;line2\u0026#39; 内嵌表达式 使用模板字符串的最大优势在于不必再使用繁琐的字符串连接操作来连接普通字符串与表达式，而是可以直接在字符串内部写表达式。\nlet a = 10; let b = 20; // \u0026#39;10 + 20 = 30\u0026#39; console.log(`${a} + ${b} = ${a + b}`); 带标签的模板字符串 更高级的形式的模板字符串是带标签的模板字符串。标签使您可以用函数解析模板字符串。标签函数的第一个参数包含一个字符串值的数组。其余的参数与表达式相关。最后，你的函数可以返回处理好的的字符串（或者它可以返回完全不同的东西 , 如下个例子所述）。用于该标签的函数的名称可以被命名为任何名字。\nvar person = \u0026#39;Mike\u0026#39;; var age = 28; function myTag(strings, personExp, ageExp) { var str0 = strings[0]; // \u0026#34;that \u0026#34; var str1 = strings[1]; // \u0026#34; is a \u0026#34; // There is technically a string after // the final expression (in our example), // but it is empty (\u0026#34;\u0026#34;), so disregard. // var str2 = strings[2]; var ageStr; if (ageExp \u0026gt; 99){ ageStr = \u0026#39;centenarian\u0026#39;; } else { ageStr = \u0026#39;youngster\u0026#39;; } return str0 + personExp + str1 + ageStr; } var output = myTag`that ${ person } is a ${ age }`; console.log(output); // that Mike is a youngster 正如下面例子所展示的，标签函数并不一定需要返回一个字符串。\nfunction template(strings, ...keys) { return (function(...values) { var dict = values[values.length - 1] || {}; var result = [strings[0]]; keys.forEach(function(key, i) { var value = Number.isInteger(key) ? values[key] : dict[key]; result.push(value, strings[i + 1]); }); return result.join(\u0026#39;\u0026#39;); }); } var t1Closure = template`${0}${1}${0}!`; t1Closure(\u0026#39;Y\u0026#39;, \u0026#39;A\u0026#39;); // \u0026#34;YAY!\u0026#34; var t2Closure = template`${0} ${\u0026#39;foo\u0026#39;}!`; t2Closure(\u0026#39;Hello\u0026#39;, {foo: \u0026#39;World\u0026#39;}); // \u0026#34;Hello World!\u0026#34; 原始字符串 在标签函数的第一个参数中，存在一个特殊的属性 raw ，我们可以通过它来访问模板字符串的原始字符串，而不经过特殊字符的替换。\nfunction tag(strings) { console.log(strings.raw[0]); } tag`string text line 1 \\n string text line 2`; // logs \u0026#34;string text line 1 \\n string text line 2\u0026#34; , // including the two characters \u0026#39;\\\u0026#39; and \u0026#39;n\u0026#39; 另外，使用 String.raw() 方法创建原始字符串和使用默认模板函数和字符串连接创建是一样的。\nvar str = String.raw`Hi\\n${2+3}!`; // \u0026#34;Hi\\n5!\u0026#34; str.length; // 6 str.split(\u0026#39;\u0026#39;).join(\u0026#39;,\u0026#39;); // \u0026#34;H,i,\\,n,5,!\u0026#34; ","date":"2018-06-09T00:00:00Z","permalink":"https://www.kindem.xyz/post/12/","title":"JavaScript 中的模板字符串"},{"content":"🤔 Electron ? Electron 是一个使用 HTML、CSS、JavaScript 构建跨平台桌面应用的框架。\n说白了就是用这个框架，你可以在使用前端技术来开发桌面应用，原理是在本地应用上跑一个抽出来的浏览器，浏览器上放你写的页面。\n你可能会问 Electron 的存在有什么意义，众所周知，前端技术可以让我们轻松写出漂亮易用的界面，如果你尝试过其他的桌面开发技术，想必你也应该知道其他的那些桌面开发工具开发出来的界面有多丑，而 Electron 轻松地解决了这个问题。而且从另外一个角度来讲，Electron 也可以快速地将你的网站打包成一个原生应用发布。总之，前端技术是构建用户界面最好的选择，而 Electron 则为这一思想在桌面的实现奠定了基础。\n☕ 聊一聊需要用到的前端技术栈 如果你已经对常见的前端技术栈有着一定了解，建议直接跳至下一节，查看 Electron + React 项目的建立方法。\n在开始我们的畅聊之前，先要说一说原始的前端技术。众所周知，传统的前端技术都是使用 HTML、CSS、JavaScript 这御三家来完成开发的，HTML 负责页面框架、CSS 负责页面样式、JavaScript 负责页面动态，这三者各司其职，展现出一个完整美妙的 Web 世界。\n随着前端的发展，这三者开始出现了这样那样的问题，每一项新前端技术的出现，都是前端的一次飞跃。\nNode.js Node.js 的出现，无非是前端发展的一个里程碑，它的出现，将前端推向了一个新的高峰。\nNode.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效。 Node.js 的包管理器 npm，是全球最大的开源库生态系统。\n看官网的解释你可能还是一脸懵逼，这么说吧，传统的 JavaScript 只能依赖浏览器而运行，而 Node.js 则将 Chrome 的浏览器引擎抽了出来并加以改进，使得 JavaScript 可以脱离浏览器而运行。\n而 npm 则是 Node.js 的一个包管理工具，你可以使用 npm 安装这样那样的 JavaScript 包，就像 Python 的 pip 那样简单。\nNode.js 的出现，使得这样那样的前端开发工具、框架如春笋般涌现，如 Grunt、Webpack、React、Vue 等等。而且 JavaScript 能够脱离浏览器而运行，也从某种意义上使 JavaScript 变成了一个跨平台语言。可以说，Node.js，就是如今前端的核心。\n构建工具 传统的前端 JavaScript 开发中，会存在一些问题，最大的问题之一，就是项目文件之间的依赖问题，这一问题时常让前端开发者苦恼不已。\n随着 Node.js 的出现，人们对 JavaScript 的使用方法产生了潜移默化的变化，因为 JavaScript 已经成为了一门脱离浏览器而存在的Native语言，人们开始将 JavaScript 像其他语言一样看待。\n“编译”，这一概念，也自然地被人们引入了 JavaScript 的世界，尽管它是一门动态语言。在传统语言中，“编译”这一过程时常是将多个源文件编译并链接成一个可执行文件，“编译”的过程，无非就三个重要点：\n每一个源文件输出成中间件 判断各个中间件之间的相互依赖关系 根据依赖关系将中间件打包在一起构成输出 这一思想被运用到 JavaScript 之后，人们觉得 JavaScript 也应该有“编译”这一过程，用来做以下事情：\n将每一个 JavaScript 文件压缩，删去所有无效字符，输出为中间件 判断各个中间件之间的依赖关系 根据依赖关系将所有中间件打包成一个输出文件，这个输出文件中具有原来各个 JavaScript 中的所有功能，但是体积更小，而且依赖关系被严格限制并且无误 这就是构建工具，你可以把他们认为是 JavaScript 的编译器，用于产生更加适合生产使用的输出文件。\n当然这只是构建工具功能的一部分，现在的构建工具往往还具有一些更加高级的功能，比如自动流程等。\n现在常见的构建工具有 Grunt、Webpack 等。\nReact React 是一个用于构建用户界面的 JavaScript 框架，与 Vue、Angular 这另两大框架相并列。\nReact 的强大之处在于用一种巧妙的思想处理了 Web 页面中冗余重复代码多的问题。它能将一些可重用的代码封装成一个个组件，在另外使用的时候，只需要使用组件进行实例化即可。这种思想与面向对象的思想非常相像。所以说，从思想和使用上说，React应该是一个非常成熟的框架。\n前端路由 众所周知，往常Web网站中的路由是交由后端来做的，比如用户访问\n/match/2 这么一个 url，本来应该是由后端服务器来接收请求并且做出相应的处理。但是随着 Node.js 和构建工具的出现，人们开始想，那么多请求都要交由后端来做岂不是很麻烦，而且从某种意义上，Web 网站本身就是一个应用，其中的地址变化处理的逻辑应该在应用内部解决，只有涉及到后端需求的，才交由服务器来处理。\n所以，前端路由，应运而生。\n前端路由的存在意义就在于将路径逻辑交由前端来处理，而不是后端，这样能让后端专注与真正需要后端资源的请求的处理。\n前端路由往往与构建工具、前端界面框架相互配合，构建工具负责将所有文件打包，而前端界面框架往往自己带有自己的前端路由框架，最后打包出来的输出文件，一般只有一个 inedx.html、一个 bunble.js 和其他的资源文件。一个 index.html ，配合 bunble.js，就能展现所有页面的内容。\n这样既能减少请求量，又符合人们的正常思想，一个网站就是一个应用，像 Native 那样，应用内部的逻辑由应用自己处理，真正需要后端支援的时候才发送请求到服务器，让服务器处理，多好。\n🎉 项目搭建例子: Electron + React + Ant-Design 理论上来说，目前的前端框架都能很好地配合 Electron 进行工作，当然你甚至可以使用原生御三家加上 Node.js 来进行 Electron 应用的开发。\n在这里，我以我本人的开发喜好为例，讲解一下使用 React 作为前端界面框架、Ant-Design 作为 UI 库、Electron 作为 Native 支持的项目搭建。\n接下来的操作默认你已经安装了 Node.js。\n安装Electron 首先，当然需要安装 Electron 了，进入 cmd：\nnpm install -g electron 如果无法安装尝试为 npm 设置代理。\n我这里使用的是全局安装 Electron，原因是因为 Electron 包比较大，而且运行 Electron 这一操作是可复用的，所以我认为全局安装 Electron 更加合适，这里只需要安装一次 Electron，在哪里都能使用。\n创建React项目 接下来用于我们需要使用 React，所以一个在项目中启用 React 支持也是必不可少的，创建一个真正可用的 React 项目环境还是比较复杂的，这里推荐直接使用 Facebook 官方的 create-react-app 工具，使用它可以直接创建一个 React 项目。\n使用 npm 全局安装它：\nnpm install -g create-react-app 安装完 create-react-app 之后，我建议使用 WebStorm 来创建项目，因为 WebStorm 是现在最好的 JavaScript IDE，当然如果你一定要使用命令行来创建我也没意见，只是 WebStorm 可以方便你之后的开发。\n你安装 create-react-app 成功之后，就能直接在 WebStorm 中使用集成创建项目的方法创建一个 React 项目，创建项目的时候选择到 React App 一栏，WebStorm 会自动识别到 create-react-app 以供你创建项目：\nWebStorm创建项目 第一栏是你项目的位置，自己选一个并且取好项目名即可，第三栏如果报红色错误则说明你的 create-react-app 工具没能被识别或者没能被安装，请自行检查。\n确认无误之后创建项目即可，创建项目之后将会自动执行指令完成之后的事情。\n等下面的操作全部完成之后，你可以看到项目目录像这样：\n项目结构 这时候推荐再安装一个额外的包管理工具 yarn，这个时候我们可以不用使用自己的 cmd 或者终端了，而可以直接使用 WebStorm 自带的集成终端，这个终端跟原生终端( cmd )一样，但是会自动进入项目目录下。看上方的菜单：View -\u0026gt; Tool Windows -\u0026gt; Terminal 即可调出，在集成终端中输入：\nnpm install -g yarn 安装 yarn，以后我们将使用 yarn 来进行包管理而不是 npm，因为 yarn 有着更多优点。\n这时候你可以使用：\nyarn start 打开调试服务器，在弹出的网页中你可以直接看到 React 的欢迎页面，这些就是 public 和 src 目录下的文件所做的努力。\n但是接下来，我们需要把他们全部删除，因为我们自己的页面根本不需要它。注意是删除 public、src 文件夹下的所有文件，而不是删除这两个文件夹！\n引入Ant-Design 当删除完成之后，我们就可以引入 Ant-Design 了，在集成终端中输入：\nyarn add antd 这样一来我们就在项目中引入了 Ant-Design，但是我们还不能直接使用它，我们还需要做一些处理。\n安装 react-app-rewired，这是一个自定义配置 react 项目的工具：\nyarn add react-app-rewired --dev 修改根目录下的 package.json：\n# /package.json \u0026#34;scripts\u0026#34;: { - \u0026#34;start\u0026#34;: \u0026#34;react-scripts start\u0026#34;, - \u0026#34;build\u0026#34;: \u0026#34;react-scripts build\u0026#34;, - \u0026#34;test\u0026#34;: \u0026#34;react-scripts test --env=jsdom\u0026#34;, + \u0026#34;start\u0026#34;: \u0026#34;react-app-rewired start\u0026#34;, + \u0026#34;build\u0026#34;: \u0026#34;react-app-rewired build\u0026#34;, + \u0026#34;test\u0026#34;: \u0026#34;react-app-rewired test --env=jsdom\u0026#34;, } 这样做的目的是让 start、build、test三个命令使用我们自定义的 React 配置而不是使用默认的。\n然后在项目根目录下创建一个 config-overrides.js，用于书写自定义配置：\n# /config-overrides.js module.exports = function override(config, env) { return config; }; 接下来需要安装 babel-plugin-import，这是一个按需加载代码、样式的 babel 插件：\nyarn add babel-plugin-import --dev 修改 config-overrides.js：\n# /config-overrides.js + const { injectBabelPlugin } = require(\u0026#39;react-app-rewired\u0026#39;); module.exports = function override(config, env) { + config = injectBabelPlugin([\u0026#39;import\u0026#39;, { libraryName: \u0026#39;antd\u0026#39;, libraryDirectory: \u0026#39;es\u0026#39;, style: \u0026#39;css\u0026#39; }], config); return config; }; 这样一来，Ant-Design 就配置完了\n添加路由 这时候在 public 下新建一个 html 文件，像这样：\n# /public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Electron Test\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 这个文件将来将会作为 Electron 的入口网页文件。\n安装前端路由 react-router-dom：\nyarn install react-router-dom 安装完成之后，在 src 目录下新建一个入口 js 文件 index.js、一个路由组件文件 router.js，再创建一个文件夹叫 page 用于存储页面组件文件，里面再建立一个文件叫做 index.js，用于存储首页组件，这时项目结构如下：\n项目结构 这时候我们先修改 /src/page/index.js 文件，在里面写一个首页的组件：\n# /src/page/index.js import React from \u0026#39;react\u0026#39;; import { Button } from \u0026#39;antd\u0026#39;; export class IndexPage extends React.Component { render() { return ( \u0026lt;div\u0026gt; \u0026lt;Button\u0026gt;Click Me!\u0026lt;/Button\u0026gt; \u0026lt;/div\u0026gt; ); } } 然后打开路由文件 /src/router.js，写路由组件：\n# /src/router.js import React from \u0026#39;react\u0026#39;; import { HashRouter, Route, Switch } from \u0026#39;react-router-dom\u0026#39;; import { IndexPage } from \u0026#34;./page\u0026#34;; export class MainRouter extends React.Component { render() { return ( \u0026lt;HashRouter\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route exact path={\u0026#39;/\u0026#39;} component={IndexPage}/\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/HashRouter\u0026gt; ); } } 以后添加新页面只需要在 page 中写一个新的页面组件文件，然后修改路由文件，在 Switch 中添加 path 与组件的对应关系即可。\n接下来再在 /src/index.js 这一入口文件中渲染路由组件：\n# /src/index.js import React from \u0026#39;react\u0026#39;; import ReactDom from \u0026#39;react-dom\u0026#39;; import { MainRouter } from \u0026#34;./router\u0026#34;; ReactDom.render( \u0026lt;MainRouter/\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) ); 这样一来，就算成功地写了一个框架了，以后添加新页面只需要按照规则添加即可。\n可以尝试使用：\nyarn start 来运行调试服务器查看页面是否显示正常。如果看到这样的页面，上面有一个 Antd 样式的按钮：\n页面效果 那么恭喜你，至少你到这一步之前的都成功了，如果没有成功，仔细回看步骤，看是否有做错的地方。\n使用Electron运行页面 既然页面在不使用的 Electron 的时候能够正常运行，那么应该在 Electron 上面跑一跑看一下效果了。\n在 /package.jso n中添加一条脚本，并且修改少量配置,用于执行 Electron 应用：\n# /package.json \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;react-app-rewired start\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;react-app-rewired build\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;react-app-rewired test --env=jsdom\u0026#34;, \u0026#34;eject\u0026#34;: \u0026#34;react-scripts eject\u0026#34;, + \u0026#34;estart\u0026#34;: \u0026#34;electron .\u0026#34; } ... + \u0026#34;main\u0026#34;: \u0026#34;main.js\u0026#34;, + \u0026#34;homepage\u0026#34;: \u0026#34;.\u0026#34;, + \u0026#34;DEV\u0026#34;: true 在项目根目录下创建一个 main.js，用于作为 Electron 应用的入口：\n# /main.js const { app, BrowserWindow } = require(\u0026#39;electron\u0026#39;); // 浏览器引用 let window; // 创建浏览器窗口函数 let createWindow = () =\u0026gt; { // 创建浏览器窗口 window = new BrowserWindow({ width: 800, height: 600 }); // 加载应用中的index.html文件 window.loadFile(\u0026#39;./build/index.html/\u0026#39;); // 当window被关闭时，除掉window的引用 window.on(\u0026#39;closed\u0026#39;, () =\u0026gt; { window = null; }); }; // 当app准备就绪时候开启窗口 app.on(\u0026#39;ready\u0026#39;, createWindow); // 当全部窗口都被关闭之后推出 app.on(\u0026#39;window-all-closed\u0026#39;, () =\u0026gt; { if (process.platform !== \u0026#39;darwin\u0026#39;) { app.quit(); } }); // 在macos上，单击dock图标并且没有其他窗口打开的时候，重新创建一个窗口 app.on(\u0026#39;activate\u0026#39;, () =\u0026gt; { if (window == null) { createWindow(); } }); 从此，每次运行 Electron，只需要输入\n# 运行构建指令 yarn build # 使用electron运行构建出来的Web项目 yarn estart 即可看见效果，像这样：\nElectron 应用运行效果 像平时写 Web 项目一样写原生 UI 吧，Enjoy!\n","date":"2018-06-03T00:00:00Z","permalink":"https://www.kindem.xyz/post/11/","title":"使用 Electron 和 React 构建桌面应用"},{"content":"☕ FastBle VS 原生Android蓝牙API 原生 Android 的蓝牙 API 使用有点麻烦，要先获取设备的蓝牙适配器，接着注册广播来接受蓝牙设备信息，用完了还需要将广播给注销，相对来说有点麻烦。\n不好封装，可以说是原生 Android 最让人痛苦的地方，这是因为原生 Android 的代码不是很独立，与 Activity、广播等相杂糅。市面上的蓝牙库也是少之又少，先看了看 BleLib，感觉还是换汤不换药，用起来一点也不简洁。\n但是 FastLib 封装的就很技巧，基本上能把一个操作的粒度控制在一行内，另外，代码也无需与线程、通知之类的打交道，库中已经帮我们把这些复杂的东西都做完了。\nFastBle 的 Github 项目地址在这，大家可以看看：FastBle - GitHub\n它的文档也相对比较完整，大家可以查看官方文档来使用它：FastBle - Document\n✨ FastBle的使用 0x00 申明权限 只要使用到了蓝牙，申明权限是必不可少的，FastBle 需要的权限如下:\n\u0026lt;uses-permission android:name=\u0026#34;android.permission.BLUETOOTH\u0026#34; /\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.BLUETOOTH_ADMIN\u0026#34; /\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.ACCESS_COARSE_LOCATION\u0026#34; /\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.ACCESS_FINE_LOCATION\u0026#34; /\u0026gt; 这里要注意一点，如果 Android 版本高于 6.0，用户还需要打开位置信息(不光要位置权限，还需要打开位置信息)才能通过蓝牙进行扫描。\n0x01 初始化与全局配置 初始化需要在库中任何函数被调用前执行，由于库使用的是单例模式，只需要初始化一次，在哪里都能使用，建议在 onCreate 里执行初始化代码：\nBleManager.getInstance().init(getApplication()); 全局配置可以紧跟初始化之后执行，当然如果不进行配置也没有任何关系，每一个选项都有默认值：\nBleManager.getInstance() .enableLog(true) .setReConnectCount(1, 5000) .setSplitWriteNum(20) .setConnectOverTime(10000) .setOperateTimeout(5000); 每一项的详细信息你都能在官方文档中找到说明\n0x02 打开蓝牙 使用 FastBle 中的 BleManager 类有很多种方式来打开蓝牙，这里推荐使用下面这种方式，这种方式会使线程被阻塞，如果用户不选择是否打开蓝牙，线程将会暂停执行：\nBleManager.getInstance().enableBluetooth(); 0x03 扫描设备 打开蓝牙之后即可扫描设备，在正式扫描之前，可以自定义扫描规则，像这样：\nBleScanRuleConfig scanRuleConfig = new BleScanRuleConfig.Builder() .setServiceUuids(serviceUuids) // 只扫描指定的服务的设备，可选 .setDeviceName(true, names) // 只扫描指定广播名的设备，可选 .setDeviceMac(mac) // 只扫描指定mac的设备，可选 .setAutoConnect(isAutoConnect) // 连接时的autoConnect参数，可选，默认false .setScanTimeOut(10000) // 扫描超时时间，可选，默认10秒；小于等于0表示不限制扫描时间 .build(); BleManager.getInstance().initScanRule(scanRuleConfig); 在设置规则后，即可开始扫描，像这样\nBleManager.getInstance().scan(new BleScanCallBack() { @Override public void onScanStarted(boolean success) { // 开始扫描的回调 } @Override public void onScanning(BleDevice bleDevice) { // 扫描到一个之前没有扫到过的设备的回调 } @Override public void onScanFinished(List\u0026lt;BleDevice\u0026gt; scanResultList) { // 扫描完成的回调，列表里将不会有重复的设备 } }); 这几个回调都是线程安全的，将会自动返回主线程，所以可以放心使用。\n当然，在任何地方，任何时候，你都可以直接使用取消扫描这个函数来停止扫描:\nBleManager.getInstance().cancelScan(); 0x04 连接设备 在扫描之后，你已经获取到了一个或多个 BleDevice 对象，你可以直接使用这些对象向目标设备发起连接，像这样：\nBleManager.getInstance().connect(bleDevice, new BleGattCallback() { @Override public void onStartConnect() { // 开始连接 } @Override public void onConnectFail(BleDevice bleDevice, BleException exception) { // 连接失败 } @Override public void onConnectSuccess(BleDevice bleDevice, BluetoothGatt gatt, int status) { // 连接成功，BleDevice即为所连接的BLE设备 } @Override public void onDisConnected(boolean isActiveDisConnected, BleDevice bleDevice, BluetoothGatt gatt, int status) { // 连接中断，isActiveDisConnected表示是否是主动调用了断开连接方法 } }); 当然，在官方文档中还有很多详细的说明，这里只是简单介绍了一下FastBle的基本使用，了解详情还请看官方文档。\n","date":"2018-05-25T00:00:00Z","permalink":"https://www.kindem.xyz/post/10/","title":"Android 蓝牙库 FastBLE 的使用方法"},{"content":"📦 Ubuntu18 下 Gtk 开发环境搭建 GTK 是在 Linux 下使用 c 语言构建图形界面的一个库，它构建的图形界面是基于 GNOME 运行的。\nUbuntu18 已经回归到了主流 Linux 桌面 GNOME 上，所以我们搭建 GTK 开发环境的时候，不需要再额外安装 GNOME 了。\n至于 GTK 的安装，你首先需要安装编译工具：\nsudo apt-get install build-essential GTK 现在有两种版本，2 和 3，可以使用如下指令同时安装两个版本:\nsudo apt-get install gnome-core-devel 接下来还要安装 pkg-config 用于自动查找 GTK 的头文件位置：\nsudo apt-get install pkg-config 完成之后你可以使用官方给出的示例来测试是否能够运行，Getting Started With GTK+\n编译指令如下：\ngcc main.c -o main `pkg-config --cflags --libs gtk+-3.0` 完成之后即可打开可执行文件运行查看效果\n","date":"2018-05-18T00:00:00Z","permalink":"https://www.kindem.xyz/post/9/","title":"Ubuntu18 搭建 GTK 开发环境"},{"content":"🤔 什么是 Bash On Windows Bash On Windows 是微软的 Microsoft Love Linux 计划中重要的一环，目的是能让 Windows 用户能在系统中运行 Linux 子系统，也就是说你可以直接在 Windows 中获得原生 Linux Bash 级别的体验。\n📦 安装 首先你要确保你的 Windows 已经升级到创意者更新版本( 1709 )，因为只有创意者更新版本以后的 Windows，Bash On Windows 才真正发行，之前的都是测试版本。\n首先，你需要进入控制面板的程序与功能界面，点击启动或关闭 Windows 功能： 程序与功能 然后，把适用于 Windows 的 Linux 子系统这一项勾上，并且点击确定 启动或关闭Windows功能 接着，你就可以直接在商店下载你需要的 Linux 系统了，打开 Windows Store，搜索 Linux，可以看到很多 Linux 子系统： Windows Store 你可以任选一下载，我选的是 Ubuntu 18.04，下载完成之后，你可以在 Windows 任务栏上面的搜索栏直接搜索 Ubuntu (我是 Ubuntu，如果你下了其他的你就搜其他的)，打开会要求你先重启电脑。\n重启之，重启完成之后，再次打开子系统，你会发现他在慢慢解压，如果不成功的话，你可以直接在 Windows Store 中卸载它并且重新安装就行了，Linux 子系统在 Windows 里面，就相当于一个 Windows Store 应用。\n安装完成之后，你就可以像使用普通 Bash 一样使用之了。\n☕ 优化 当然，子系统是以 cmd 的形式跑在 Windows 里面的，这样显然会有很多问题，比如每次你退格所有字符，就会发出一声让人绝望的 Windows 错误提示音，再者这样的 Linux Bash 也不好看。\n这里推荐使用 cmder 优化之，cmder 是一个优化版的 Windows Cmd，但是他可以设置启动命令，我们使用这条启动命令，可以让 Cmd 自动启动 Bash，这样就可以让 cmder 直接运行 Bash。\ncmder 的字体和各种配置是可以设置的，所以，这样用子系统就很舒服！\ncmder的官网在这： Cmder | Console Emulator\n你可以下载 Mini 版，也可以下载 Full 版本，都差不多，运行 cmder 之后点击右下角的汉堡形按钮，可以看到 Settings，进去，像下面这样改动： cmder settings 代码如下：\n%windir%\\system32\\bash.exe ~ -cur_console:p:n 这样就可以让他启动的时候自动进入 Bash，另外字体什么的就不提了，可以在上面设置，配色什么的也是。\n最后放一张我的Ubuntu子系统优化结果： Ubuntu + Cmder ","date":"2018-05-15T00:00:00Z","permalink":"https://www.kindem.xyz/post/8/","title":"Bash On Windows 安装教程"},{"content":"🤔 问题 今天在写页面的时候发现一个问题，就是在 React Router 中使用了 Url 传参的功能，像这样:\nexport class MainRouter extends React.Component { render() { return ( \u0026lt;BrowserRouter\u0026gt; \u0026lt;Switch\u0026gt; ... \u0026lt;Route exact path={\u0026#39;/channel/:channelId\u0026#39;} component={ChannelPerPage}/\u0026gt; ... \u0026lt;/Switch\u0026gt; \u0026lt;/BrowserRouter\u0026gt; ); } } 按照官方文档的说法，可以在 ChannelPerPage 这个组件中使用\nthis.props.match.params 来获取 url 参数的值，但是我发现如果你在这个 url 下只将 url 中的参数部分改变，比如 channelId 从 1 变成 2 的时候，页面并不会重新渲染。\n🧐 解决办法 查阅资料后发现这样的根本原因是 props 的改变并不会引起组件的重新渲染，只有 state 的变化才会引起组件的重新渲染，而 url 参数属于 props，故改变 url 参数并不会引起组件的重新渲染。\n后来发现React的组件中有一个可复写的方法\ncomponentWillReceiveProps(nextProps) { ... } 这个方法可以在 React 组件中被复写，这个方法将会在 props 改变的时候被调用，所以你可以使用这个方法将 nextProps 获取到，并且在这个方法里面修改 state 的内容，这样就可以让组件重新被渲染。\n","date":"2018-05-07T00:00:00Z","permalink":"https://www.kindem.xyz/post/7/","title":"React Router 使用 Url 传参后改变页面参数不刷新的解决方法"},{"content":"在 Django 中，上传文件不同于普通服务器的上传方法，在普通服务器中只需要使用一个 Controller 来控制文件的上传即可完成，但是在 Django 中，则需要额外使用数据库资源来存储文件。本文将说明如何使用 Django 接收、保存并且返回图片。\n☕ 准备 首先，你需要为你的 Python 安装 pillow，pillow 是一个 Python 图像库，Django 的图片方面的功能使用到了它，所以我们需要事先安装：\npip install pillow 安装完成之后我们需要在 Django 的 settings.py 中更改一些设置：\n# settings.py # 在末尾添加 MEDIA_ROOT = os.path.join(BASE_DIR, \u0026#39;media\u0026#39;).replace(\u0026#39;\\\\\u0026#39;, \u0026#39;/\u0026#39;) MEDIA_URL = \u0026#39;/media/\u0026#39; 🎫 Model 之前说到了 Django 的图片需要使用额外的数据库资源来存储文件，这样的设定并不是把图片数据本身存在数据库，而是 Django 将会自动将文件上传到你设置的位置，并且把上传之后的图片 path 存入数据库，这样你只需要访问数据库中的 path 即可访问到图片。\n在你的应用目录下的 models.py 里新建一个图片 Model\nfrom django.db import models class Image(models.Model): # 图片 img = models.ImageField(upload_to=\u0026#39;img\u0026#39;) # 创建时间 time = models.DateTimeField(auto_now_add=True) 这样做之后，一旦数据库对象被创建，img 表列接受的图片对象将会自动被上传到 /media/img 文件夹中，在上传完成之后，img 将会保存图片的 path。\n🧀 View 主流服务器接受文件都需要自己写一个响应，Django 也不例外。\n在你的应用下的 views.py 中新建一个响应:\nfrom .models import Image from django.shortcuts import HttpResponse import json MEDIA_SERVER = \u0026#39;http://127.0.0.1:8000/media/\u0026#39; class ImageTool: @staticmethod def get_new_random_file_name(file_name): find_type = False for c in file_name: if c == \u0026#39;.\u0026#39;: find_type = True if find_type: type = file_name.split(\u0026#39;.\u0026#39;)[-1] return str(uuid.uuid1()) + \u0026#39;.\u0026#39; + type else: return str(uuid.uuid1()) def image_upload(request): source = request.FILES.get(\u0026#39;image\u0026#39;) if source: source.name = ImageTool.get_new_random_file_name(source.name) image = Image( img=source ) image.save() return HttpResponse(json.dumps({ \u0026#39;success\u0026#39;: True, \u0026#39;path\u0026#39;: MEDIA_SERVER + image.img.url })) else: return HttpResponse(json.dumps({ \u0026#39;success\u0026#39;: False, \u0026#39;error_code\u0026#39;: 100 })) 响应的主体是 image_upload 方法，而 ImageTool 中 get_new_random_file_name 方法是为了获取一个新的 uuid 随机新名字，这样做的原因是因为图片可能有重名的状况，虽然如果遇到这样的事情 Django 会自动为我们处理，但是为了保持名字的可管理性和统一性，自己写一个重命名的方法会更好。\n🍗 Url 最后只需要在 url 中添加文件上传 view 的 url 即可:\n# urls.py from django.urls import path from . import views urlpatterns = [ ... path(\u0026#39;file/image_upload\u0026#39;, views.file__image_upload) ] 🎉 上传图片和访问图片 完成这些后，你只需要在前端需要上传图片的地方将 url 指向这个地址，就能将图片成功上传，上传完成之后你可以使用 /media/ 加上数据库中图片的 path 就能访问到图片。\n","date":"2018-05-04T00:00:00Z","permalink":"https://www.kindem.xyz/post/6/","title":"Django 中图片的上传及显示"},{"content":"📦 封装举例 export class Ajax { static get(url, data, hook) { let xmlHttpRequest = new XMLHttpRequest(); url += \u0026#39;?\u0026#39;; let count = -1; for (let key in data) { count++; if (data.hasOwnProperty(key)) { url += count === 0 ? key + \u0026#39;=\u0026#39; + data[key] : \u0026#39;\u0026amp;\u0026#39; + key + \u0026#39;=\u0026#39; + data[key]; } } xmlHttpRequest.open(\u0026#39;GET\u0026#39;, url, true); xmlHttpRequest.onreadystatechange = () =\u0026gt; { if (xmlHttpRequest.readyState === 4 \u0026amp;\u0026amp; xmlHttpRequest.status === 200 || xmlHttpRequest.status === 304) { hook(xmlHttpRequest.responseText) } }; xmlHttpRequest.send(); } static post(url, data, hook) { let xmlHttpRequest = new XMLHttpRequest(); let formatData = \u0026#39;\u0026#39;; let count = -1; for (let key in data) { count++; if (data.hasOwnProperty(key)) { formatData += count === 0 ? key + \u0026#39;=\u0026#39; + data[key] : \u0026#39;\u0026amp;\u0026#39; + key + \u0026#39;=\u0026#39; + data[key]; } } xmlHttpRequest.open(\u0026#39;POST\u0026#39;, url, true); xmlHttpRequest.setRequestHeader(\u0026#39;Content-Type\u0026#39;, \u0026#39;application/x-www-form-urlencoded\u0026#39;); xmlHttpRequest.onreadystatechange = () =\u0026gt; { if (xmlHttpRequest.readyState === 4 \u0026amp;\u0026amp; xmlHttpRequest.status === 200 || xmlHttpRequest.status === 304) { hook(xmlHttpRequest.responseText) } }; xmlHttpRequest.send(formatData); } } 🎫 关于 XMLHttpRequest 其实 ajax 无非就是异步网络请求而已，各种语言都有自己的 http 库，只要使用 http 库基本上都能自己实现 ajax 的功能，在 js 中的原生 http 库则是 XMLHttpRequest，使用 XMLHttpRequest 发送一个请求有几个步骤，第一步是打开连接。\nlet xmlHttpRequest = new XMLHttpRequest(); // 三个参数分别是请求类型，URL和是否异步 xmlHttpRequest.open(TYPE, URL, ASYNC); 如果是 POST 请求或是一些自定义的请求，则还需要添加头部内容\n// 两个参数分别是请求头键值 xmlHttpRequest.setRequestHeader(HEADER_KEY, HEADER_VALUE); 如果是异步请求，则需要设定完成相应之后的回调\n// 这个是指readystate变化的时候触发的事件，如果请求成功，会返回200或者304，所以我们在这里面调用回调，当然你也可以在这里设置出错的时候调用的回调函数 xmlHttpRequest.onreadystatechange = () =\u0026gt; { if (xmlHttpRequest.readyState === 4 \u0026amp;\u0026amp; xmlHttpRequest.status === 200 || xmlHttpRequest.status === 304) { hook(xmlHttpRequest.responseText) } }; 然后则可以发送请求\n// 如果是get，则数据以键值对的形式带在url中发送，如果是post，发送的data应该写在这里 xmlHttpRequest.send(DATA); 请求完成后悔自动调用之前设定的钩子函数\n","date":"2018-04-24T00:00:00Z","permalink":"https://www.kindem.xyz/post/5/","title":"使用原生 JavaScript 封装 Ajax 操作"}]